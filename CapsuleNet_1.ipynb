{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "3.6.3",
      "name": "python"
    },
    "colab": {
      "name": "Copy_of_CapsuleNet_on_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyanendar/ms_project/blob/main/CapsuleNet_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7f4c4917-22fb-4b10-879e-51c600e6c3af",
        "_uuid": "9b086e5ec535ad75eada3ca72bf5e6534251074f",
        "id": "LQnu9movo8xz"
      },
      "source": [
        "# Overview\n",
        "\n",
        "The new model CapsuleNet proposed by Sara Sabour (and Geoffry Hinton) claims to deliver state of the art results on [MNIST](https://arxiv.org/abs/1710.09829). The kernel aims to create and train the model using the Kaggle Dataset and then make a submission to see where it actually ends up. Given the constraint of using a Kaggle Kernel means it can't be trained as long as we would like or with GPU's but IMHO if a model can't be reasonably well trained in an hour on a 28x28 dataset, that model probably won't be too useful in the immediate future.\n",
        "\n",
        "## Implementation Details\n",
        "\n",
        "* Keras implementation of CapsNet in Hinton's paper Dynamic Routing Between Capsules.\n",
        "* Code adapted from https://github.com/XifengGuo/CapsNet-Keras/blob/master/capsulenet.py\n",
        "*  Author: Xifeng Guo, E-mail: `guoxifeng1990@163.com`, Github: `https://github.com/XifengGuo/CapsNet-Keras`\n",
        "*     The current version maybe only works for TensorFlow backend. Actually it will be straightforward to re-write to TF code.\n",
        "*     Adopting to other backends should be easy, but I have not tested this. \n",
        "\n",
        "Result:\n",
        "    Validation accuracy > 99.5% after 20 epochs. Still under-fitting.\n",
        "    About 110 seconds per epoch on a single GTX1070 GPU card\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "e30e2e10-a909-485d-be9d-dc6f592911a7",
        "_uuid": "c7e569699c6d067cd9fdf9c77299775e399b2ef3",
        "id": "qWnuqFe2o8x2",
        "outputId": "d28b35b6-9c26-4b5a-ba4f-5f0c0b63a9c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import callbacks\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from keras import callbacks\n",
        "#from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import initializers, layers\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set Seed for random numer\n",
        "def set_seed(seed = 100):\n",
        "  tf.random.set_seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)"
      ],
      "metadata": {
        "id": "efio_60jqJY8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9776fd57-44e0-4211-a7a5-c7e647a10704",
        "_uuid": "f4b5499a472b312d5c5f0274ad429567aced6841",
        "id": "xYHeLw1do8x5"
      },
      "source": [
        "# Capsule Layers \n",
        "Here is the implementation of the necessary layers for the CapsuleNet. These are not optimized yet and can be made significantly more performant. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "167d39ca-ee32-4eec-a83b-86194252b14f",
        "_uuid": "90c180a9a8c20e3fb8a93c3eb42588927cfcd6b6",
        "id": "dQti96GTo8x5"
      },
      "source": [
        "\n",
        "\n",
        "class Length(layers.Layer):\n",
        "    \"\"\"\n",
        "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n",
        "    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n",
        "    inputs: shape=[None, num_vectors, dim_vector]\n",
        "    output: shape=[None, num_vectors]\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), -1) + K.epsilon())\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Length, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "class Mask(layers.Layer):\n",
        "    \"\"\"\n",
        "    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional \n",
        "    input mask. Except the max-length capsule (or specified capsule), all vectors are masked to zeros. Then flatten the\n",
        "    masked Tensor.\n",
        "    For example:\n",
        "        ```\n",
        "        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n",
        "        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n",
        "        out = Mask()(x)  # out.shape=[8, 6]\n",
        "        # or\n",
        "        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n",
        "        ```\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
        "            # compute lengths of capsules\n",
        "            x = tf.sqrt(tf.reduce_sum(tf.square(inputs), -1))\n",
        "            # generate the mask which is a one-hot code.\n",
        "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
        "            mask = tf.one_hot(indices=tf.argmax(x, 1), depth=x.shape[1])\n",
        "\n",
        "        # inputs.shape=[None, num_capsule, dim_capsule]\n",
        "        # mask.shape=[None, num_capsule]\n",
        "        # masked.shape=[None, num_capsule * dim_capsule]\n",
        "        masked = K.batch_flatten(inputs * tf.expand_dims(mask, -1))\n",
        "        return masked\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if type(input_shape[0]) is tuple:  # true label provided\n",
        "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
        "        else:  # no true label provided\n",
        "            return tuple([None, input_shape[1] * input_shape[2]])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Mask, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "def squash(vectors, axis=-1):\n",
        "    \"\"\"\n",
        "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
        "    :param vectors: some vectors to be squashed, N-dim tensor\n",
        "    :param axis: the axis to squash\n",
        "    :return: a Tensor with same shape as input vectors\n",
        "    \"\"\"\n",
        "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / tf.sqrt(s_squared_norm + K.epsilon())\n",
        "    return scale * vectors\n",
        "\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the\n",
        "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
        "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_capsule] and output shape = \\\n",
        "    [None, num_capsule, dim_capsule]. For Dense Layer, input_dim_capsule = dim_capsule = 1.\n",
        "    :param num_capsule: number of capsules in this layer\n",
        "    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n",
        "    :param routings: number of iterations for the routing algorithm\n",
        "    \"\"\"\n",
        "    def __init__(self, num_capsule, dim_capsule, routings=3,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
        "        self.input_num_capsule = input_shape[1]\n",
        "        self.input_dim_capsule = input_shape[2]\n",
        "\n",
        "        # Transform matrix, from each input capsule to each output capsule, there's a unique weight as in Dense layer.\n",
        "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
        "                                        self.dim_capsule, self.input_dim_capsule],\n",
        "                                 initializer=self.kernel_initializer,\n",
        "                                 name='W')\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n",
        "        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule, 1]\n",
        "        inputs_expand = tf.expand_dims(tf.expand_dims(inputs, 1), -1)\n",
        "\n",
        "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
        "        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule, 1]\n",
        "        inputs_tiled = tf.tile(inputs_expand, [1, self.num_capsule, 1, 1, 1])\n",
        "\n",
        "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n",
        "        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n",
        "        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule, 1]\n",
        "        # Regard the first two dimensions as `batch` dimension, then\n",
        "        # matmul(W, x): [..., dim_capsule, input_dim_capsule] x [..., input_dim_capsule, 1] -> [..., dim_capsule, 1].\n",
        "        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
        "        inputs_hat = tf.squeeze(tf.map_fn(lambda x: tf.matmul(self.W, x), elems=inputs_tiled))\n",
        "\n",
        "        # Begin: Routing algorithm ---------------------------------------------------------------------#\n",
        "        # The prior for coupling coefficient, initialized as zeros.\n",
        "        # b.shape = [None, self.num_capsule, 1, self.input_num_capsule].\n",
        "        b = tf.zeros(shape=[inputs.shape[0], self.num_capsule, 1, self.input_num_capsule])\n",
        "\n",
        "        assert self.routings > 0, 'The routings should be > 0.'\n",
        "        for i in range(self.routings):\n",
        "            # c.shape=[batch_size, num_capsule, 1, input_num_capsule]\n",
        "            c = tf.nn.softmax(b, axis=1)\n",
        "\n",
        "            # c.shape = [batch_size, num_capsule, 1, input_num_capsule]\n",
        "            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "            # The first two dimensions as `batch` dimension,\n",
        "            # then matmal: [..., 1, input_num_capsule] x [..., input_num_capsule, dim_capsule] -> [..., 1, dim_capsule].\n",
        "            # outputs.shape=[None, num_capsule, 1, dim_capsule]\n",
        "            outputs = squash(tf.matmul(c, inputs_hat))  # [None, 10, 1, 16]\n",
        "\n",
        "            if i < self.routings - 1:\n",
        "                # outputs.shape =  [None, num_capsule, 1, dim_capsule]\n",
        "                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "                # The first two dimensions as `batch` dimension, then\n",
        "                # matmal:[..., 1, dim_capsule] x [..., input_num_capsule, dim_capsule]^T -> [..., 1, input_num_capsule].\n",
        "                # b.shape=[batch_size, num_capsule, 1, input_num_capsule]\n",
        "                b += tf.matmul(outputs, inputs_hat, transpose_b=True)\n",
        "        # End: Routing algorithm -----------------------------------------------------------------------#\n",
        "\n",
        "        return tf.squeeze(outputs)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'num_capsule': self.num_capsule,\n",
        "            'dim_capsule': self.dim_capsule,\n",
        "            'routings': self.routings\n",
        "        }\n",
        "        base_config = super(CapsuleLayer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "    \"\"\"\n",
        "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
        "    :param dim_capsule: the dim of the output vector of capsule\n",
        "    :param n_channels: the number of types of capsules\n",
        "    :return: output tensor, shape=[None, num_capsule, dim_capsule]\n",
        "    \"\"\"\n",
        "    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
        "                           name='primarycap_conv2d')(inputs)\n",
        "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n",
        "    return layers.Lambda(squash, name='primarycap_squash')(outputs)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7cd17730-22b6-4ac3-a612-31f18902fa78",
        "_uuid": "61c38c7ee701bb3ee2190263cf907fcdbe40dca2",
        "id": "UDdQcGoko8x8"
      },
      "source": [
        "# Build the Model\n",
        "Here we use the layers to build up the model. The model is a bit different from a standard $X\\rightarrow y$  model, it is $(X,y)\\rightarrow (y,X)$ meaning it attempts to predict the class from the image, and then at the same time, using the same capsule reconstruct the image from the class. The approach appears very cGAN-like where the task of reconstructing better helps the model 'understand' the image data better."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K.set_image_data_format('channels_last')"
      ],
      "metadata": {
        "id": "ntVVFq6dlEWz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CapsuleNet:\n",
        "  @staticmethod\n",
        "  def build(input_shape,number_of_class,routing_count,batch_size,\n",
        "            n_channels = 32,dim_capsule=16,\n",
        "            kernels=[9],filters=[256],strides=[1]):\n",
        "    \n",
        "   \n",
        "\n",
        "   #A Capsule Network on MNIST.\n",
        "   #:param input_shape: data shape, 3d, [width, height, channels]\n",
        "   #:param n_class: number of classes\n",
        "   #:param routings: number of routing iterations\n",
        "   #:param batch_size: size of batch\n",
        "   #:return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
        "   #        `eval_model` can also be used for training.\n",
        "   \n",
        "\n",
        "   input = layers.Input(shape=input_shape, batch_size=batch_size)  \n",
        "   for index in range(len(kernels)):\n",
        "      if index == 0 :\n",
        "         conv = layers.Conv2D(filters=filters[index], \n",
        "                             kernel_size=kernels[index], \n",
        "                             strides=strides[index], \n",
        "                             padding='valid', \n",
        "                             activation='relu', \n",
        "                             name='conv'+str(index))(input)\n",
        "      else:\n",
        "         conv = layers.Conv2D(filters=filters[index], \n",
        "                             kernel_size=kernels[index], \n",
        "                             strides=strides[index], \n",
        "                             padding='valid', \n",
        "                             activation='relu', \n",
        "                             name='conv'+str(index))(conv)\n",
        "  \n",
        "    #Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "    #:param inputs: 4D tensor, shape=[None, width, height, channels]\n",
        "    #:param dim_capsule: the dim of the output vector of capsule\n",
        "    #:param n_channels: the number of types of capsules\n",
        "    #:return: output tensor, shape=[None, num_capsule, dim_capsule]\n",
        "  \n",
        "   conv_1 = layers.Conv2D(filters=dim_capsule*n_channels, \n",
        "                             kernel_size=kernels[-1], \n",
        "                             strides=strides[-1], \n",
        "                             padding='valid', \n",
        "                             activation='relu', \n",
        "                             name='primary_capsule_conv')(conv)\n",
        "    \n",
        "   conv_2 = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(conv_1)\n",
        "\n",
        "   primary_capsule = layers.Lambda(squash,name = 'primary_capsule')(conv_2)\n",
        "\n",
        "    # Capsule layer. Routing algorithm works here.\n",
        "   digitcaps = CapsuleLayer(num_capsule=number_of_class, \n",
        "                             dim_capsule=dim_capsule, \n",
        "                             routings=routing_count, \n",
        "                             name='digitcaps')(primary_capsule)\n",
        "\n",
        "    # Auxiliary layer to replace each capsule with its length.\n",
        "    # Just to match the true label's shape.\n",
        "    \n",
        "   out_caps = Length(name='capsnet')(digitcaps)\n",
        "\n",
        "    # Decoder network.\n",
        "   y = layers.Input(shape=(number_of_class,))\n",
        "   masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
        "   masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
        "\n",
        "    # Shared Decoder model in training and prediction\n",
        "   decoder = models.Sequential(name='decoder')\n",
        "   decoder.add(layers.Dense(512, activation='relu', input_dim=16 * number_of_class))\n",
        "   decoder.add(layers.Dense(1024, activation='relu'))\n",
        "   decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
        "   decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
        "\n",
        "    # Models for training and evaluation (prediction)\n",
        "   train_model = models.Model([input, y], [out_caps, decoder(masked_by_y)])\n",
        "   eval_model = models.Model(input, [out_caps, decoder(masked)])\n",
        "  \n",
        "   return train_model, eval_model"
      ],
      "metadata": {
        "id": "Jb3c5i5Zk8aA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "bc101123-d53c-4c2e-a187-101c434885da",
        "_uuid": "2497453eb1895f624ad84617dd98c230f5640304",
        "id": "HCMIciV0o8x9"
      },
      "source": [
        "\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "def CapsNet(input_shape, n_class, routings, batch_size):\n",
        "    \"\"\"\n",
        "    A Capsule Network on MNIST.\n",
        "    :param input_shape: data shape, 3d, [width, height, channels]\n",
        "    :param n_class: number of classes\n",
        "    :param routings: number of routing iterations\n",
        "    :param batch_size: size of batch\n",
        "    :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
        "            `eval_model` can also be used for training.\n",
        "    \"\"\"\n",
        "    x = layers.Input(shape=input_shape, batch_size=batch_size)\n",
        "\n",
        "    # Layer 1: Just a conventional Conv2D layer\n",
        "    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "\n",
        "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
        "    primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
        "\n",
        "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
        "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings, name='digitcaps')(primarycaps)\n",
        "\n",
        "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
        "    # If using tensorflow, this will not be necessary. :)\n",
        "    out_caps = Length(name='capsnet')(digitcaps)\n",
        "\n",
        "    # Decoder network.\n",
        "    y = layers.Input(shape=(n_class,))\n",
        "    masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
        "    masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
        "\n",
        "    # Shared Decoder model in training and prediction\n",
        "    decoder = models.Sequential(name='decoder')\n",
        "    decoder.add(layers.Dense(512, activation='relu', input_dim=16 * n_class))\n",
        "    decoder.add(layers.Dense(1024, activation='relu'))\n",
        "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
        "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
        "\n",
        "    # Models for training and evaluation (prediction)\n",
        "    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
        "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
        "\n",
        "   \n",
        "    return train_model, eval_model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "c6d84e5a-c33c-40c8-89c3-aba3454f7025",
        "_uuid": "9f27c6b0623ebffb6c8a24579f9dd4e321d6b1c2",
        "id": "LS09Ic7qo8x_"
      },
      "source": [
        "def margin_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
        "    :param y_true: [None, n_classes]\n",
        "    :param y_pred: [None, num_capsule]\n",
        "    :return: a scalar loss value.\n",
        "    \"\"\"\n",
        "    # return tf.reduce_mean(tf.square(y_pred))\n",
        "    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return tf.reduce_mean(tf.reduce_sum(L, 1))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JBMdPcyZrla"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "169b7f78-12c7-4fed-886e-60024fe59339",
        "_uuid": "02b7db879a533e7bfb3116522bebf3867b23498c",
        "id": "0zSuXAxxo8yQ"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import csv\n",
        "import math\n",
        "import pandas\n",
        "\n",
        "def combine_images(generated_images, height=None, width=None):\n",
        "    num = generated_images.shape[0]\n",
        "    if width is None and height is None:\n",
        "        width = int(math.sqrt(num))\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif width is not None and height is None:  # height not given\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif height is not None and width is None:  # width not given\n",
        "        width = int(math.ceil(float(num)/height))\n",
        "\n",
        "    shape = generated_images.shape[1:3]\n",
        "    image = np.zeros((height*shape[0], width*shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[:, :, 0]\n",
        "    return image\n",
        "\n",
        "def plot_log(filename, show=True):\n",
        "\n",
        "    data = pandas.read_csv(filename)\n",
        "\n",
        "    fig = plt.figure(figsize=(4,6))\n",
        "    fig.subplots_adjust(top=0.95, bottom=0.05, right=0.95)\n",
        "    fig.add_subplot(211)\n",
        "    for key in data.keys():\n",
        "        if key.find('loss') >= 0 and not key.find('val') >= 0:  # training loss\n",
        "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
        "    plt.legend()\n",
        "    plt.title('Training loss')\n",
        "\n",
        "    fig.add_subplot(212)\n",
        "    for key in data.keys():\n",
        "        if key.find('acc') >= 0:  # acc\n",
        "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
        "    plt.legend()\n",
        "    plt.title('Training and validation accuracy')\n",
        "\n",
        "    # fig.savefig('result/log.png')\n",
        "    if show:\n",
        "        plt.show()    \n",
        "\n",
        "def test(model, data, args):\n",
        "    x_test, y_test = data\n",
        "    y_pred, _ = model.predict(x_test)#, batch_size=args.batch_size)\n",
        "    print('-' * 30 + 'Begin: test' + '-' * 30)\n",
        "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)) / y_test.shape[0])\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train CapsNet**"
      ],
      "metadata": {
        "id": "kEL29LHiYu9X"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "e698ab37-4e74-43e6-b35b-a0507449d916",
        "_uuid": "c0374dabdf452026e3f231ffe689b5dd9f99288b",
        "id": "TZJyVmido8yK"
      },
      "source": [
        "# Train Capsule Network\n",
        "def train(model, data, args):\n",
        "    \"\"\"\n",
        "    Training a CapsuleNet\n",
        "    @param model: the CapsuleNet model\n",
        "    @param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
        "    @param args: arguments\n",
        "    return: The trained model\n",
        "    \"\"\"\n",
        "    # unpacking the data\n",
        "    (x_train, y_train), (x_test, y_test) = data\n",
        "\n",
        "    # callbacks\n",
        "    log = callbacks.CSVLogger(args.save_dir + '/log.csv')\n",
        "    checkpoint = callbacks.ModelCheckpoint(args.save_dir + '/weights.h5', monitor='val_capsnet_accuracy',\n",
        "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
        "    \n",
        "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args.lr * (args.lr_decay ** epoch))\n",
        "\n",
        "    # compile the model\n",
        "    model.compile(optimizer=optimizers.Adam(lr=args.lr),\n",
        "                  loss=[margin_loss, 'mse'],\n",
        "                  loss_weights=[1., args.lam_recon],run_eagerly=True,\n",
        "                  metrics={'capsnet': 'accuracy'})\n",
        "\n",
        "\n",
        "    # Begin: Training with data augmentation ---------------------------------------------------------------------#\n",
        "    def train_generator(x, y, batch_size, shift_fraction=0.):\n",
        "        #Default No Data Augmentation\n",
        "        train_datagen = ImageDataGenerator()  \n",
        "        generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
        "        while 1:\n",
        "            x_batch, y_batch = generator.next()\n",
        "            yield (x_batch, y_batch), (y_batch, x_batch)\n",
        "\n",
        "    # Training with data augmentation. If shift_fraction=0., no augmentation.\n",
        "    history = model.fit(train_generator(x_train, y_train, args.batch_size, args.shift_fraction),\n",
        "              steps_per_epoch=int(y_train.shape[0] / args.batch_size),\n",
        "              epochs=args.epochs,\n",
        "              validation_data=((x_test, y_test), (y_test, x_test)), batch_size=args.batch_size,\n",
        "              callbacks=[log, checkpoint, lr_decay])\n",
        "\n",
        "    \n",
        "    index = history.history[\"val_capsnet_accuracy\"].index(max(history.history[\"val_capsnet_accuracy\"]))\n",
        "    best_val_accuracy = history.history[\"val_capsnet_accuracy\"][index]    \n",
        "    print(f\"Best Validation Accuracy:{best_val_accuracy}\") \n",
        "    \n",
        "   \n",
        "    plot_log(args.save_dir + '/log.csv', show=True)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GYC0AqPieYOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "e698ab37-4e74-43e6-b35b-a0507449d916",
        "_uuid": "c0374dabdf452026e3f231ffe689b5dd9f99288b",
        "id": "6toL-30MeYpO"
      },
      "source": [
        "# Train Capsule Network\n",
        "def train(model, data, args):\n",
        "    \"\"\"\n",
        "    Training a CapsuleNet\n",
        "    @param model: the CapsuleNet model\n",
        "    @param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
        "    @param args: arguments\n",
        "    return: The trained model\n",
        "    \"\"\"\n",
        "    # unpacking the data\n",
        "    (x_train, y_train), (x_test, y_test) = data\n",
        "\n",
        "    # callbacks\n",
        "    log = callbacks.CSVLogger(args.save_dir + '/log.csv')\n",
        "    checkpoint = callbacks.ModelCheckpoint(args.save_dir + '/weights.h5', monitor='val_capsnet_accuracy',\n",
        "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
        "    \n",
        "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args.lr * (args.lr_decay ** epoch))\n",
        "\n",
        "    # compile the model\n",
        "    model.compile(optimizer=optimizers.Adam(lr=args.lr),\n",
        "                  loss=[margin_loss, 'mse'],\n",
        "                  loss_weights=[1., args.lam_recon],run_eagerly=True,\n",
        "                  metrics={'capsnet': 'accuracy'})\n",
        "\n",
        "\n",
        "    # Begin: Training with data augmentation ---------------------------------------------------------------------#\n",
        "    def train_generator(x, y, batch_size, shift_fraction=0.):\n",
        "        #Default No Data Augmentation\n",
        "        train_datagen = ImageDataGenerator()  \n",
        "        generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
        "        while 1:\n",
        "            x_batch, y_batch = generator.next()\n",
        "            yield (x_batch, y_batch), (y_batch, x_batch)\n",
        "\n",
        "    # Training with data augmentation. If shift_fraction=0., no augmentation.\n",
        "    history = model.fit(train_generator(x_train, y_train, args.batch_size, args.shift_fraction),\n",
        "              steps_per_epoch=int(y_train.shape[0] / args.batch_size),\n",
        "              epochs=args.epochs,\n",
        "              validation_data=((x_test, y_test), (y_test, x_test)), batch_size=args.batch_size,\n",
        "              callbacks=[log, checkpoint, lr_decay])\n",
        "\n",
        "    \n",
        "    index = history.history[\"val_capsnet_accuracy\"].index(max(history.history[\"val_capsnet_accuracy\"]))\n",
        "    best_val_accuracy = history.history[\"val_capsnet_accuracy\"][index]    \n",
        "    print(f\"Best Validation Accuracy:{best_val_accuracy}\") \n",
        "    \n",
        "   \n",
        "    plot_log(args.save_dir + '/log.csv', show=True)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_train_test(data,args):\n",
        "  set_seed()\n",
        "  (x_train,y_train),(x_test,y_test) = data\n",
        "  #model, eval_model = CapsNet(input_shape=x_train.shape[1:],\n",
        "  #                                                n_class=len(np.unique(np.argmax(y_train, 1))),\n",
        "  #                                                routings=args.routings,\n",
        "  #                                                batch_size=args.batch_size)\n",
        "  \n",
        "  model,eval_model = CapsuleNet.build(input_shape=x_train.shape[1:], number_of_class=len(np.unique(np.argmax(y_train, 1))),\n",
        "                                                  routing_count=args.routings,batch_size=args.batch_size )\n",
        "\n",
        "  model.summary()\n",
        "  trained_model = train(model=model, data=((x_train, y_train), (x_test, y_test)), args=args)\n",
        "  trained_model.load_weights(f'./result/weights.h5')\n",
        "  # Model Training Done\n",
        "  #Prediction and calculate the matrix value\n",
        "  y_pred,_= trained_model.predict((x_test,y_test), batch_size=x_test.shape[0])\n",
        "  print('-' * 30 + 'Begin: test' + '-' * 30)\n",
        "  print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)) / y_test.shape[0])  \n",
        " \n",
        "  result_pred = np.argmax(y_pred, axis=1) \n",
        "  result_actual = np.argmax(y_test, axis=1) \n",
        "  precision = precision_score(result_actual, result_pred)\n",
        "  recall = recall_score(result_actual, result_pred)\n",
        "  f1 = f1_score(result_actual, result_pred)\n",
        "  tn, fp, fn, tp = confusion_matrix(result_actual, result_pred).ravel()\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(result_actual, result_pred)\n",
        "  auc = metrics.auc(fpr, tpr)\n",
        "  \n",
        "  print(f\"Precision:{precision}\")\n",
        "  print(f\"recall:{recall}\")\n",
        "  print(f\"f1:{f1}\")\n",
        "  print(f\"AUC:{auc}\")\n",
        "  print(f\"Sensitivity:{tp/(tp+fn)}\")\n",
        "  print(f\"specificity:{tn/(tn+fp)}\")\n"
      ],
      "metadata": {
        "id": "DaOxiCiiW5fQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EKbfeEhiYkr",
        "outputId": "fce8f29b-05c0-462e-d9d4-7fb74fe69673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"Capsule Network Glaucoma Classification.\")\n",
        "parser.add_argument('--epochs', default=15, type=int)\n",
        "parser.add_argument('--batch_size', default=32, type=int)\n",
        "parser.add_argument('--lr', default=0.0001, type=float,\n",
        "                        help=\"Initial learning rate\")\n",
        "parser.add_argument('--lr_decay', default=1, type=float,\n",
        "                        help=\"The value multiplied by lr at each epoch. Set a larger value for larger epochs\")\n",
        "parser.add_argument('--lam_recon', default=0.392, type=float,\n",
        "                        help=\"The coefficient for the loss of decoder\")\n",
        "parser.add_argument('-r', '--routings', default=1, type=int,\n",
        "                        help=\"Number of iterations used in routing algorithm. should > 0\")\n",
        "parser.add_argument('--shift_fraction', default=0.1, type=float,\n",
        "                        help=\"Fraction of pixels to shift at most in each direction.\")\n",
        "parser.add_argument('--debug', action='store_true',\n",
        "                        help=\"Save weights by TensorBoard\")\n",
        "parser.add_argument('--save_dir', default='./result')\n",
        "parser.add_argument('-t', '--testing', action='store_true',\n",
        "                        help=\"Test the trained model on testing dataset\")\n",
        "parser.add_argument('--digit', default=5, type=int,\n",
        "                        help=\"Digit to manipulate\")\n",
        "parser.add_argument('-w', '--weights', default=None,\n",
        "                        help=\"The path of the saved weights. Should be specified when testing\")\n",
        "args, unknown = parser.parse_known_args()\n",
        "print(args)\n",
        "\n",
        "if not os.path.exists(args.save_dir):\n",
        "    os.makedirs(args.save_dir)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=32, debug=False, digit=5, epochs=15, lam_recon=0.392, lr=0.0001, lr_decay=1, routings=1, save_dir='./result', shift_fraction=0.1, testing=False, weights=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Public Dataset**"
      ],
      "metadata": {
        "id": "pyoKrohAY3Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVhC0mWybBFf",
        "outputId": "2f60fae9-b5ac-4d3d-a78e-96bb2ce85c6d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Path**"
      ],
      "metadata": {
        "id": "GeUCh794pb2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RIM_ONE_DL_DIR = '/content/gdrive/My Drive/MSC_Project/Dataset/RIM-ONE_DL_images/partitioned_randomly'\n",
        "RIM_ONE_R2_DIR = '/content/gdrive/My Drive/MSC_Project/Dataset/RIMONE-db-r2'\n",
        "ACRIMA_DIR = '/content/gdrive/My Drive/MSC_Project/Dataset/ACRIMA'"
      ],
      "metadata": {
        "id": "99C4kIlhbJdD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Standard Image Size**"
      ],
      "metadata": {
        "id": "gITa5bV2pfE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HEIGHT= 64\n",
        "WIDTH = 64\n"
      ],
      "metadata": {
        "id": "kv4_0aYMbNC_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Images, Resize and convert to numpy array**"
      ],
      "metadata": {
        "id": "1Vn9uC8apnmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize image to HEIGHT*WIDTH\n",
        "# Convert to numpy array\n",
        "def process_image(data_set_dir, label_dict, width,height):\n",
        "    \n",
        "    x = [] # will store images as arrays\n",
        "    y = [] # store labels\n",
        "    # list folders in directory\n",
        "    directories = os.listdir(data_set_dir)\n",
        "     \n",
        "    # for each folder (train and validation) \n",
        "    for label in directories:\n",
        "        \n",
        "        # add class label to label dictionary\n",
        "        if label not in label_dict:\n",
        "            label_dict[label] = len(label_dict)\n",
        "        \n",
        "        # create full path for image directory \n",
        "        source_images = os.path.join(data_set_dir, label)\n",
        "        images = os.listdir(source_images)\n",
        "        # for each image in directory, \n",
        "        for image in images:\n",
        "            #folder have .txt files which needs to be ignored\n",
        "            if '.txt'not in image:\n",
        "                # read the image from file, resize and add to a list\n",
        "                full_size_image = cv2.imread(os.path.join(source_images, image))\n",
        "                #gray_image = cv2.cvtColor(full_size_image, cv2.COLOR_BGR2GRAY)\n",
        "                \n",
        "                #append the image to x\n",
        "                x.append(cv2.resize(full_size_image, (width,height), \n",
        "                                                            interpolation=cv2.INTER_CUBIC))\n",
        "                # add the class label to y\n",
        "                y.append(label)\n",
        "\n",
        "    data = np.array(x, dtype=\"float\") / 255.0                \n",
        "    label = np.array(y)\n",
        "    \n",
        "    return data,label"
      ],
      "metadata": {
        "id": "RwbtEuh3bQXF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and return test tarin data"
      ],
      "metadata": {
        "id": "bpAn6P3Ip3Ao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*RIMONE_DL*"
      ],
      "metadata": {
        "id": "QSSVMNvqp8Ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rim_one_dl():\n",
        "  class_labels = {}\n",
        "  training_images,training_labels = process_image(RIM_ONE_DL_DIR+\"/training_set\",\n",
        "                                                  class_labels,\n",
        "                                                  WIDTH,HEIGHT)\n",
        "  \n",
        "  training_label = (pd.Series(training_labels).map(class_labels)).values\n",
        "  training_label = to_categorical(training_label.astype('float32'))\n",
        "  training_images = training_images.reshape(-1, WIDTH, WIDTH, 3).astype('float32')\n",
        "\n",
        "  test_images,test_labels = process_image(RIM_ONE_DL_DIR+\"/test_set\",\n",
        "                                          class_labels,\n",
        "                                          WIDTH,HEIGHT)\n",
        "  test_label = (pd.Series(test_labels).map(class_labels)).values\n",
        "  test_label = to_categorical(test_label.astype('float32'))\n",
        "  test_images = test_images.reshape(-1, WIDTH, WIDTH, 3).astype('float32')\n",
        "\n",
        "  return (training_images,training_label),(test_images,test_label)"
      ],
      "metadata": {
        "id": "WYYvphuBabld"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*RIMONE_V2*"
      ],
      "metadata": {
        "id": "c5yfRqbSp_DS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rim_one_db_r2(test_train_ratio = 0.2):\n",
        "  \n",
        "  class_labels = {}\n",
        "  training_images,training_labels = process_image(RIM_ONE_R2_DIR,\n",
        "                                                  class_labels,\n",
        "                                                  WIDTH,HEIGHT)\n",
        "  \n",
        "  training_label = (pd.Series(training_labels).map(class_labels)).values\n",
        "  training_label = to_categorical(training_label.astype('float32'))\n",
        "  training_images = training_images.reshape(-1, WIDTH, WIDTH, 3).astype('float32')\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(training_images, \n",
        "                                                      training_label, \n",
        "                                                      test_size=test_train_ratio, \n",
        "                                                      random_state=100)\n",
        "\n",
        "  return (X_train,y_train),(X_test,y_test)"
      ],
      "metadata": {
        "id": "aI44L23fgLGf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*ACRIMA*"
      ],
      "metadata": {
        "id": "Y6HCZNiAqBqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_acrima_dataset(test_train_ratio = 0.2):\n",
        "  class_labels = {}\n",
        "  training_images,training_labels = process_image(ACRIMA_DIR,\n",
        "                                                  class_labels,\n",
        "                                                  WIDTH,HEIGHT)\n",
        "  \n",
        "  training_label = (pd.Series(training_labels).map(class_labels)).values\n",
        "  training_label = to_categorical(training_label.astype('float32'))\n",
        "  training_images = training_images.reshape(-1, WIDTH, WIDTH, 3).astype('float32')\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(training_images, \n",
        "                                                      training_label, \n",
        "                                                      test_size=test_train_ratio, \n",
        "                                                      random_state=100)\n",
        "\n",
        "  return (X_train,y_train),(X_test,y_test)"
      ],
      "metadata": {
        "id": "iU4ArbgNZBKZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train and Predict**"
      ],
      "metadata": {
        "id": "csMM_UCtvjQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RIM-ONE R2"
      ],
      "metadata": {
        "id": "ni7ifR9rvoAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args.batch_size = 32\n",
        "args.epochs = 100\n",
        "args.routings = 8\n",
        "data = get_rim_one_db_r2()\n",
        "get_model_train_test(data,args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GECoDk0NqCFG",
        "outputId": "9dcaf985-f8b4-4468-debf-019a5509a669"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(32, 64, 64, 3)]    0           []                               \n",
            "                                                                                                  \n",
            " conv0 (Conv2D)                 (32, 56, 56, 256)    62464       ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " primary_capsule_conv (Conv2D)  (32, 48, 48, 512)    10617344    ['conv0[0][0]']                  \n",
            "                                                                                                  \n",
            " primarycap_reshape (Reshape)   (32, 73728, 16)      0           ['primary_capsule_conv[0][0]']   \n",
            "                                                                                                  \n",
            " primary_capsule (Lambda)       (32, 73728, 16)      0           ['primarycap_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " digitcaps (CapsuleLayer)       (32, 2, 16)          37748736    ['primary_capsule[0][0]']        \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " mask_4 (Mask)                  (32, 32)             0           ['digitcaps[0][0]',              \n",
            "                                                                  'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " capsnet (Length)               (32, 2)              0           ['digitcaps[0][0]']              \n",
            "                                                                                                  \n",
            " decoder (Sequential)           (None, 64, 64, 3)    13137408    ['mask_4[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 61,565,952\n",
            "Trainable params: 61,565,952\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - ETA: 0s - loss: 0.3788 - capsnet_loss: 0.3518 - decoder_loss: 0.0688 - capsnet_accuracy: 0.5341\n",
            "Epoch 1: val_capsnet_accuracy improved from -inf to 0.45652, saving model to ./result/weights.h5\n",
            "11/11 [==============================] - 13s 1s/step - loss: 0.3788 - capsnet_loss: 0.3518 - decoder_loss: 0.0688 - capsnet_accuracy: 0.5341 - val_loss: 0.2604 - val_capsnet_loss: 0.2346 - val_decoder_loss: 0.0660 - val_capsnet_accuracy: 0.4565 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2566 - capsnet_loss: 0.2299 - decoder_loss: 0.0681 - capsnet_accuracy: 0.5863\n",
            "Epoch 2: val_capsnet_accuracy improved from 0.45652 to 0.54348, saving model to ./result/weights.h5\n",
            "11/11 [==============================] - 14s 988ms/step - loss: 0.2566 - capsnet_loss: 0.2299 - decoder_loss: 0.0681 - capsnet_accuracy: 0.5863 - val_loss: 0.2639 - val_capsnet_loss: 0.2381 - val_decoder_loss: 0.0657 - val_capsnet_accuracy: 0.5435 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2622 - capsnet_loss: 0.2354 - decoder_loss: 0.0683 - capsnet_accuracy: 0.5000\n",
            "Epoch 3: val_capsnet_accuracy improved from 0.54348 to 0.55435, saving model to ./result/weights.h5\n",
            "11/11 [==============================] - 11s 965ms/step - loss: 0.2622 - capsnet_loss: 0.2354 - decoder_loss: 0.0683 - capsnet_accuracy: 0.5000 - val_loss: 0.2529 - val_capsnet_loss: 0.2272 - val_decoder_loss: 0.0655 - val_capsnet_accuracy: 0.5543 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2598 - capsnet_loss: 0.2331 - decoder_loss: 0.0682 - capsnet_accuracy: 0.6071\n",
            "Epoch 4: val_capsnet_accuracy improved from 0.55435 to 0.58696, saving model to ./result/weights.h5\n",
            "11/11 [==============================] - 11s 970ms/step - loss: 0.2598 - capsnet_loss: 0.2331 - decoder_loss: 0.0682 - capsnet_accuracy: 0.6071 - val_loss: 0.2526 - val_capsnet_loss: 0.2271 - val_decoder_loss: 0.0648 - val_capsnet_accuracy: 0.5870 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2333 - capsnet_loss: 0.2071 - decoder_loss: 0.0668 - capsnet_accuracy: 0.6577\n",
            "Epoch 5: val_capsnet_accuracy improved from 0.58696 to 0.72826, saving model to ./result/weights.h5\n",
            "11/11 [==============================] - 11s 969ms/step - loss: 0.2333 - capsnet_loss: 0.2071 - decoder_loss: 0.0668 - capsnet_accuracy: 0.6577 - val_loss: 0.2261 - val_capsnet_loss: 0.2010 - val_decoder_loss: 0.0641 - val_capsnet_accuracy: 0.7283 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.2263 - capsnet_loss: 0.2004 - decoder_loss: 0.0661 - capsnet_accuracy: 0.6875\n",
            "Epoch 6: val_capsnet_accuracy did not improve from 0.72826\n",
            "11/11 [==============================] - 10s 929ms/step - loss: 0.2263 - capsnet_loss: 0.2004 - decoder_loss: 0.0661 - capsnet_accuracy: 0.6875 - val_loss: 0.2058 - val_capsnet_loss: 0.1813 - val_decoder_loss: 0.0626 - val_capsnet_accuracy: 0.6522 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1873 - capsnet_loss: 0.1624 - decoder_loss: 0.0633 - capsnet_accuracy: 0.7589\n",
            "Epoch 7: val_capsnet_accuracy improved from 0.72826 to 0.76087, saving model to ./result/weights.h5\n",
            "11/11 [==============================] - 13s 1s/step - loss: 0.1873 - capsnet_loss: 0.1624 - decoder_loss: 0.0633 - capsnet_accuracy: 0.7589 - val_loss: 0.2035 - val_capsnet_loss: 0.1800 - val_decoder_loss: 0.0598 - val_capsnet_accuracy: 0.7609 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1900 - capsnet_loss: 0.1663 - decoder_loss: 0.0605 - capsnet_accuracy: 0.7500\n",
            "Epoch 8: val_capsnet_accuracy improved from 0.76087 to 0.77174, saving model to ./result/weights.h5\n",
            "11/11 [==============================] - 11s 979ms/step - loss: 0.1900 - capsnet_loss: 0.1663 - decoder_loss: 0.0605 - capsnet_accuracy: 0.7500 - val_loss: 0.1835 - val_capsnet_loss: 0.1622 - val_decoder_loss: 0.0544 - val_capsnet_accuracy: 0.7717 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1693 - capsnet_loss: 0.1485 - decoder_loss: 0.0531 - capsnet_accuracy: 0.8006\n",
            "Epoch 9: val_capsnet_accuracy did not improve from 0.77174\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.1693 - capsnet_loss: 0.1485 - decoder_loss: 0.0531 - capsnet_accuracy: 0.8006 - val_loss: 0.1866 - val_capsnet_loss: 0.1681 - val_decoder_loss: 0.0474 - val_capsnet_accuracy: 0.7609 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1667 - capsnet_loss: 0.1499 - decoder_loss: 0.0431 - capsnet_accuracy: 0.7798\n",
            "Epoch 10: val_capsnet_accuracy did not improve from 0.77174\n",
            "11/11 [==============================] - 10s 936ms/step - loss: 0.1667 - capsnet_loss: 0.1499 - decoder_loss: 0.0431 - capsnet_accuracy: 0.7798 - val_loss: 0.1745 - val_capsnet_loss: 0.1610 - val_decoder_loss: 0.0343 - val_capsnet_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1564 - capsnet_loss: 0.1447 - decoder_loss: 0.0299 - capsnet_accuracy: 0.7649\n",
            "Epoch 11: val_capsnet_accuracy did not improve from 0.77174\n",
            "11/11 [==============================] - 11s 998ms/step - loss: 0.1564 - capsnet_loss: 0.1447 - decoder_loss: 0.0299 - capsnet_accuracy: 0.7649 - val_loss: 0.1722 - val_capsnet_loss: 0.1641 - val_decoder_loss: 0.0208 - val_capsnet_accuracy: 0.6957 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1447 - capsnet_loss: 0.1375 - decoder_loss: 0.0181 - capsnet_accuracy: 0.8036\n",
            "Epoch 12: val_capsnet_accuracy did not improve from 0.77174\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.1447 - capsnet_loss: 0.1375 - decoder_loss: 0.0181 - capsnet_accuracy: 0.8036 - val_loss: 0.1659 - val_capsnet_loss: 0.1606 - val_decoder_loss: 0.0135 - val_capsnet_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1278 - capsnet_loss: 0.1229 - decoder_loss: 0.0124 - capsnet_accuracy: 0.8210\n",
            "Epoch 13: val_capsnet_accuracy did not improve from 0.77174\n",
            "11/11 [==============================] - 11s 978ms/step - loss: 0.1278 - capsnet_loss: 0.1229 - decoder_loss: 0.0124 - capsnet_accuracy: 0.8210 - val_loss: 0.1604 - val_capsnet_loss: 0.1563 - val_decoder_loss: 0.0106 - val_capsnet_accuracy: 0.7717 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1195 - capsnet_loss: 0.1154 - decoder_loss: 0.0107 - capsnet_accuracy: 0.8363\n",
            "Epoch 14: val_capsnet_accuracy improved from 0.77174 to 0.81522, saving model to ./result/weights.h5\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.1195 - capsnet_loss: 0.1154 - decoder_loss: 0.0107 - capsnet_accuracy: 0.8363 - val_loss: 0.1558 - val_capsnet_loss: 0.1517 - val_decoder_loss: 0.0104 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1093 - capsnet_loss: 0.1053 - decoder_loss: 0.0101 - capsnet_accuracy: 0.8423\n",
            "Epoch 15: val_capsnet_accuracy did not improve from 0.81522\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.1093 - capsnet_loss: 0.1053 - decoder_loss: 0.0101 - capsnet_accuracy: 0.8423 - val_loss: 0.1622 - val_capsnet_loss: 0.1581 - val_decoder_loss: 0.0105 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1058 - capsnet_loss: 0.1019 - decoder_loss: 0.0098 - capsnet_accuracy: 0.8512\n",
            "Epoch 16: val_capsnet_accuracy did not improve from 0.81522\n",
            "11/11 [==============================] - 10s 939ms/step - loss: 0.1058 - capsnet_loss: 0.1019 - decoder_loss: 0.0098 - capsnet_accuracy: 0.8512 - val_loss: 0.1484 - val_capsnet_loss: 0.1447 - val_decoder_loss: 0.0095 - val_capsnet_accuracy: 0.7717 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1050 - capsnet_loss: 0.1013 - decoder_loss: 0.0092 - capsnet_accuracy: 0.8571\n",
            "Epoch 17: val_capsnet_accuracy did not improve from 0.81522\n",
            "11/11 [==============================] - 10s 938ms/step - loss: 0.1050 - capsnet_loss: 0.1013 - decoder_loss: 0.0092 - capsnet_accuracy: 0.8571 - val_loss: 0.1440 - val_capsnet_loss: 0.1404 - val_decoder_loss: 0.0092 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1053 - capsnet_loss: 0.1012 - decoder_loss: 0.0103 - capsnet_accuracy: 0.8571\n",
            "Epoch 18: val_capsnet_accuracy did not improve from 0.81522\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.1053 - capsnet_loss: 0.1012 - decoder_loss: 0.0103 - capsnet_accuracy: 0.8571 - val_loss: 0.1502 - val_capsnet_loss: 0.1465 - val_decoder_loss: 0.0095 - val_capsnet_accuracy: 0.7717 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1141 - capsnet_loss: 0.1102 - decoder_loss: 0.0099 - capsnet_accuracy: 0.8482\n",
            "Epoch 19: val_capsnet_accuracy did not improve from 0.81522\n",
            "11/11 [==============================] - 10s 939ms/step - loss: 0.1141 - capsnet_loss: 0.1102 - decoder_loss: 0.0099 - capsnet_accuracy: 0.8482 - val_loss: 0.1456 - val_capsnet_loss: 0.1419 - val_decoder_loss: 0.0094 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.1116 - capsnet_loss: 0.1080 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8393\n",
            "Epoch 20: val_capsnet_accuracy did not improve from 0.81522\n",
            "11/11 [==============================] - 11s 999ms/step - loss: 0.1116 - capsnet_loss: 0.1080 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8393 - val_loss: 0.1659 - val_capsnet_loss: 0.1622 - val_decoder_loss: 0.0095 - val_capsnet_accuracy: 0.7391 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0986 - capsnet_loss: 0.0949 - decoder_loss: 0.0096 - capsnet_accuracy: 0.8542\n",
            "Epoch 21: val_capsnet_accuracy did not improve from 0.81522\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0986 - capsnet_loss: 0.0949 - decoder_loss: 0.0096 - capsnet_accuracy: 0.8542 - val_loss: 0.1509 - val_capsnet_loss: 0.1470 - val_decoder_loss: 0.0100 - val_capsnet_accuracy: 0.7717 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0803 - capsnet_loss: 0.0767 - decoder_loss: 0.0092 - capsnet_accuracy: 0.8958\n",
            "Epoch 22: val_capsnet_accuracy did not improve from 0.81522\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0803 - capsnet_loss: 0.0767 - decoder_loss: 0.0092 - capsnet_accuracy: 0.8958 - val_loss: 0.1421 - val_capsnet_loss: 0.1385 - val_decoder_loss: 0.0093 - val_capsnet_accuracy: 0.7935 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0832 - capsnet_loss: 0.0795 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8958\n",
            "Epoch 23: val_capsnet_accuracy did not improve from 0.81522\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0832 - capsnet_loss: 0.0795 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8958 - val_loss: 0.1387 - val_capsnet_loss: 0.1353 - val_decoder_loss: 0.0088 - val_capsnet_accuracy: 0.7935 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0929 - capsnet_loss: 0.0892 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8780\n",
            "Epoch 24: val_capsnet_accuracy did not improve from 0.81522\n",
            "11/11 [==============================] - 10s 941ms/step - loss: 0.0929 - capsnet_loss: 0.0892 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8780 - val_loss: 0.1401 - val_capsnet_loss: 0.1364 - val_decoder_loss: 0.0094 - val_capsnet_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0829 - capsnet_loss: 0.0794 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8807\n",
            "Epoch 25: val_capsnet_accuracy did not improve from 0.81522\n",
            "11/11 [==============================] - 11s 983ms/step - loss: 0.0829 - capsnet_loss: 0.0794 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8807 - val_loss: 0.1509 - val_capsnet_loss: 0.1471 - val_decoder_loss: 0.0098 - val_capsnet_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0873 - capsnet_loss: 0.0836 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8869\n",
            "Epoch 26: val_capsnet_accuracy did not improve from 0.81522\n",
            "11/11 [==============================] - 10s 992ms/step - loss: 0.0873 - capsnet_loss: 0.0836 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8869 - val_loss: 0.1361 - val_capsnet_loss: 0.1325 - val_decoder_loss: 0.0091 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0882 - capsnet_loss: 0.0845 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8869\n",
            "Epoch 27: val_capsnet_accuracy did not improve from 0.81522\n",
            "11/11 [==============================] - 10s 944ms/step - loss: 0.0882 - capsnet_loss: 0.0845 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8869 - val_loss: 0.1491 - val_capsnet_loss: 0.1453 - val_decoder_loss: 0.0099 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0888 - capsnet_loss: 0.0853 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8631\n",
            "Epoch 28: val_capsnet_accuracy did not improve from 0.81522\n",
            "11/11 [==============================] - 10s 948ms/step - loss: 0.0888 - capsnet_loss: 0.0853 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8631 - val_loss: 0.1375 - val_capsnet_loss: 0.1338 - val_decoder_loss: 0.0094 - val_capsnet_accuracy: 0.7935 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0735 - capsnet_loss: 0.0699 - decoder_loss: 0.0094 - capsnet_accuracy: 0.9048\n",
            "Epoch 29: val_capsnet_accuracy improved from 0.81522 to 0.82609, saving model to ./result/weights.h5\n",
            "11/11 [==============================] - 11s 998ms/step - loss: 0.0735 - capsnet_loss: 0.0699 - decoder_loss: 0.0094 - capsnet_accuracy: 0.9048 - val_loss: 0.1295 - val_capsnet_loss: 0.1259 - val_decoder_loss: 0.0092 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0672 - capsnet_loss: 0.0638 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9077\n",
            "Epoch 30: val_capsnet_accuracy did not improve from 0.82609\n",
            "11/11 [==============================] - 10s 945ms/step - loss: 0.0672 - capsnet_loss: 0.0638 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9077 - val_loss: 0.1297 - val_capsnet_loss: 0.1262 - val_decoder_loss: 0.0090 - val_capsnet_accuracy: 0.7935 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0802 - capsnet_loss: 0.0766 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8839\n",
            "Epoch 31: val_capsnet_accuracy did not improve from 0.82609\n",
            "11/11 [==============================] - 10s 948ms/step - loss: 0.0802 - capsnet_loss: 0.0766 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8839 - val_loss: 0.1482 - val_capsnet_loss: 0.1443 - val_decoder_loss: 0.0098 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0669 - capsnet_loss: 0.0632 - decoder_loss: 0.0096 - capsnet_accuracy: 0.9256\n",
            "Epoch 32: val_capsnet_accuracy did not improve from 0.82609\n",
            "11/11 [==============================] - 10s 948ms/step - loss: 0.0669 - capsnet_loss: 0.0632 - decoder_loss: 0.0096 - capsnet_accuracy: 0.9256 - val_loss: 0.1381 - val_capsnet_loss: 0.1346 - val_decoder_loss: 0.0089 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0686 - capsnet_loss: 0.0652 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9196\n",
            "Epoch 33: val_capsnet_accuracy did not improve from 0.82609\n",
            "11/11 [==============================] - 10s 942ms/step - loss: 0.0686 - capsnet_loss: 0.0652 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9196 - val_loss: 0.1264 - val_capsnet_loss: 0.1228 - val_decoder_loss: 0.0092 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0758 - capsnet_loss: 0.0724 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9077\n",
            "Epoch 34: val_capsnet_accuracy did not improve from 0.82609\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0758 - capsnet_loss: 0.0724 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9077 - val_loss: 0.1314 - val_capsnet_loss: 0.1279 - val_decoder_loss: 0.0089 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0639 - capsnet_loss: 0.0604 - decoder_loss: 0.0089 - capsnet_accuracy: 0.9315\n",
            "Epoch 35: val_capsnet_accuracy did not improve from 0.82609\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0639 - capsnet_loss: 0.0604 - decoder_loss: 0.0089 - capsnet_accuracy: 0.9315 - val_loss: 0.1292 - val_capsnet_loss: 0.1257 - val_decoder_loss: 0.0089 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0663 - capsnet_loss: 0.0629 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9077\n",
            "Epoch 36: val_capsnet_accuracy did not improve from 0.82609\n",
            "11/11 [==============================] - 10s 945ms/step - loss: 0.0663 - capsnet_loss: 0.0629 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9077 - val_loss: 0.1379 - val_capsnet_loss: 0.1343 - val_decoder_loss: 0.0093 - val_capsnet_accuracy: 0.7935 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0586 - capsnet_loss: 0.0551 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9261\n",
            "Epoch 37: val_capsnet_accuracy improved from 0.82609 to 0.83696, saving model to ./result/weights.h5\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0586 - capsnet_loss: 0.0551 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9261 - val_loss: 0.1268 - val_capsnet_loss: 0.1233 - val_decoder_loss: 0.0091 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0669 - capsnet_loss: 0.0636 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9107\n",
            "Epoch 38: val_capsnet_accuracy did not improve from 0.83696\n",
            "11/11 [==============================] - 10s 992ms/step - loss: 0.0669 - capsnet_loss: 0.0636 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9107 - val_loss: 0.1315 - val_capsnet_loss: 0.1280 - val_decoder_loss: 0.0090 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0540 - capsnet_loss: 0.0506 - decoder_loss: 0.0089 - capsnet_accuracy: 0.9435\n",
            "Epoch 39: val_capsnet_accuracy improved from 0.83696 to 0.84783, saving model to ./result/weights.h5\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0540 - capsnet_loss: 0.0506 - decoder_loss: 0.0089 - capsnet_accuracy: 0.9435 - val_loss: 0.1339 - val_capsnet_loss: 0.1303 - val_decoder_loss: 0.0092 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0570 - capsnet_loss: 0.0536 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9375\n",
            "Epoch 40: val_capsnet_accuracy did not improve from 0.84783\n",
            "11/11 [==============================] - 10s 945ms/step - loss: 0.0570 - capsnet_loss: 0.0536 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9375 - val_loss: 0.1336 - val_capsnet_loss: 0.1300 - val_decoder_loss: 0.0090 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0474 - capsnet_loss: 0.0440 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9583\n",
            "Epoch 41: val_capsnet_accuracy did not improve from 0.84783\n",
            "11/11 [==============================] - 10s 946ms/step - loss: 0.0474 - capsnet_loss: 0.0440 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9583 - val_loss: 0.1278 - val_capsnet_loss: 0.1244 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0578 - capsnet_loss: 0.0545 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9435\n",
            "Epoch 42: val_capsnet_accuracy did not improve from 0.84783\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0578 - capsnet_loss: 0.0545 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9435 - val_loss: 0.1233 - val_capsnet_loss: 0.1200 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0558 - capsnet_loss: 0.0524 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9226\n",
            "Epoch 43: val_capsnet_accuracy did not improve from 0.84783\n",
            "11/11 [==============================] - 10s 945ms/step - loss: 0.0558 - capsnet_loss: 0.0524 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9226 - val_loss: 0.1275 - val_capsnet_loss: 0.1240 - val_decoder_loss: 0.0089 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0442 - capsnet_loss: 0.0410 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9554\n",
            "Epoch 44: val_capsnet_accuracy did not improve from 0.84783\n",
            "11/11 [==============================] - 10s 943ms/step - loss: 0.0442 - capsnet_loss: 0.0410 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9554 - val_loss: 0.1304 - val_capsnet_loss: 0.1269 - val_decoder_loss: 0.0089 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0463 - capsnet_loss: 0.0430 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9494\n",
            "Epoch 45: val_capsnet_accuracy did not improve from 0.84783\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0463 - capsnet_loss: 0.0430 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9494 - val_loss: 0.1222 - val_capsnet_loss: 0.1189 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0475 - capsnet_loss: 0.0443 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9464\n",
            "Epoch 46: val_capsnet_accuracy did not improve from 0.84783\n",
            "11/11 [==============================] - 10s 947ms/step - loss: 0.0475 - capsnet_loss: 0.0443 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9464 - val_loss: 0.1304 - val_capsnet_loss: 0.1270 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0409 - capsnet_loss: 0.0376 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9643\n",
            "Epoch 47: val_capsnet_accuracy improved from 0.84783 to 0.85870, saving model to ./result/weights.h5\n",
            "11/11 [==============================] - 11s 987ms/step - loss: 0.0409 - capsnet_loss: 0.0376 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9643 - val_loss: 0.1268 - val_capsnet_loss: 0.1234 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0438 - capsnet_loss: 0.0406 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9435\n",
            "Epoch 48: val_capsnet_accuracy did not improve from 0.85870\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0438 - capsnet_loss: 0.0406 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9435 - val_loss: 0.1284 - val_capsnet_loss: 0.1250 - val_decoder_loss: 0.0089 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0399 - capsnet_loss: 0.0367 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9602\n",
            "Epoch 49: val_capsnet_accuracy did not improve from 0.85870\n",
            "11/11 [==============================] - 11s 989ms/step - loss: 0.0399 - capsnet_loss: 0.0367 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9602 - val_loss: 0.1278 - val_capsnet_loss: 0.1245 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0416 - capsnet_loss: 0.0383 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9554\n",
            "Epoch 50: val_capsnet_accuracy did not improve from 0.85870\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0416 - capsnet_loss: 0.0383 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9554 - val_loss: 0.1251 - val_capsnet_loss: 0.1218 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0416 - capsnet_loss: 0.0383 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9524\n",
            "Epoch 51: val_capsnet_accuracy did not improve from 0.85870\n",
            "11/11 [==============================] - 10s 942ms/step - loss: 0.0416 - capsnet_loss: 0.0383 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9524 - val_loss: 0.1367 - val_capsnet_loss: 0.1332 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0395 - capsnet_loss: 0.0363 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9643\n",
            "Epoch 52: val_capsnet_accuracy did not improve from 0.85870\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0395 - capsnet_loss: 0.0363 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9643 - val_loss: 0.1274 - val_capsnet_loss: 0.1240 - val_decoder_loss: 0.0088 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0342 - capsnet_loss: 0.0309 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9702\n",
            "Epoch 53: val_capsnet_accuracy did not improve from 0.85870\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0342 - capsnet_loss: 0.0309 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9702 - val_loss: 0.1256 - val_capsnet_loss: 0.1222 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0344 - capsnet_loss: 0.0313 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9613\n",
            "Epoch 54: val_capsnet_accuracy did not improve from 0.85870\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0344 - capsnet_loss: 0.0313 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9613 - val_loss: 0.1378 - val_capsnet_loss: 0.1343 - val_decoder_loss: 0.0090 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0388 - capsnet_loss: 0.0356 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9613\n",
            "Epoch 55: val_capsnet_accuracy did not improve from 0.85870\n",
            "11/11 [==============================] - 10s 949ms/step - loss: 0.0388 - capsnet_loss: 0.0356 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9613 - val_loss: 0.1196 - val_capsnet_loss: 0.1164 - val_decoder_loss: 0.0082 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0324 - capsnet_loss: 0.0290 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9613\n",
            "Epoch 56: val_capsnet_accuracy did not improve from 0.85870\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0324 - capsnet_loss: 0.0290 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9613 - val_loss: 0.1252 - val_capsnet_loss: 0.1218 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0292 - capsnet_loss: 0.0260 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9673\n",
            "Epoch 57: val_capsnet_accuracy did not improve from 0.85870\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0292 - capsnet_loss: 0.0260 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9673 - val_loss: 0.1254 - val_capsnet_loss: 0.1220 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0305 - capsnet_loss: 0.0273 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9821\n",
            "Epoch 58: val_capsnet_accuracy did not improve from 0.85870\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0305 - capsnet_loss: 0.0273 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9821 - val_loss: 0.1289 - val_capsnet_loss: 0.1254 - val_decoder_loss: 0.0089 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0310 - capsnet_loss: 0.0279 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9673\n",
            "Epoch 59: val_capsnet_accuracy did not improve from 0.85870\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0310 - capsnet_loss: 0.0279 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9673 - val_loss: 0.1228 - val_capsnet_loss: 0.1195 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0275 - capsnet_loss: 0.0243 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9673\n",
            "Epoch 60: val_capsnet_accuracy did not improve from 0.85870\n",
            "11/11 [==============================] - 10s 948ms/step - loss: 0.0275 - capsnet_loss: 0.0243 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9673 - val_loss: 0.1209 - val_capsnet_loss: 0.1176 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0253 - capsnet_loss: 0.0222 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9773\n",
            "Epoch 61: val_capsnet_accuracy did not improve from 0.85870\n",
            "11/11 [==============================] - 11s 983ms/step - loss: 0.0253 - capsnet_loss: 0.0222 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9773 - val_loss: 0.1206 - val_capsnet_loss: 0.1173 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0263 - capsnet_loss: 0.0231 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9732\n",
            "Epoch 62: val_capsnet_accuracy improved from 0.85870 to 0.86957, saving model to ./result/weights.h5\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0263 - capsnet_loss: 0.0231 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9732 - val_loss: 0.1173 - val_capsnet_loss: 0.1140 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0201 - capsnet_loss: 0.0171 - decoder_loss: 0.0077 - capsnet_accuracy: 0.9821\n",
            "Epoch 63: val_capsnet_accuracy did not improve from 0.86957\n",
            "11/11 [==============================] - 10s 950ms/step - loss: 0.0201 - capsnet_loss: 0.0171 - decoder_loss: 0.0077 - capsnet_accuracy: 0.9821 - val_loss: 0.1230 - val_capsnet_loss: 0.1197 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0271 - capsnet_loss: 0.0238 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9792\n",
            "Epoch 64: val_capsnet_accuracy did not improve from 0.86957\n",
            "11/11 [==============================] - 10s 944ms/step - loss: 0.0271 - capsnet_loss: 0.0238 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9792 - val_loss: 0.1206 - val_capsnet_loss: 0.1174 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0236 - capsnet_loss: 0.0205 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9792\n",
            "Epoch 65: val_capsnet_accuracy did not improve from 0.86957\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0236 - capsnet_loss: 0.0205 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9792 - val_loss: 0.1202 - val_capsnet_loss: 0.1171 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0231 - capsnet_loss: 0.0199 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9732\n",
            "Epoch 66: val_capsnet_accuracy did not improve from 0.86957\n",
            "11/11 [==============================] - 10s 944ms/step - loss: 0.0231 - capsnet_loss: 0.0199 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9732 - val_loss: 0.1202 - val_capsnet_loss: 0.1168 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0209 - capsnet_loss: 0.0177 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9792\n",
            "Epoch 67: val_capsnet_accuracy improved from 0.86957 to 0.88043, saving model to ./result/weights.h5\n",
            "11/11 [==============================] - 11s 992ms/step - loss: 0.0209 - capsnet_loss: 0.0177 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9792 - val_loss: 0.1206 - val_capsnet_loss: 0.1174 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.8804 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0192 - capsnet_loss: 0.0161 - decoder_loss: 0.0078 - capsnet_accuracy: 0.9851\n",
            "Epoch 68: val_capsnet_accuracy did not improve from 0.88043\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0192 - capsnet_loss: 0.0161 - decoder_loss: 0.0078 - capsnet_accuracy: 0.9851 - val_loss: 0.1177 - val_capsnet_loss: 0.1144 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0183 - capsnet_loss: 0.0151 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9881\n",
            "Epoch 69: val_capsnet_accuracy did not improve from 0.88043\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0183 - capsnet_loss: 0.0151 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9881 - val_loss: 0.1204 - val_capsnet_loss: 0.1171 - val_decoder_loss: 0.0082 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0185 - capsnet_loss: 0.0152 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9911\n",
            "Epoch 70: val_capsnet_accuracy did not improve from 0.88043\n",
            "11/11 [==============================] - 10s 946ms/step - loss: 0.0185 - capsnet_loss: 0.0152 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9911 - val_loss: 0.1195 - val_capsnet_loss: 0.1164 - val_decoder_loss: 0.0081 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0193 - capsnet_loss: 0.0161 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9881\n",
            "Epoch 71: val_capsnet_accuracy did not improve from 0.88043\n",
            "11/11 [==============================] - 10s 948ms/step - loss: 0.0193 - capsnet_loss: 0.0161 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9881 - val_loss: 0.1193 - val_capsnet_loss: 0.1160 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0171 - capsnet_loss: 0.0140 - decoder_loss: 0.0079 - capsnet_accuracy: 0.9881\n",
            "Epoch 72: val_capsnet_accuracy did not improve from 0.88043\n",
            "11/11 [==============================] - 10s 950ms/step - loss: 0.0171 - capsnet_loss: 0.0140 - decoder_loss: 0.0079 - capsnet_accuracy: 0.9881 - val_loss: 0.1229 - val_capsnet_loss: 0.1195 - val_decoder_loss: 0.0086 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0157 - capsnet_loss: 0.0125 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9915\n",
            "Epoch 73: val_capsnet_accuracy did not improve from 0.88043\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0157 - capsnet_loss: 0.0125 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9915 - val_loss: 0.1170 - val_capsnet_loss: 0.1137 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0152 - capsnet_loss: 0.0122 - decoder_loss: 0.0078 - capsnet_accuracy: 0.9911\n",
            "Epoch 74: val_capsnet_accuracy improved from 0.88043 to 0.90217, saving model to ./result/weights.h5\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0152 - capsnet_loss: 0.0122 - decoder_loss: 0.0078 - capsnet_accuracy: 0.9911 - val_loss: 0.1160 - val_capsnet_loss: 0.1128 - val_decoder_loss: 0.0082 - val_capsnet_accuracy: 0.9022 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0123 - capsnet_loss: 0.0093 - decoder_loss: 0.0077 - capsnet_accuracy: 0.9940\n",
            "Epoch 75: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 951ms/step - loss: 0.0123 - capsnet_loss: 0.0093 - decoder_loss: 0.0077 - capsnet_accuracy: 0.9940 - val_loss: 0.1122 - val_capsnet_loss: 0.1090 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8913 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0141 - capsnet_loss: 0.0108 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9911\n",
            "Epoch 76: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 949ms/step - loss: 0.0141 - capsnet_loss: 0.0108 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9911 - val_loss: 0.1234 - val_capsnet_loss: 0.1201 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0169 - capsnet_loss: 0.0138 - decoder_loss: 0.0078 - capsnet_accuracy: 0.9911\n",
            "Epoch 77: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0169 - capsnet_loss: 0.0138 - decoder_loss: 0.0078 - capsnet_accuracy: 0.9911 - val_loss: 0.1155 - val_capsnet_loss: 0.1122 - val_decoder_loss: 0.0082 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0131 - capsnet_loss: 0.0100 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000\n",
            "Epoch 78: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 945ms/step - loss: 0.0131 - capsnet_loss: 0.0100 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000 - val_loss: 0.1183 - val_capsnet_loss: 0.1150 - val_decoder_loss: 0.0082 - val_capsnet_accuracy: 0.8804 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0142 - capsnet_loss: 0.0110 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9940\n",
            "Epoch 79: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0142 - capsnet_loss: 0.0110 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9940 - val_loss: 0.1160 - val_capsnet_loss: 0.1127 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0109 - capsnet_loss: 0.0078 - decoder_loss: 0.0079 - capsnet_accuracy: 0.9970\n",
            "Epoch 80: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0109 - capsnet_loss: 0.0078 - decoder_loss: 0.0079 - capsnet_accuracy: 0.9970 - val_loss: 0.1256 - val_capsnet_loss: 0.1223 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0131 - capsnet_loss: 0.0102 - decoder_loss: 0.0076 - capsnet_accuracy: 0.9970\n",
            "Epoch 81: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 947ms/step - loss: 0.0131 - capsnet_loss: 0.0102 - decoder_loss: 0.0076 - capsnet_accuracy: 0.9970 - val_loss: 0.1207 - val_capsnet_loss: 0.1175 - val_decoder_loss: 0.0082 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0117 - capsnet_loss: 0.0086 - decoder_loss: 0.0078 - capsnet_accuracy: 0.9940\n",
            "Epoch 82: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0117 - capsnet_loss: 0.0086 - decoder_loss: 0.0078 - capsnet_accuracy: 0.9940 - val_loss: 0.1236 - val_capsnet_loss: 0.1204 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0126 - capsnet_loss: 0.0095 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000\n",
            "Epoch 83: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 950ms/step - loss: 0.0126 - capsnet_loss: 0.0095 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000 - val_loss: 0.1214 - val_capsnet_loss: 0.1182 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0114 - capsnet_loss: 0.0083 - decoder_loss: 0.0079 - capsnet_accuracy: 0.9970\n",
            "Epoch 84: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 953ms/step - loss: 0.0114 - capsnet_loss: 0.0083 - decoder_loss: 0.0079 - capsnet_accuracy: 0.9970 - val_loss: 0.1255 - val_capsnet_loss: 0.1223 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0091 - capsnet_loss: 0.0060 - decoder_loss: 0.0077 - capsnet_accuracy: 1.0000\n",
            "Epoch 85: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0091 - capsnet_loss: 0.0060 - decoder_loss: 0.0077 - capsnet_accuracy: 1.0000 - val_loss: 0.1142 - val_capsnet_loss: 0.1111 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0091 - capsnet_loss: 0.0060 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000\n",
            "Epoch 86: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 990ms/step - loss: 0.0091 - capsnet_loss: 0.0060 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000 - val_loss: 0.1185 - val_capsnet_loss: 0.1154 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0071 - capsnet_loss: 0.0041 - decoder_loss: 0.0077 - capsnet_accuracy: 1.0000\n",
            "Epoch 87: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 953ms/step - loss: 0.0071 - capsnet_loss: 0.0041 - decoder_loss: 0.0077 - capsnet_accuracy: 1.0000 - val_loss: 0.1186 - val_capsnet_loss: 0.1155 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8804 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0083 - capsnet_loss: 0.0053 - decoder_loss: 0.0076 - capsnet_accuracy: 1.0000\n",
            "Epoch 88: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 947ms/step - loss: 0.0083 - capsnet_loss: 0.0053 - decoder_loss: 0.0076 - capsnet_accuracy: 1.0000 - val_loss: 0.1234 - val_capsnet_loss: 0.1201 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0078 - capsnet_loss: 0.0046 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000\n",
            "Epoch 89: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 946ms/step - loss: 0.0078 - capsnet_loss: 0.0046 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000 - val_loss: 0.1179 - val_capsnet_loss: 0.1148 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0063 - capsnet_loss: 0.0033 - decoder_loss: 0.0078 - capsnet_accuracy: 1.0000\n",
            "Epoch 90: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 951ms/step - loss: 0.0063 - capsnet_loss: 0.0033 - decoder_loss: 0.0078 - capsnet_accuracy: 1.0000 - val_loss: 0.1242 - val_capsnet_loss: 0.1211 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0067 - capsnet_loss: 0.0037 - decoder_loss: 0.0076 - capsnet_accuracy: 1.0000\n",
            "Epoch 91: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 943ms/step - loss: 0.0067 - capsnet_loss: 0.0037 - decoder_loss: 0.0076 - capsnet_accuracy: 1.0000 - val_loss: 0.1302 - val_capsnet_loss: 0.1269 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0091 - capsnet_loss: 0.0060 - decoder_loss: 0.0078 - capsnet_accuracy: 1.0000\n",
            "Epoch 92: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 949ms/step - loss: 0.0091 - capsnet_loss: 0.0060 - decoder_loss: 0.0078 - capsnet_accuracy: 1.0000 - val_loss: 0.1155 - val_capsnet_loss: 0.1125 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0072 - capsnet_loss: 0.0041 - decoder_loss: 0.0079 - capsnet_accuracy: 1.0000\n",
            "Epoch 93: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0072 - capsnet_loss: 0.0041 - decoder_loss: 0.0079 - capsnet_accuracy: 1.0000 - val_loss: 0.1198 - val_capsnet_loss: 0.1167 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0058 - capsnet_loss: 0.0030 - decoder_loss: 0.0072 - capsnet_accuracy: 1.0000\n",
            "Epoch 94: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0058 - capsnet_loss: 0.0030 - decoder_loss: 0.0072 - capsnet_accuracy: 1.0000 - val_loss: 0.1234 - val_capsnet_loss: 0.1203 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8804 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0051 - capsnet_loss: 0.0021 - decoder_loss: 0.0078 - capsnet_accuracy: 1.0000\n",
            "Epoch 95: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 950ms/step - loss: 0.0051 - capsnet_loss: 0.0021 - decoder_loss: 0.0078 - capsnet_accuracy: 1.0000 - val_loss: 0.1266 - val_capsnet_loss: 0.1234 - val_decoder_loss: 0.0081 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0049 - capsnet_loss: 0.0018 - decoder_loss: 0.0078 - capsnet_accuracy: 1.0000\n",
            "Epoch 96: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0049 - capsnet_loss: 0.0018 - decoder_loss: 0.0078 - capsnet_accuracy: 1.0000 - val_loss: 0.1253 - val_capsnet_loss: 0.1221 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0051 - capsnet_loss: 0.0021 - decoder_loss: 0.0077 - capsnet_accuracy: 1.0000\n",
            "Epoch 97: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0051 - capsnet_loss: 0.0021 - decoder_loss: 0.0077 - capsnet_accuracy: 1.0000 - val_loss: 0.1194 - val_capsnet_loss: 0.1164 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8804 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0049 - capsnet_loss: 0.0020 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000\n",
            "Epoch 98: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 11s 1s/step - loss: 0.0049 - capsnet_loss: 0.0020 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000 - val_loss: 0.1300 - val_capsnet_loss: 0.1268 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0046 - capsnet_loss: 0.0018 - decoder_loss: 0.0074 - capsnet_accuracy: 1.0000\n",
            "Epoch 99: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 948ms/step - loss: 0.0046 - capsnet_loss: 0.0018 - decoder_loss: 0.0074 - capsnet_accuracy: 1.0000 - val_loss: 0.1256 - val_capsnet_loss: 0.1225 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.0042 - capsnet_loss: 0.0011 - decoder_loss: 0.0079 - capsnet_accuracy: 1.0000\n",
            "Epoch 100: val_capsnet_accuracy did not improve from 0.90217\n",
            "11/11 [==============================] - 10s 947ms/step - loss: 0.0042 - capsnet_loss: 0.0011 - decoder_loss: 0.0079 - capsnet_accuracy: 1.0000 - val_loss: 0.1259 - val_capsnet_loss: 0.1228 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8804 - lr: 1.0000e-04\n",
            "Best Validation Accuracy:0.9021739363670349\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------Begin: test------------------------------\n",
            "Test acc: 0.9021739130434783\n",
            "Precision:0.9183673469387755\n",
            "recall:0.9\n",
            "f1:0.9090909090909091\n",
            "AUC:0.9023809523809523\n",
            "Sensitivity:0.9\n",
            "specificity:0.9047619047619048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACRIMA"
      ],
      "metadata": {
        "id": "WP85uVyT1Xwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args.batch_size = 32\n",
        "args.epochs = 100\n",
        "args.routings = 8\n",
        "data = get_acrima_dataset()\n",
        "get_model_train_test(data,args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CCbyQXmBwpqF",
        "outputId": "4eda618d-b45a-4e77-e601-07f4620313e7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(32, 64, 64, 3)]    0           []                               \n",
            "                                                                                                  \n",
            " conv0 (Conv2D)                 (32, 56, 56, 256)    62464       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " primary_capsule_conv (Conv2D)  (32, 48, 48, 512)    10617344    ['conv0[0][0]']                  \n",
            "                                                                                                  \n",
            " primarycap_reshape (Reshape)   (32, 73728, 16)      0           ['primary_capsule_conv[0][0]']   \n",
            "                                                                                                  \n",
            " primary_capsule (Lambda)       (32, 73728, 16)      0           ['primarycap_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " digitcaps (CapsuleLayer)       (32, 2, 16)          37748736    ['primary_capsule[0][0]']        \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " mask (Mask)                    (32, 32)             0           ['digitcaps[0][0]',              \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " capsnet (Length)               (32, 2)              0           ['digitcaps[0][0]']              \n",
            "                                                                                                  \n",
            " decoder (Sequential)           (None, 64, 64, 3)    13137408    ['mask[0][0]']                   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 61,565,952\n",
            "Trainable params: 61,565,952\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - ETA: 0s - loss: 0.4675 - capsnet_loss: 0.4293 - decoder_loss: 0.0973 - capsnet_accuracy: 0.5717\n",
            "Epoch 1: val_capsnet_accuracy improved from -inf to 0.51773, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 34s 1s/step - loss: 0.4675 - capsnet_loss: 0.4293 - decoder_loss: 0.0973 - capsnet_accuracy: 0.5717 - val_loss: 0.4250 - val_capsnet_loss: 0.3867 - val_decoder_loss: 0.0977 - val_capsnet_accuracy: 0.5177 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.2827 - capsnet_loss: 0.2447 - decoder_loss: 0.0972 - capsnet_accuracy: 0.6504\n",
            "Epoch 2: val_capsnet_accuracy improved from 0.51773 to 0.73050, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 20s 952ms/step - loss: 0.2827 - capsnet_loss: 0.2447 - decoder_loss: 0.0972 - capsnet_accuracy: 0.6504 - val_loss: 0.2128 - val_capsnet_loss: 0.1747 - val_decoder_loss: 0.0971 - val_capsnet_accuracy: 0.7305 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.2214 - capsnet_loss: 0.1841 - decoder_loss: 0.0952 - capsnet_accuracy: 0.7350\n",
            "Epoch 3: val_capsnet_accuracy did not improve from 0.73050\n",
            "17/17 [==============================] - 15s 905ms/step - loss: 0.2214 - capsnet_loss: 0.1841 - decoder_loss: 0.0952 - capsnet_accuracy: 0.7350 - val_loss: 0.2981 - val_capsnet_loss: 0.2607 - val_decoder_loss: 0.0955 - val_capsnet_accuracy: 0.6028 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.1781 - capsnet_loss: 0.1417 - decoder_loss: 0.0929 - capsnet_accuracy: 0.7895\n",
            "Epoch 4: val_capsnet_accuracy improved from 0.73050 to 0.77305, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 16s 955ms/step - loss: 0.1781 - capsnet_loss: 0.1417 - decoder_loss: 0.0929 - capsnet_accuracy: 0.7895 - val_loss: 0.1731 - val_capsnet_loss: 0.1376 - val_decoder_loss: 0.0905 - val_capsnet_accuracy: 0.7730 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.1258 - capsnet_loss: 0.0925 - decoder_loss: 0.0850 - capsnet_accuracy: 0.8759\n",
            "Epoch 5: val_capsnet_accuracy improved from 0.77305 to 0.83688, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 16s 955ms/step - loss: 0.1258 - capsnet_loss: 0.0925 - decoder_loss: 0.0850 - capsnet_accuracy: 0.8759 - val_loss: 0.1478 - val_capsnet_loss: 0.1166 - val_decoder_loss: 0.0795 - val_capsnet_accuracy: 0.8369 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.1323 - capsnet_loss: 0.1053 - decoder_loss: 0.0688 - capsnet_accuracy: 0.8647\n",
            "Epoch 6: val_capsnet_accuracy improved from 0.83688 to 0.85106, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 16s 962ms/step - loss: 0.1323 - capsnet_loss: 0.1053 - decoder_loss: 0.0688 - capsnet_accuracy: 0.8647 - val_loss: 0.1202 - val_capsnet_loss: 0.0986 - val_decoder_loss: 0.0553 - val_capsnet_accuracy: 0.8511 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0976 - capsnet_loss: 0.0806 - decoder_loss: 0.0433 - capsnet_accuracy: 0.8853\n",
            "Epoch 7: val_capsnet_accuracy improved from 0.85106 to 0.87234, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 16s 949ms/step - loss: 0.0976 - capsnet_loss: 0.0806 - decoder_loss: 0.0433 - capsnet_accuracy: 0.8853 - val_loss: 0.1107 - val_capsnet_loss: 0.0994 - val_decoder_loss: 0.0290 - val_capsnet_accuracy: 0.8723 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0920 - capsnet_loss: 0.0825 - decoder_loss: 0.0243 - capsnet_accuracy: 0.8816\n",
            "Epoch 8: val_capsnet_accuracy improved from 0.87234 to 0.90780, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 16s 972ms/step - loss: 0.0920 - capsnet_loss: 0.0825 - decoder_loss: 0.0243 - capsnet_accuracy: 0.8816 - val_loss: 0.0875 - val_capsnet_loss: 0.0805 - val_decoder_loss: 0.0177 - val_capsnet_accuracy: 0.9078 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0845 - capsnet_loss: 0.0768 - decoder_loss: 0.0196 - capsnet_accuracy: 0.8891\n",
            "Epoch 9: val_capsnet_accuracy improved from 0.90780 to 0.92199, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 16s 955ms/step - loss: 0.0845 - capsnet_loss: 0.0768 - decoder_loss: 0.0196 - capsnet_accuracy: 0.8891 - val_loss: 0.0802 - val_capsnet_loss: 0.0741 - val_decoder_loss: 0.0155 - val_capsnet_accuracy: 0.9220 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0773 - capsnet_loss: 0.0696 - decoder_loss: 0.0195 - capsnet_accuracy: 0.9135\n",
            "Epoch 10: val_capsnet_accuracy did not improve from 0.92199\n",
            "17/17 [==============================] - 16s 929ms/step - loss: 0.0773 - capsnet_loss: 0.0696 - decoder_loss: 0.0195 - capsnet_accuracy: 0.9135 - val_loss: 0.0922 - val_capsnet_loss: 0.0862 - val_decoder_loss: 0.0152 - val_capsnet_accuracy: 0.8723 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0823 - capsnet_loss: 0.0752 - decoder_loss: 0.0181 - capsnet_accuracy: 0.8853\n",
            "Epoch 11: val_capsnet_accuracy did not improve from 0.92199\n",
            "17/17 [==============================] - 16s 946ms/step - loss: 0.0823 - capsnet_loss: 0.0752 - decoder_loss: 0.0181 - capsnet_accuracy: 0.8853 - val_loss: 0.0792 - val_capsnet_loss: 0.0733 - val_decoder_loss: 0.0150 - val_capsnet_accuracy: 0.8794 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0726 - capsnet_loss: 0.0656 - decoder_loss: 0.0178 - capsnet_accuracy: 0.9135\n",
            "Epoch 12: val_capsnet_accuracy did not improve from 0.92199\n",
            "17/17 [==============================] - 17s 947ms/step - loss: 0.0726 - capsnet_loss: 0.0656 - decoder_loss: 0.0178 - capsnet_accuracy: 0.9135 - val_loss: 0.0844 - val_capsnet_loss: 0.0787 - val_decoder_loss: 0.0147 - val_capsnet_accuracy: 0.9149 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0648 - capsnet_loss: 0.0576 - decoder_loss: 0.0183 - capsnet_accuracy: 0.9229\n",
            "Epoch 13: val_capsnet_accuracy did not improve from 0.92199\n",
            "17/17 [==============================] - 16s 951ms/step - loss: 0.0648 - capsnet_loss: 0.0576 - decoder_loss: 0.0183 - capsnet_accuracy: 0.9229 - val_loss: 0.0772 - val_capsnet_loss: 0.0713 - val_decoder_loss: 0.0150 - val_capsnet_accuracy: 0.8865 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0693 - capsnet_loss: 0.0624 - decoder_loss: 0.0177 - capsnet_accuracy: 0.9117\n",
            "Epoch 14: val_capsnet_accuracy improved from 0.92199 to 0.92908, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 17s 979ms/step - loss: 0.0693 - capsnet_loss: 0.0624 - decoder_loss: 0.0177 - capsnet_accuracy: 0.9117 - val_loss: 0.0685 - val_capsnet_loss: 0.0627 - val_decoder_loss: 0.0146 - val_capsnet_accuracy: 0.9291 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0575 - capsnet_loss: 0.0505 - decoder_loss: 0.0179 - capsnet_accuracy: 0.9342\n",
            "Epoch 15: val_capsnet_accuracy did not improve from 0.92908\n",
            "17/17 [==============================] - 16s 952ms/step - loss: 0.0575 - capsnet_loss: 0.0505 - decoder_loss: 0.0179 - capsnet_accuracy: 0.9342 - val_loss: 0.0718 - val_capsnet_loss: 0.0660 - val_decoder_loss: 0.0149 - val_capsnet_accuracy: 0.9149 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0589 - capsnet_loss: 0.0520 - decoder_loss: 0.0174 - capsnet_accuracy: 0.9267\n",
            "Epoch 16: val_capsnet_accuracy did not improve from 0.92908\n",
            "17/17 [==============================] - 16s 938ms/step - loss: 0.0589 - capsnet_loss: 0.0520 - decoder_loss: 0.0174 - capsnet_accuracy: 0.9267 - val_loss: 0.0674 - val_capsnet_loss: 0.0616 - val_decoder_loss: 0.0148 - val_capsnet_accuracy: 0.9149 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0562 - capsnet_loss: 0.0492 - decoder_loss: 0.0179 - capsnet_accuracy: 0.9417\n",
            "Epoch 17: val_capsnet_accuracy did not improve from 0.92908\n",
            "17/17 [==============================] - 17s 985ms/step - loss: 0.0562 - capsnet_loss: 0.0492 - decoder_loss: 0.0179 - capsnet_accuracy: 0.9417 - val_loss: 0.0898 - val_capsnet_loss: 0.0838 - val_decoder_loss: 0.0152 - val_capsnet_accuracy: 0.8936 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0658 - capsnet_loss: 0.0587 - decoder_loss: 0.0180 - capsnet_accuracy: 0.9286\n",
            "Epoch 18: val_capsnet_accuracy did not improve from 0.92908\n",
            "17/17 [==============================] - 16s 937ms/step - loss: 0.0658 - capsnet_loss: 0.0587 - decoder_loss: 0.0180 - capsnet_accuracy: 0.9286 - val_loss: 0.0780 - val_capsnet_loss: 0.0721 - val_decoder_loss: 0.0149 - val_capsnet_accuracy: 0.8936 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0510 - capsnet_loss: 0.0441 - decoder_loss: 0.0177 - capsnet_accuracy: 0.9412\n",
            "Epoch 19: val_capsnet_accuracy improved from 0.92908 to 0.94326, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 17s 992ms/step - loss: 0.0510 - capsnet_loss: 0.0441 - decoder_loss: 0.0177 - capsnet_accuracy: 0.9412 - val_loss: 0.0625 - val_capsnet_loss: 0.0568 - val_decoder_loss: 0.0145 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0518 - capsnet_loss: 0.0451 - decoder_loss: 0.0171 - capsnet_accuracy: 0.9380\n",
            "Epoch 20: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 977ms/step - loss: 0.0518 - capsnet_loss: 0.0451 - decoder_loss: 0.0171 - capsnet_accuracy: 0.9380 - val_loss: 0.0650 - val_capsnet_loss: 0.0593 - val_decoder_loss: 0.0146 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0442 - capsnet_loss: 0.0372 - decoder_loss: 0.0177 - capsnet_accuracy: 0.9624\n",
            "Epoch 21: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 959ms/step - loss: 0.0442 - capsnet_loss: 0.0372 - decoder_loss: 0.0177 - capsnet_accuracy: 0.9624 - val_loss: 0.0728 - val_capsnet_loss: 0.0670 - val_decoder_loss: 0.0147 - val_capsnet_accuracy: 0.9291 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0495 - capsnet_loss: 0.0426 - decoder_loss: 0.0176 - capsnet_accuracy: 0.9474\n",
            "Epoch 22: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 959ms/step - loss: 0.0495 - capsnet_loss: 0.0426 - decoder_loss: 0.0176 - capsnet_accuracy: 0.9474 - val_loss: 0.0652 - val_capsnet_loss: 0.0595 - val_decoder_loss: 0.0144 - val_capsnet_accuracy: 0.9291 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0502 - capsnet_loss: 0.0436 - decoder_loss: 0.0167 - capsnet_accuracy: 0.9511\n",
            "Epoch 23: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 955ms/step - loss: 0.0502 - capsnet_loss: 0.0436 - decoder_loss: 0.0167 - capsnet_accuracy: 0.9511 - val_loss: 0.0689 - val_capsnet_loss: 0.0633 - val_decoder_loss: 0.0143 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0454 - capsnet_loss: 0.0386 - decoder_loss: 0.0175 - capsnet_accuracy: 0.9624\n",
            "Epoch 24: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 957ms/step - loss: 0.0454 - capsnet_loss: 0.0386 - decoder_loss: 0.0175 - capsnet_accuracy: 0.9624 - val_loss: 0.0627 - val_capsnet_loss: 0.0572 - val_decoder_loss: 0.0142 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0414 - capsnet_loss: 0.0348 - decoder_loss: 0.0170 - capsnet_accuracy: 0.9605\n",
            "Epoch 25: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 941ms/step - loss: 0.0414 - capsnet_loss: 0.0348 - decoder_loss: 0.0170 - capsnet_accuracy: 0.9605 - val_loss: 0.0591 - val_capsnet_loss: 0.0535 - val_decoder_loss: 0.0142 - val_capsnet_accuracy: 0.9220 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0400 - capsnet_loss: 0.0332 - decoder_loss: 0.0173 - capsnet_accuracy: 0.9605\n",
            "Epoch 26: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 941ms/step - loss: 0.0400 - capsnet_loss: 0.0332 - decoder_loss: 0.0173 - capsnet_accuracy: 0.9605 - val_loss: 0.0544 - val_capsnet_loss: 0.0488 - val_decoder_loss: 0.0141 - val_capsnet_accuracy: 0.9291 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0398 - capsnet_loss: 0.0331 - decoder_loss: 0.0170 - capsnet_accuracy: 0.9624\n",
            "Epoch 27: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 955ms/step - loss: 0.0398 - capsnet_loss: 0.0331 - decoder_loss: 0.0170 - capsnet_accuracy: 0.9624 - val_loss: 0.0587 - val_capsnet_loss: 0.0532 - val_decoder_loss: 0.0141 - val_capsnet_accuracy: 0.9291 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0377 - capsnet_loss: 0.0311 - decoder_loss: 0.0167 - capsnet_accuracy: 0.9812\n",
            "Epoch 28: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 943ms/step - loss: 0.0377 - capsnet_loss: 0.0311 - decoder_loss: 0.0167 - capsnet_accuracy: 0.9812 - val_loss: 0.0682 - val_capsnet_loss: 0.0626 - val_decoder_loss: 0.0143 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0372 - capsnet_loss: 0.0305 - decoder_loss: 0.0169 - capsnet_accuracy: 0.9624\n",
            "Epoch 29: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 958ms/step - loss: 0.0372 - capsnet_loss: 0.0305 - decoder_loss: 0.0169 - capsnet_accuracy: 0.9624 - val_loss: 0.0580 - val_capsnet_loss: 0.0525 - val_decoder_loss: 0.0141 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0373 - capsnet_loss: 0.0308 - decoder_loss: 0.0166 - capsnet_accuracy: 0.9699\n",
            "Epoch 30: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 939ms/step - loss: 0.0373 - capsnet_loss: 0.0308 - decoder_loss: 0.0166 - capsnet_accuracy: 0.9699 - val_loss: 0.0615 - val_capsnet_loss: 0.0560 - val_decoder_loss: 0.0139 - val_capsnet_accuracy: 0.9220 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0332 - capsnet_loss: 0.0265 - decoder_loss: 0.0173 - capsnet_accuracy: 0.9756\n",
            "Epoch 31: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 941ms/step - loss: 0.0332 - capsnet_loss: 0.0265 - decoder_loss: 0.0173 - capsnet_accuracy: 0.9756 - val_loss: 0.0536 - val_capsnet_loss: 0.0483 - val_decoder_loss: 0.0137 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0278 - capsnet_loss: 0.0216 - decoder_loss: 0.0159 - capsnet_accuracy: 0.9812\n",
            "Epoch 32: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 954ms/step - loss: 0.0278 - capsnet_loss: 0.0216 - decoder_loss: 0.0159 - capsnet_accuracy: 0.9812 - val_loss: 0.0556 - val_capsnet_loss: 0.0503 - val_decoder_loss: 0.0136 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0307 - capsnet_loss: 0.0243 - decoder_loss: 0.0162 - capsnet_accuracy: 0.9737\n",
            "Epoch 33: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 939ms/step - loss: 0.0307 - capsnet_loss: 0.0243 - decoder_loss: 0.0162 - capsnet_accuracy: 0.9737 - val_loss: 0.0531 - val_capsnet_loss: 0.0478 - val_decoder_loss: 0.0133 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0313 - capsnet_loss: 0.0250 - decoder_loss: 0.0161 - capsnet_accuracy: 0.9793\n",
            "Epoch 34: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 954ms/step - loss: 0.0313 - capsnet_loss: 0.0250 - decoder_loss: 0.0161 - capsnet_accuracy: 0.9793 - val_loss: 0.0533 - val_capsnet_loss: 0.0480 - val_decoder_loss: 0.0135 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0260 - capsnet_loss: 0.0197 - decoder_loss: 0.0160 - capsnet_accuracy: 0.9850\n",
            "Epoch 35: val_capsnet_accuracy did not improve from 0.94326\n",
            "17/17 [==============================] - 16s 941ms/step - loss: 0.0260 - capsnet_loss: 0.0197 - decoder_loss: 0.0160 - capsnet_accuracy: 0.9850 - val_loss: 0.0586 - val_capsnet_loss: 0.0534 - val_decoder_loss: 0.0132 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0303 - capsnet_loss: 0.0241 - decoder_loss: 0.0157 - capsnet_accuracy: 0.9793\n",
            "Epoch 36: val_capsnet_accuracy improved from 0.94326 to 0.95745, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 17s 987ms/step - loss: 0.0303 - capsnet_loss: 0.0241 - decoder_loss: 0.0157 - capsnet_accuracy: 0.9793 - val_loss: 0.0515 - val_capsnet_loss: 0.0464 - val_decoder_loss: 0.0131 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0245 - capsnet_loss: 0.0185 - decoder_loss: 0.0154 - capsnet_accuracy: 0.9816\n",
            "Epoch 37: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 961ms/step - loss: 0.0245 - capsnet_loss: 0.0185 - decoder_loss: 0.0154 - capsnet_accuracy: 0.9816 - val_loss: 0.0590 - val_capsnet_loss: 0.0540 - val_decoder_loss: 0.0128 - val_capsnet_accuracy: 0.9220 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0252 - capsnet_loss: 0.0193 - decoder_loss: 0.0151 - capsnet_accuracy: 0.9850\n",
            "Epoch 38: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 978ms/step - loss: 0.0252 - capsnet_loss: 0.0193 - decoder_loss: 0.0151 - capsnet_accuracy: 0.9850 - val_loss: 0.0516 - val_capsnet_loss: 0.0468 - val_decoder_loss: 0.0123 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0213 - capsnet_loss: 0.0156 - decoder_loss: 0.0144 - capsnet_accuracy: 0.9850\n",
            "Epoch 39: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 974ms/step - loss: 0.0213 - capsnet_loss: 0.0156 - decoder_loss: 0.0144 - capsnet_accuracy: 0.9850 - val_loss: 0.0553 - val_capsnet_loss: 0.0505 - val_decoder_loss: 0.0122 - val_capsnet_accuracy: 0.9291 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0219 - capsnet_loss: 0.0164 - decoder_loss: 0.0140 - capsnet_accuracy: 0.9831\n",
            "Epoch 40: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 974ms/step - loss: 0.0219 - capsnet_loss: 0.0164 - decoder_loss: 0.0140 - capsnet_accuracy: 0.9831 - val_loss: 0.0493 - val_capsnet_loss: 0.0446 - val_decoder_loss: 0.0121 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0191 - capsnet_loss: 0.0137 - decoder_loss: 0.0138 - capsnet_accuracy: 0.9925\n",
            "Epoch 41: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 958ms/step - loss: 0.0191 - capsnet_loss: 0.0137 - decoder_loss: 0.0138 - capsnet_accuracy: 0.9925 - val_loss: 0.0516 - val_capsnet_loss: 0.0470 - val_decoder_loss: 0.0117 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0251 - capsnet_loss: 0.0197 - decoder_loss: 0.0135 - capsnet_accuracy: 0.9850\n",
            "Epoch 42: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 958ms/step - loss: 0.0251 - capsnet_loss: 0.0197 - decoder_loss: 0.0135 - capsnet_accuracy: 0.9850 - val_loss: 0.0543 - val_capsnet_loss: 0.0498 - val_decoder_loss: 0.0114 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0248 - capsnet_loss: 0.0198 - decoder_loss: 0.0128 - capsnet_accuracy: 0.9887\n",
            "Epoch 43: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 956ms/step - loss: 0.0248 - capsnet_loss: 0.0198 - decoder_loss: 0.0128 - capsnet_accuracy: 0.9887 - val_loss: 0.0537 - val_capsnet_loss: 0.0492 - val_decoder_loss: 0.0115 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0205 - capsnet_loss: 0.0155 - decoder_loss: 0.0128 - capsnet_accuracy: 0.9868\n",
            "Epoch 44: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 970ms/step - loss: 0.0205 - capsnet_loss: 0.0155 - decoder_loss: 0.0128 - capsnet_accuracy: 0.9868 - val_loss: 0.0472 - val_capsnet_loss: 0.0429 - val_decoder_loss: 0.0111 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0202 - capsnet_loss: 0.0152 - decoder_loss: 0.0129 - capsnet_accuracy: 0.9906\n",
            "Epoch 45: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 969ms/step - loss: 0.0202 - capsnet_loss: 0.0152 - decoder_loss: 0.0129 - capsnet_accuracy: 0.9906 - val_loss: 0.0457 - val_capsnet_loss: 0.0414 - val_decoder_loss: 0.0109 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0228 - capsnet_loss: 0.0179 - decoder_loss: 0.0126 - capsnet_accuracy: 0.9887\n",
            "Epoch 46: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 956ms/step - loss: 0.0228 - capsnet_loss: 0.0179 - decoder_loss: 0.0126 - capsnet_accuracy: 0.9887 - val_loss: 0.0501 - val_capsnet_loss: 0.0459 - val_decoder_loss: 0.0108 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0202 - capsnet_loss: 0.0154 - decoder_loss: 0.0122 - capsnet_accuracy: 0.9887\n",
            "Epoch 47: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 951ms/step - loss: 0.0202 - capsnet_loss: 0.0154 - decoder_loss: 0.0122 - capsnet_accuracy: 0.9887 - val_loss: 0.0557 - val_capsnet_loss: 0.0516 - val_decoder_loss: 0.0106 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0188 - capsnet_loss: 0.0143 - decoder_loss: 0.0114 - capsnet_accuracy: 0.9944\n",
            "Epoch 48: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 958ms/step - loss: 0.0188 - capsnet_loss: 0.0143 - decoder_loss: 0.0114 - capsnet_accuracy: 0.9944 - val_loss: 0.0489 - val_capsnet_loss: 0.0448 - val_decoder_loss: 0.0103 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0168 - capsnet_loss: 0.0120 - decoder_loss: 0.0121 - capsnet_accuracy: 0.9887\n",
            "Epoch 49: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 955ms/step - loss: 0.0168 - capsnet_loss: 0.0120 - decoder_loss: 0.0121 - capsnet_accuracy: 0.9887 - val_loss: 0.0488 - val_capsnet_loss: 0.0449 - val_decoder_loss: 0.0101 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0135 - capsnet_loss: 0.0092 - decoder_loss: 0.0111 - capsnet_accuracy: 0.9962\n",
            "Epoch 50: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 960ms/step - loss: 0.0135 - capsnet_loss: 0.0092 - decoder_loss: 0.0111 - capsnet_accuracy: 0.9962 - val_loss: 0.0508 - val_capsnet_loss: 0.0470 - val_decoder_loss: 0.0098 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0161 - capsnet_loss: 0.0117 - decoder_loss: 0.0112 - capsnet_accuracy: 0.9925\n",
            "Epoch 51: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 959ms/step - loss: 0.0161 - capsnet_loss: 0.0117 - decoder_loss: 0.0112 - capsnet_accuracy: 0.9925 - val_loss: 0.0535 - val_capsnet_loss: 0.0496 - val_decoder_loss: 0.0098 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0161 - capsnet_loss: 0.0118 - decoder_loss: 0.0109 - capsnet_accuracy: 0.9906\n",
            "Epoch 52: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 958ms/step - loss: 0.0161 - capsnet_loss: 0.0118 - decoder_loss: 0.0109 - capsnet_accuracy: 0.9906 - val_loss: 0.0509 - val_capsnet_loss: 0.0471 - val_decoder_loss: 0.0098 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0142 - capsnet_loss: 0.0100 - decoder_loss: 0.0108 - capsnet_accuracy: 0.9944\n",
            "Epoch 53: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 974ms/step - loss: 0.0142 - capsnet_loss: 0.0100 - decoder_loss: 0.0108 - capsnet_accuracy: 0.9944 - val_loss: 0.0474 - val_capsnet_loss: 0.0436 - val_decoder_loss: 0.0097 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0131 - capsnet_loss: 0.0088 - decoder_loss: 0.0109 - capsnet_accuracy: 0.9925\n",
            "Epoch 54: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 972ms/step - loss: 0.0131 - capsnet_loss: 0.0088 - decoder_loss: 0.0109 - capsnet_accuracy: 0.9925 - val_loss: 0.0480 - val_capsnet_loss: 0.0443 - val_decoder_loss: 0.0096 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0132 - capsnet_loss: 0.0091 - decoder_loss: 0.0106 - capsnet_accuracy: 0.9926\n",
            "Epoch 55: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 17s 976ms/step - loss: 0.0132 - capsnet_loss: 0.0091 - decoder_loss: 0.0106 - capsnet_accuracy: 0.9926 - val_loss: 0.0460 - val_capsnet_loss: 0.0424 - val_decoder_loss: 0.0091 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0138 - capsnet_loss: 0.0097 - decoder_loss: 0.0103 - capsnet_accuracy: 0.9944\n",
            "Epoch 56: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 979ms/step - loss: 0.0138 - capsnet_loss: 0.0097 - decoder_loss: 0.0103 - capsnet_accuracy: 0.9944 - val_loss: 0.0484 - val_capsnet_loss: 0.0449 - val_decoder_loss: 0.0090 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0130 - capsnet_loss: 0.0090 - decoder_loss: 0.0102 - capsnet_accuracy: 0.9925\n",
            "Epoch 57: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 958ms/step - loss: 0.0130 - capsnet_loss: 0.0090 - decoder_loss: 0.0102 - capsnet_accuracy: 0.9925 - val_loss: 0.0481 - val_capsnet_loss: 0.0444 - val_decoder_loss: 0.0094 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0166 - capsnet_loss: 0.0127 - decoder_loss: 0.0099 - capsnet_accuracy: 0.9944\n",
            "Epoch 58: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 962ms/step - loss: 0.0166 - capsnet_loss: 0.0127 - decoder_loss: 0.0099 - capsnet_accuracy: 0.9944 - val_loss: 0.0527 - val_capsnet_loss: 0.0492 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0154 - capsnet_loss: 0.0113 - decoder_loss: 0.0103 - capsnet_accuracy: 0.9925\n",
            "Epoch 59: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 972ms/step - loss: 0.0154 - capsnet_loss: 0.0113 - decoder_loss: 0.0103 - capsnet_accuracy: 0.9925 - val_loss: 0.0479 - val_capsnet_loss: 0.0444 - val_decoder_loss: 0.0090 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0132 - capsnet_loss: 0.0094 - decoder_loss: 0.0097 - capsnet_accuracy: 0.9944\n",
            "Epoch 60: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 971ms/step - loss: 0.0132 - capsnet_loss: 0.0094 - decoder_loss: 0.0097 - capsnet_accuracy: 0.9944 - val_loss: 0.0486 - val_capsnet_loss: 0.0452 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0121 - capsnet_loss: 0.0084 - decoder_loss: 0.0095 - capsnet_accuracy: 0.9962\n",
            "Epoch 61: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 970ms/step - loss: 0.0121 - capsnet_loss: 0.0084 - decoder_loss: 0.0095 - capsnet_accuracy: 0.9962 - val_loss: 0.0418 - val_capsnet_loss: 0.0384 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0114 - capsnet_loss: 0.0076 - decoder_loss: 0.0096 - capsnet_accuracy: 0.9944\n",
            "Epoch 62: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 959ms/step - loss: 0.0114 - capsnet_loss: 0.0076 - decoder_loss: 0.0096 - capsnet_accuracy: 0.9944 - val_loss: 0.0429 - val_capsnet_loss: 0.0396 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0114 - capsnet_loss: 0.0079 - decoder_loss: 0.0091 - capsnet_accuracy: 0.9944\n",
            "Epoch 63: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 973ms/step - loss: 0.0114 - capsnet_loss: 0.0079 - decoder_loss: 0.0091 - capsnet_accuracy: 0.9944 - val_loss: 0.0418 - val_capsnet_loss: 0.0385 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0117 - capsnet_loss: 0.0081 - decoder_loss: 0.0093 - capsnet_accuracy: 0.9925\n",
            "Epoch 64: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 972ms/step - loss: 0.0117 - capsnet_loss: 0.0081 - decoder_loss: 0.0093 - capsnet_accuracy: 0.9925 - val_loss: 0.0471 - val_capsnet_loss: 0.0438 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0100 - capsnet_loss: 0.0063 - decoder_loss: 0.0093 - capsnet_accuracy: 0.9962\n",
            "Epoch 65: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 972ms/step - loss: 0.0100 - capsnet_loss: 0.0063 - decoder_loss: 0.0093 - capsnet_accuracy: 0.9962 - val_loss: 0.0483 - val_capsnet_loss: 0.0451 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0092 - capsnet_loss: 0.0057 - decoder_loss: 0.0089 - capsnet_accuracy: 1.0000\n",
            "Epoch 66: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 957ms/step - loss: 0.0092 - capsnet_loss: 0.0057 - decoder_loss: 0.0089 - capsnet_accuracy: 1.0000 - val_loss: 0.0445 - val_capsnet_loss: 0.0413 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0099 - capsnet_loss: 0.0063 - decoder_loss: 0.0090 - capsnet_accuracy: 0.9962\n",
            "Epoch 67: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 17s 982ms/step - loss: 0.0099 - capsnet_loss: 0.0063 - decoder_loss: 0.0090 - capsnet_accuracy: 0.9962 - val_loss: 0.0419 - val_capsnet_loss: 0.0387 - val_decoder_loss: 0.0081 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0090 - capsnet_loss: 0.0056 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9962\n",
            "Epoch 68: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 959ms/step - loss: 0.0090 - capsnet_loss: 0.0056 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9962 - val_loss: 0.0462 - val_capsnet_loss: 0.0431 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0094 - capsnet_loss: 0.0060 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9981\n",
            "Epoch 69: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 973ms/step - loss: 0.0094 - capsnet_loss: 0.0060 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9981 - val_loss: 0.0460 - val_capsnet_loss: 0.0428 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0098 - capsnet_loss: 0.0063 - decoder_loss: 0.0089 - capsnet_accuracy: 0.9981\n",
            "Epoch 70: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 973ms/step - loss: 0.0098 - capsnet_loss: 0.0063 - decoder_loss: 0.0089 - capsnet_accuracy: 0.9981 - val_loss: 0.0475 - val_capsnet_loss: 0.0441 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0128 - capsnet_loss: 0.0093 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9944\n",
            "Epoch 71: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 17s 975ms/step - loss: 0.0128 - capsnet_loss: 0.0093 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9944 - val_loss: 0.0735 - val_capsnet_loss: 0.0700 - val_decoder_loss: 0.0090 - val_capsnet_accuracy: 0.9220 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0165 - capsnet_loss: 0.0128 - decoder_loss: 0.0094 - capsnet_accuracy: 0.9925\n",
            "Epoch 72: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 957ms/step - loss: 0.0165 - capsnet_loss: 0.0128 - decoder_loss: 0.0094 - capsnet_accuracy: 0.9925 - val_loss: 0.0512 - val_capsnet_loss: 0.0478 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0117 - capsnet_loss: 0.0083 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9963\n",
            "Epoch 73: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 17s 992ms/step - loss: 0.0117 - capsnet_loss: 0.0083 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9963 - val_loss: 0.0523 - val_capsnet_loss: 0.0492 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0128 - capsnet_loss: 0.0094 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9962\n",
            "Epoch 74: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 988ms/step - loss: 0.0128 - capsnet_loss: 0.0094 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9962 - val_loss: 0.0480 - val_capsnet_loss: 0.0448 - val_decoder_loss: 0.0082 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0123 - capsnet_loss: 0.0088 - decoder_loss: 0.0089 - capsnet_accuracy: 0.9981\n",
            "Epoch 75: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 956ms/step - loss: 0.0123 - capsnet_loss: 0.0088 - decoder_loss: 0.0089 - capsnet_accuracy: 0.9981 - val_loss: 0.0503 - val_capsnet_loss: 0.0472 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0092 - capsnet_loss: 0.0060 - decoder_loss: 0.0081 - capsnet_accuracy: 1.0000\n",
            "Epoch 76: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 958ms/step - loss: 0.0092 - capsnet_loss: 0.0060 - decoder_loss: 0.0081 - capsnet_accuracy: 1.0000 - val_loss: 0.0473 - val_capsnet_loss: 0.0441 - val_decoder_loss: 0.0082 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0098 - capsnet_loss: 0.0064 - decoder_loss: 0.0088 - capsnet_accuracy: 1.0000\n",
            "Epoch 77: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 973ms/step - loss: 0.0098 - capsnet_loss: 0.0064 - decoder_loss: 0.0088 - capsnet_accuracy: 1.0000 - val_loss: 0.0475 - val_capsnet_loss: 0.0442 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0089 - capsnet_loss: 0.0058 - decoder_loss: 0.0081 - capsnet_accuracy: 1.0000\n",
            "Epoch 78: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 972ms/step - loss: 0.0089 - capsnet_loss: 0.0058 - decoder_loss: 0.0081 - capsnet_accuracy: 1.0000 - val_loss: 0.0451 - val_capsnet_loss: 0.0421 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0081 - capsnet_loss: 0.0049 - decoder_loss: 0.0083 - capsnet_accuracy: 1.0000\n",
            "Epoch 79: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 972ms/step - loss: 0.0081 - capsnet_loss: 0.0049 - decoder_loss: 0.0083 - capsnet_accuracy: 1.0000 - val_loss: 0.0426 - val_capsnet_loss: 0.0396 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0069 - capsnet_loss: 0.0037 - decoder_loss: 0.0081 - capsnet_accuracy: 1.0000\n",
            "Epoch 80: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 960ms/step - loss: 0.0069 - capsnet_loss: 0.0037 - decoder_loss: 0.0081 - capsnet_accuracy: 1.0000 - val_loss: 0.0436 - val_capsnet_loss: 0.0406 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0065 - capsnet_loss: 0.0034 - decoder_loss: 0.0079 - capsnet_accuracy: 1.0000\n",
            "Epoch 81: val_capsnet_accuracy improved from 0.95745 to 0.96454, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 17s 986ms/step - loss: 0.0065 - capsnet_loss: 0.0034 - decoder_loss: 0.0079 - capsnet_accuracy: 1.0000 - val_loss: 0.0422 - val_capsnet_loss: 0.0391 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.9645 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0056 - capsnet_loss: 0.0025 - decoder_loss: 0.0079 - capsnet_accuracy: 1.0000\n",
            "Epoch 82: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 17s 980ms/step - loss: 0.0056 - capsnet_loss: 0.0025 - decoder_loss: 0.0079 - capsnet_accuracy: 1.0000 - val_loss: 0.0455 - val_capsnet_loss: 0.0426 - val_decoder_loss: 0.0075 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0064 - capsnet_loss: 0.0032 - decoder_loss: 0.0081 - capsnet_accuracy: 1.0000\n",
            "Epoch 83: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 971ms/step - loss: 0.0064 - capsnet_loss: 0.0032 - decoder_loss: 0.0081 - capsnet_accuracy: 1.0000 - val_loss: 0.0449 - val_capsnet_loss: 0.0419 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0059 - capsnet_loss: 0.0029 - decoder_loss: 0.0076 - capsnet_accuracy: 1.0000\n",
            "Epoch 84: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 17s 979ms/step - loss: 0.0059 - capsnet_loss: 0.0029 - decoder_loss: 0.0076 - capsnet_accuracy: 1.0000 - val_loss: 0.0438 - val_capsnet_loss: 0.0408 - val_decoder_loss: 0.0075 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0051 - capsnet_loss: 0.0022 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000\n",
            "Epoch 85: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 17s 982ms/step - loss: 0.0051 - capsnet_loss: 0.0022 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000 - val_loss: 0.0431 - val_capsnet_loss: 0.0401 - val_decoder_loss: 0.0076 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0071 - capsnet_loss: 0.0040 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000\n",
            "Epoch 86: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 964ms/step - loss: 0.0071 - capsnet_loss: 0.0040 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000 - val_loss: 0.0442 - val_capsnet_loss: 0.0412 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0082 - capsnet_loss: 0.0051 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9981\n",
            "Epoch 87: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 17s 977ms/step - loss: 0.0082 - capsnet_loss: 0.0051 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9981 - val_loss: 0.0451 - val_capsnet_loss: 0.0420 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0075 - capsnet_loss: 0.0044 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000\n",
            "Epoch 88: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 963ms/step - loss: 0.0075 - capsnet_loss: 0.0044 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000 - val_loss: 0.0467 - val_capsnet_loss: 0.0437 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0066 - capsnet_loss: 0.0035 - decoder_loss: 0.0079 - capsnet_accuracy: 1.0000\n",
            "Epoch 89: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 963ms/step - loss: 0.0066 - capsnet_loss: 0.0035 - decoder_loss: 0.0079 - capsnet_accuracy: 1.0000 - val_loss: 0.0484 - val_capsnet_loss: 0.0454 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0084 - capsnet_loss: 0.0053 - decoder_loss: 0.0078 - capsnet_accuracy: 1.0000\n",
            "Epoch 90: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 963ms/step - loss: 0.0084 - capsnet_loss: 0.0053 - decoder_loss: 0.0078 - capsnet_accuracy: 1.0000 - val_loss: 0.0566 - val_capsnet_loss: 0.0533 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0071 - capsnet_loss: 0.0041 - decoder_loss: 0.0076 - capsnet_accuracy: 1.0000\n",
            "Epoch 91: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 17s 994ms/step - loss: 0.0071 - capsnet_loss: 0.0041 - decoder_loss: 0.0076 - capsnet_accuracy: 1.0000 - val_loss: 0.0444 - val_capsnet_loss: 0.0414 - val_decoder_loss: 0.0075 - val_capsnet_accuracy: 0.9645 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0059 - capsnet_loss: 0.0029 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000\n",
            "Epoch 92: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 983ms/step - loss: 0.0059 - capsnet_loss: 0.0029 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000 - val_loss: 0.0486 - val_capsnet_loss: 0.0457 - val_decoder_loss: 0.0075 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0054 - capsnet_loss: 0.0025 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000\n",
            "Epoch 93: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 17s 976ms/step - loss: 0.0054 - capsnet_loss: 0.0025 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000 - val_loss: 0.0413 - val_capsnet_loss: 0.0384 - val_decoder_loss: 0.0075 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0049 - capsnet_loss: 0.0020 - decoder_loss: 0.0074 - capsnet_accuracy: 1.0000\n",
            "Epoch 94: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 960ms/step - loss: 0.0049 - capsnet_loss: 0.0020 - decoder_loss: 0.0074 - capsnet_accuracy: 1.0000 - val_loss: 0.0441 - val_capsnet_loss: 0.0412 - val_decoder_loss: 0.0072 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0046 - capsnet_loss: 0.0016 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000\n",
            "Epoch 95: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 17s 975ms/step - loss: 0.0046 - capsnet_loss: 0.0016 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000 - val_loss: 0.0442 - val_capsnet_loss: 0.0413 - val_decoder_loss: 0.0075 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0047 - capsnet_loss: 0.0018 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000\n",
            "Epoch 96: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 17s 975ms/step - loss: 0.0047 - capsnet_loss: 0.0018 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000 - val_loss: 0.0430 - val_capsnet_loss: 0.0402 - val_decoder_loss: 0.0072 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0050 - capsnet_loss: 0.0022 - decoder_loss: 0.0070 - capsnet_accuracy: 1.0000\n",
            "Epoch 97: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 963ms/step - loss: 0.0050 - capsnet_loss: 0.0022 - decoder_loss: 0.0070 - capsnet_accuracy: 1.0000 - val_loss: 0.0465 - val_capsnet_loss: 0.0437 - val_decoder_loss: 0.0073 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0061 - capsnet_loss: 0.0032 - decoder_loss: 0.0073 - capsnet_accuracy: 1.0000\n",
            "Epoch 98: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 17s 983ms/step - loss: 0.0061 - capsnet_loss: 0.0032 - decoder_loss: 0.0073 - capsnet_accuracy: 1.0000 - val_loss: 0.0429 - val_capsnet_loss: 0.0400 - val_decoder_loss: 0.0075 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0055 - capsnet_loss: 0.0026 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000\n",
            "Epoch 99: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 958ms/step - loss: 0.0055 - capsnet_loss: 0.0026 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000 - val_loss: 0.0442 - val_capsnet_loss: 0.0411 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0050 - capsnet_loss: 0.0021 - decoder_loss: 0.0074 - capsnet_accuracy: 1.0000\n",
            "Epoch 100: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 961ms/step - loss: 0.0050 - capsnet_loss: 0.0021 - decoder_loss: 0.0074 - capsnet_accuracy: 1.0000 - val_loss: 0.0476 - val_capsnet_loss: 0.0447 - val_decoder_loss: 0.0072 - val_capsnet_accuracy: 0.9645 - lr: 1.0000e-04\n",
            "Best Validation Accuracy:0.9645389914512634\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------Begin: test------------------------------\n",
            "Test acc: 0.9645390070921985\n",
            "Precision:0.9594594594594594\n",
            "recall:0.9726027397260274\n",
            "f1:0.9659863945578231\n",
            "AUC:0.964242546333602\n",
            "Sensitivity:0.9726027397260274\n",
            "specificity:0.9558823529411765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RIMONE_DL"
      ],
      "metadata": {
        "id": "Pew1v4oH1daa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0JBlqQvOlE1",
        "outputId": "2026ca98-1d0e-4f5c-cab2-8d71fdf1767c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args.batch_size = 32\n",
        "args.epochs = 100\n",
        "args.routings = 8\n",
        "data = get_acrima_dataset()\n",
        "get_model_train_test(data,args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-xC9-d9l1hGb",
        "outputId": "19c0c7df-bc89-4498-e618-ff1fddbab7ae"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(32, 64, 64, 3)]    0           []                               \n",
            "                                                                                                  \n",
            " conv0 (Conv2D)                 (32, 56, 56, 256)    62464       ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " primary_capsule_conv (Conv2D)  (32, 48, 48, 512)    10617344    ['conv0[0][0]']                  \n",
            "                                                                                                  \n",
            " primarycap_reshape (Reshape)   (32, 73728, 16)      0           ['primary_capsule_conv[0][0]']   \n",
            "                                                                                                  \n",
            " primary_capsule (Lambda)       (32, 73728, 16)      0           ['primarycap_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " digitcaps (CapsuleLayer)       (32, 2, 16)          37748736    ['primary_capsule[0][0]']        \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " mask_2 (Mask)                  (32, 32)             0           ['digitcaps[0][0]',              \n",
            "                                                                  'input_4[0][0]']                \n",
            "                                                                                                  \n",
            " capsnet (Length)               (32, 2)              0           ['digitcaps[0][0]']              \n",
            "                                                                                                  \n",
            " decoder (Sequential)           (None, 64, 64, 3)    13137408    ['mask_2[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 61,565,952\n",
            "Trainable params: 61,565,952\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17/17 [==============================] - ETA: 0s - loss: 0.4675 - capsnet_loss: 0.4293 - decoder_loss: 0.0973 - capsnet_accuracy: 0.5717\n",
            "Epoch 1: val_capsnet_accuracy improved from -inf to 0.51773, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 17s 971ms/step - loss: 0.4675 - capsnet_loss: 0.4293 - decoder_loss: 0.0973 - capsnet_accuracy: 0.5717 - val_loss: 0.4250 - val_capsnet_loss: 0.3867 - val_decoder_loss: 0.0977 - val_capsnet_accuracy: 0.5177 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.2827 - capsnet_loss: 0.2446 - decoder_loss: 0.0972 - capsnet_accuracy: 0.6504\n",
            "Epoch 2: val_capsnet_accuracy improved from 0.51773 to 0.73050, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 16s 981ms/step - loss: 0.2827 - capsnet_loss: 0.2446 - decoder_loss: 0.0972 - capsnet_accuracy: 0.6504 - val_loss: 0.2126 - val_capsnet_loss: 0.1745 - val_decoder_loss: 0.0971 - val_capsnet_accuracy: 0.7305 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.2199 - capsnet_loss: 0.1825 - decoder_loss: 0.0952 - capsnet_accuracy: 0.7350\n",
            "Epoch 3: val_capsnet_accuracy did not improve from 0.73050\n",
            "17/17 [==============================] - 16s 919ms/step - loss: 0.2199 - capsnet_loss: 0.1825 - decoder_loss: 0.0952 - capsnet_accuracy: 0.7350 - val_loss: 0.3149 - val_capsnet_loss: 0.2774 - val_decoder_loss: 0.0956 - val_capsnet_accuracy: 0.6028 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.1777 - capsnet_loss: 0.1412 - decoder_loss: 0.0929 - capsnet_accuracy: 0.7932\n",
            "Epoch 4: val_capsnet_accuracy improved from 0.73050 to 0.75887, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 16s 966ms/step - loss: 0.1777 - capsnet_loss: 0.1412 - decoder_loss: 0.0929 - capsnet_accuracy: 0.7932 - val_loss: 0.1757 - val_capsnet_loss: 0.1402 - val_decoder_loss: 0.0905 - val_capsnet_accuracy: 0.7589 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.1268 - capsnet_loss: 0.0935 - decoder_loss: 0.0850 - capsnet_accuracy: 0.8741\n",
            "Epoch 5: val_capsnet_accuracy improved from 0.75887 to 0.83688, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 16s 970ms/step - loss: 0.1268 - capsnet_loss: 0.0935 - decoder_loss: 0.0850 - capsnet_accuracy: 0.8741 - val_loss: 0.1501 - val_capsnet_loss: 0.1189 - val_decoder_loss: 0.0795 - val_capsnet_accuracy: 0.8369 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.1327 - capsnet_loss: 0.1058 - decoder_loss: 0.0687 - capsnet_accuracy: 0.8609\n",
            "Epoch 6: val_capsnet_accuracy improved from 0.83688 to 0.85816, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 16s 975ms/step - loss: 0.1327 - capsnet_loss: 0.1058 - decoder_loss: 0.0687 - capsnet_accuracy: 0.8609 - val_loss: 0.1180 - val_capsnet_loss: 0.0964 - val_decoder_loss: 0.0549 - val_capsnet_accuracy: 0.8582 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0987 - capsnet_loss: 0.0817 - decoder_loss: 0.0433 - capsnet_accuracy: 0.8891\n",
            "Epoch 7: val_capsnet_accuracy did not improve from 0.85816\n",
            "17/17 [==============================] - 16s 948ms/step - loss: 0.0987 - capsnet_loss: 0.0817 - decoder_loss: 0.0433 - capsnet_accuracy: 0.8891 - val_loss: 0.1254 - val_capsnet_loss: 0.1139 - val_decoder_loss: 0.0294 - val_capsnet_accuracy: 0.8369 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0923 - capsnet_loss: 0.0828 - decoder_loss: 0.0244 - capsnet_accuracy: 0.8872\n",
            "Epoch 8: val_capsnet_accuracy improved from 0.85816 to 0.90071, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 16s 962ms/step - loss: 0.0923 - capsnet_loss: 0.0828 - decoder_loss: 0.0244 - capsnet_accuracy: 0.8872 - val_loss: 0.0857 - val_capsnet_loss: 0.0788 - val_decoder_loss: 0.0175 - val_capsnet_accuracy: 0.9007 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0856 - capsnet_loss: 0.0779 - decoder_loss: 0.0196 - capsnet_accuracy: 0.9004\n",
            "Epoch 9: val_capsnet_accuracy improved from 0.90071 to 0.91489, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 16s 964ms/step - loss: 0.0856 - capsnet_loss: 0.0779 - decoder_loss: 0.0196 - capsnet_accuracy: 0.9004 - val_loss: 0.0823 - val_capsnet_loss: 0.0762 - val_decoder_loss: 0.0157 - val_capsnet_accuracy: 0.9149 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0752 - capsnet_loss: 0.0676 - decoder_loss: 0.0196 - capsnet_accuracy: 0.9079\n",
            "Epoch 10: val_capsnet_accuracy did not improve from 0.91489\n",
            "17/17 [==============================] - 16s 955ms/step - loss: 0.0752 - capsnet_loss: 0.0676 - decoder_loss: 0.0196 - capsnet_accuracy: 0.9079 - val_loss: 0.0774 - val_capsnet_loss: 0.0715 - val_decoder_loss: 0.0151 - val_capsnet_accuracy: 0.9078 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0763 - capsnet_loss: 0.0692 - decoder_loss: 0.0180 - capsnet_accuracy: 0.9004\n",
            "Epoch 11: val_capsnet_accuracy did not improve from 0.91489\n",
            "17/17 [==============================] - 16s 955ms/step - loss: 0.0763 - capsnet_loss: 0.0692 - decoder_loss: 0.0180 - capsnet_accuracy: 0.9004 - val_loss: 0.0740 - val_capsnet_loss: 0.0681 - val_decoder_loss: 0.0150 - val_capsnet_accuracy: 0.8865 - lr: 1.0000e-04\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0687 - capsnet_loss: 0.0617 - decoder_loss: 0.0178 - capsnet_accuracy: 0.9154\n",
            "Epoch 12: val_capsnet_accuracy did not improve from 0.91489\n",
            "17/17 [==============================] - 16s 955ms/step - loss: 0.0687 - capsnet_loss: 0.0617 - decoder_loss: 0.0178 - capsnet_accuracy: 0.9154 - val_loss: 0.0805 - val_capsnet_loss: 0.0747 - val_decoder_loss: 0.0148 - val_capsnet_accuracy: 0.9149 - lr: 1.0000e-04\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0633 - capsnet_loss: 0.0561 - decoder_loss: 0.0183 - capsnet_accuracy: 0.9192\n",
            "Epoch 13: val_capsnet_accuracy did not improve from 0.91489\n",
            "17/17 [==============================] - 16s 940ms/step - loss: 0.0633 - capsnet_loss: 0.0561 - decoder_loss: 0.0183 - capsnet_accuracy: 0.9192 - val_loss: 0.0752 - val_capsnet_loss: 0.0693 - val_decoder_loss: 0.0150 - val_capsnet_accuracy: 0.9007 - lr: 1.0000e-04\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0636 - capsnet_loss: 0.0566 - decoder_loss: 0.0177 - capsnet_accuracy: 0.9211\n",
            "Epoch 14: val_capsnet_accuracy improved from 0.91489 to 0.92908, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 16s 974ms/step - loss: 0.0636 - capsnet_loss: 0.0566 - decoder_loss: 0.0177 - capsnet_accuracy: 0.9211 - val_loss: 0.0674 - val_capsnet_loss: 0.0616 - val_decoder_loss: 0.0147 - val_capsnet_accuracy: 0.9291 - lr: 1.0000e-04\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0570 - capsnet_loss: 0.0500 - decoder_loss: 0.0180 - capsnet_accuracy: 0.9398\n",
            "Epoch 15: val_capsnet_accuracy did not improve from 0.92908\n",
            "17/17 [==============================] - 16s 946ms/step - loss: 0.0570 - capsnet_loss: 0.0500 - decoder_loss: 0.0180 - capsnet_accuracy: 0.9398 - val_loss: 0.0777 - val_capsnet_loss: 0.0719 - val_decoder_loss: 0.0149 - val_capsnet_accuracy: 0.9149 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0610 - capsnet_loss: 0.0541 - decoder_loss: 0.0175 - capsnet_accuracy: 0.9229\n",
            "Epoch 16: val_capsnet_accuracy did not improve from 0.92908\n",
            "17/17 [==============================] - 16s 960ms/step - loss: 0.0610 - capsnet_loss: 0.0541 - decoder_loss: 0.0175 - capsnet_accuracy: 0.9229 - val_loss: 0.0715 - val_capsnet_loss: 0.0657 - val_decoder_loss: 0.0148 - val_capsnet_accuracy: 0.9220 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0530 - capsnet_loss: 0.0459 - decoder_loss: 0.0179 - capsnet_accuracy: 0.9380\n",
            "Epoch 17: val_capsnet_accuracy did not improve from 0.92908\n",
            "17/17 [==============================] - 16s 942ms/step - loss: 0.0530 - capsnet_loss: 0.0459 - decoder_loss: 0.0179 - capsnet_accuracy: 0.9380 - val_loss: 0.0882 - val_capsnet_loss: 0.0823 - val_decoder_loss: 0.0150 - val_capsnet_accuracy: 0.8936 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0624 - capsnet_loss: 0.0554 - decoder_loss: 0.0179 - capsnet_accuracy: 0.9286\n",
            "Epoch 18: val_capsnet_accuracy did not improve from 0.92908\n",
            "17/17 [==============================] - 16s 963ms/step - loss: 0.0624 - capsnet_loss: 0.0554 - decoder_loss: 0.0179 - capsnet_accuracy: 0.9286 - val_loss: 0.0741 - val_capsnet_loss: 0.0683 - val_decoder_loss: 0.0149 - val_capsnet_accuracy: 0.9149 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0513 - capsnet_loss: 0.0444 - decoder_loss: 0.0177 - capsnet_accuracy: 0.9393\n",
            "Epoch 19: val_capsnet_accuracy improved from 0.92908 to 0.94326, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 17s 993ms/step - loss: 0.0513 - capsnet_loss: 0.0444 - decoder_loss: 0.0177 - capsnet_accuracy: 0.9393 - val_loss: 0.0625 - val_capsnet_loss: 0.0568 - val_decoder_loss: 0.0147 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0522 - capsnet_loss: 0.0455 - decoder_loss: 0.0171 - capsnet_accuracy: 0.9474\n",
            "Epoch 20: val_capsnet_accuracy improved from 0.94326 to 0.95035, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 17s 1s/step - loss: 0.0522 - capsnet_loss: 0.0455 - decoder_loss: 0.0171 - capsnet_accuracy: 0.9474 - val_loss: 0.0669 - val_capsnet_loss: 0.0612 - val_decoder_loss: 0.0147 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0444 - capsnet_loss: 0.0374 - decoder_loss: 0.0177 - capsnet_accuracy: 0.9586\n",
            "Epoch 21: val_capsnet_accuracy did not improve from 0.95035\n",
            "17/17 [==============================] - 16s 950ms/step - loss: 0.0444 - capsnet_loss: 0.0374 - decoder_loss: 0.0177 - capsnet_accuracy: 0.9586 - val_loss: 0.0700 - val_capsnet_loss: 0.0643 - val_decoder_loss: 0.0146 - val_capsnet_accuracy: 0.9149 - lr: 1.0000e-04\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0451 - capsnet_loss: 0.0382 - decoder_loss: 0.0175 - capsnet_accuracy: 0.9530\n",
            "Epoch 22: val_capsnet_accuracy did not improve from 0.95035\n",
            "17/17 [==============================] - 16s 948ms/step - loss: 0.0451 - capsnet_loss: 0.0382 - decoder_loss: 0.0175 - capsnet_accuracy: 0.9530 - val_loss: 0.0596 - val_capsnet_loss: 0.0540 - val_decoder_loss: 0.0142 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0466 - capsnet_loss: 0.0401 - decoder_loss: 0.0166 - capsnet_accuracy: 0.9568\n",
            "Epoch 23: val_capsnet_accuracy did not improve from 0.95035\n",
            "17/17 [==============================] - 16s 945ms/step - loss: 0.0466 - capsnet_loss: 0.0401 - decoder_loss: 0.0166 - capsnet_accuracy: 0.9568 - val_loss: 0.0585 - val_capsnet_loss: 0.0530 - val_decoder_loss: 0.0140 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0444 - capsnet_loss: 0.0376 - decoder_loss: 0.0175 - capsnet_accuracy: 0.9586\n",
            "Epoch 24: val_capsnet_accuracy did not improve from 0.95035\n",
            "17/17 [==============================] - 16s 945ms/step - loss: 0.0444 - capsnet_loss: 0.0376 - decoder_loss: 0.0175 - capsnet_accuracy: 0.9586 - val_loss: 0.0623 - val_capsnet_loss: 0.0568 - val_decoder_loss: 0.0142 - val_capsnet_accuracy: 0.9291 - lr: 1.0000e-04\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0430 - capsnet_loss: 0.0364 - decoder_loss: 0.0169 - capsnet_accuracy: 0.9568\n",
            "Epoch 25: val_capsnet_accuracy did not improve from 0.95035\n",
            "17/17 [==============================] - 16s 962ms/step - loss: 0.0430 - capsnet_loss: 0.0364 - decoder_loss: 0.0169 - capsnet_accuracy: 0.9568 - val_loss: 0.0632 - val_capsnet_loss: 0.0576 - val_decoder_loss: 0.0144 - val_capsnet_accuracy: 0.9149 - lr: 1.0000e-04\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0432 - capsnet_loss: 0.0365 - decoder_loss: 0.0172 - capsnet_accuracy: 0.9586\n",
            "Epoch 26: val_capsnet_accuracy did not improve from 0.95035\n",
            "17/17 [==============================] - 16s 960ms/step - loss: 0.0432 - capsnet_loss: 0.0365 - decoder_loss: 0.0172 - capsnet_accuracy: 0.9586 - val_loss: 0.0557 - val_capsnet_loss: 0.0502 - val_decoder_loss: 0.0140 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0368 - capsnet_loss: 0.0302 - decoder_loss: 0.0169 - capsnet_accuracy: 0.9680\n",
            "Epoch 27: val_capsnet_accuracy did not improve from 0.95035\n",
            "17/17 [==============================] - 16s 943ms/step - loss: 0.0368 - capsnet_loss: 0.0302 - decoder_loss: 0.0169 - capsnet_accuracy: 0.9680 - val_loss: 0.0604 - val_capsnet_loss: 0.0550 - val_decoder_loss: 0.0139 - val_capsnet_accuracy: 0.9291 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0398 - capsnet_loss: 0.0333 - decoder_loss: 0.0165 - capsnet_accuracy: 0.9793\n",
            "Epoch 28: val_capsnet_accuracy did not improve from 0.95035\n",
            "17/17 [==============================] - 16s 945ms/step - loss: 0.0398 - capsnet_loss: 0.0333 - decoder_loss: 0.0165 - capsnet_accuracy: 0.9793 - val_loss: 0.0706 - val_capsnet_loss: 0.0650 - val_decoder_loss: 0.0142 - val_capsnet_accuracy: 0.9291 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0393 - capsnet_loss: 0.0328 - decoder_loss: 0.0167 - capsnet_accuracy: 0.9605\n",
            "Epoch 29: val_capsnet_accuracy did not improve from 0.95035\n",
            "17/17 [==============================] - 16s 943ms/step - loss: 0.0393 - capsnet_loss: 0.0328 - decoder_loss: 0.0167 - capsnet_accuracy: 0.9605 - val_loss: 0.0571 - val_capsnet_loss: 0.0517 - val_decoder_loss: 0.0138 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0362 - capsnet_loss: 0.0298 - decoder_loss: 0.0163 - capsnet_accuracy: 0.9737\n",
            "Epoch 30: val_capsnet_accuracy did not improve from 0.95035\n",
            "17/17 [==============================] - 16s 942ms/step - loss: 0.0362 - capsnet_loss: 0.0298 - decoder_loss: 0.0163 - capsnet_accuracy: 0.9737 - val_loss: 0.0658 - val_capsnet_loss: 0.0603 - val_decoder_loss: 0.0139 - val_capsnet_accuracy: 0.9220 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0371 - capsnet_loss: 0.0304 - decoder_loss: 0.0171 - capsnet_accuracy: 0.9718\n",
            "Epoch 31: val_capsnet_accuracy did not improve from 0.95035\n",
            "17/17 [==============================] - 16s 960ms/step - loss: 0.0371 - capsnet_loss: 0.0304 - decoder_loss: 0.0171 - capsnet_accuracy: 0.9718 - val_loss: 0.0552 - val_capsnet_loss: 0.0499 - val_decoder_loss: 0.0134 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0327 - capsnet_loss: 0.0265 - decoder_loss: 0.0156 - capsnet_accuracy: 0.9643\n",
            "Epoch 32: val_capsnet_accuracy did not improve from 0.95035\n",
            "17/17 [==============================] - 16s 960ms/step - loss: 0.0327 - capsnet_loss: 0.0265 - decoder_loss: 0.0156 - capsnet_accuracy: 0.9643 - val_loss: 0.0596 - val_capsnet_loss: 0.0543 - val_decoder_loss: 0.0136 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0343 - capsnet_loss: 0.0281 - decoder_loss: 0.0159 - capsnet_accuracy: 0.9699\n",
            "Epoch 33: val_capsnet_accuracy did not improve from 0.95035\n",
            "17/17 [==============================] - 16s 943ms/step - loss: 0.0343 - capsnet_loss: 0.0281 - decoder_loss: 0.0159 - capsnet_accuracy: 0.9699 - val_loss: 0.0637 - val_capsnet_loss: 0.0585 - val_decoder_loss: 0.0131 - val_capsnet_accuracy: 0.9149 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0364 - capsnet_loss: 0.0303 - decoder_loss: 0.0156 - capsnet_accuracy: 0.9662\n",
            "Epoch 34: val_capsnet_accuracy did not improve from 0.95035\n",
            "17/17 [==============================] - 16s 942ms/step - loss: 0.0364 - capsnet_loss: 0.0303 - decoder_loss: 0.0156 - capsnet_accuracy: 0.9662 - val_loss: 0.0624 - val_capsnet_loss: 0.0572 - val_decoder_loss: 0.0133 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0282 - capsnet_loss: 0.0221 - decoder_loss: 0.0155 - capsnet_accuracy: 0.9812\n",
            "Epoch 35: val_capsnet_accuracy did not improve from 0.95035\n",
            "17/17 [==============================] - 16s 962ms/step - loss: 0.0282 - capsnet_loss: 0.0221 - decoder_loss: 0.0155 - capsnet_accuracy: 0.9812 - val_loss: 0.0534 - val_capsnet_loss: 0.0484 - val_decoder_loss: 0.0128 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0287 - capsnet_loss: 0.0229 - decoder_loss: 0.0149 - capsnet_accuracy: 0.9812\n",
            "Epoch 36: val_capsnet_accuracy improved from 0.95035 to 0.95745, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 16s 973ms/step - loss: 0.0287 - capsnet_loss: 0.0229 - decoder_loss: 0.0149 - capsnet_accuracy: 0.9812 - val_loss: 0.0527 - val_capsnet_loss: 0.0479 - val_decoder_loss: 0.0124 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0262 - capsnet_loss: 0.0205 - decoder_loss: 0.0146 - capsnet_accuracy: 0.9835\n",
            "Epoch 37: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 17s 980ms/step - loss: 0.0262 - capsnet_loss: 0.0205 - decoder_loss: 0.0146 - capsnet_accuracy: 0.9835 - val_loss: 0.0636 - val_capsnet_loss: 0.0588 - val_decoder_loss: 0.0123 - val_capsnet_accuracy: 0.9220 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0286 - capsnet_loss: 0.0230 - decoder_loss: 0.0144 - capsnet_accuracy: 0.9793\n",
            "Epoch 38: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 980ms/step - loss: 0.0286 - capsnet_loss: 0.0230 - decoder_loss: 0.0144 - capsnet_accuracy: 0.9793 - val_loss: 0.0530 - val_capsnet_loss: 0.0483 - val_decoder_loss: 0.0119 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0221 - capsnet_loss: 0.0168 - decoder_loss: 0.0137 - capsnet_accuracy: 0.9850\n",
            "Epoch 39: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 962ms/step - loss: 0.0221 - capsnet_loss: 0.0168 - decoder_loss: 0.0137 - capsnet_accuracy: 0.9850 - val_loss: 0.0531 - val_capsnet_loss: 0.0485 - val_decoder_loss: 0.0118 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0273 - capsnet_loss: 0.0221 - decoder_loss: 0.0133 - capsnet_accuracy: 0.9737\n",
            "Epoch 40: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 945ms/step - loss: 0.0273 - capsnet_loss: 0.0221 - decoder_loss: 0.0133 - capsnet_accuracy: 0.9737 - val_loss: 0.0551 - val_capsnet_loss: 0.0505 - val_decoder_loss: 0.0117 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0216 - capsnet_loss: 0.0164 - decoder_loss: 0.0132 - capsnet_accuracy: 0.9887\n",
            "Epoch 41: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 943ms/step - loss: 0.0216 - capsnet_loss: 0.0164 - decoder_loss: 0.0132 - capsnet_accuracy: 0.9887 - val_loss: 0.0525 - val_capsnet_loss: 0.0480 - val_decoder_loss: 0.0113 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0290 - capsnet_loss: 0.0239 - decoder_loss: 0.0130 - capsnet_accuracy: 0.9774\n",
            "Epoch 42: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 961ms/step - loss: 0.0290 - capsnet_loss: 0.0239 - decoder_loss: 0.0130 - capsnet_accuracy: 0.9774 - val_loss: 0.0482 - val_capsnet_loss: 0.0439 - val_decoder_loss: 0.0110 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0278 - capsnet_loss: 0.0229 - decoder_loss: 0.0125 - capsnet_accuracy: 0.9793\n",
            "Epoch 43: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 943ms/step - loss: 0.0278 - capsnet_loss: 0.0229 - decoder_loss: 0.0125 - capsnet_accuracy: 0.9793 - val_loss: 0.0548 - val_capsnet_loss: 0.0505 - val_decoder_loss: 0.0110 - val_capsnet_accuracy: 0.9291 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0233 - capsnet_loss: 0.0184 - decoder_loss: 0.0125 - capsnet_accuracy: 0.9831\n",
            "Epoch 44: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 946ms/step - loss: 0.0233 - capsnet_loss: 0.0184 - decoder_loss: 0.0125 - capsnet_accuracy: 0.9831 - val_loss: 0.0521 - val_capsnet_loss: 0.0479 - val_decoder_loss: 0.0107 - val_capsnet_accuracy: 0.9291 - lr: 1.0000e-04\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0220 - capsnet_loss: 0.0171 - decoder_loss: 0.0125 - capsnet_accuracy: 0.9944\n",
            "Epoch 45: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 958ms/step - loss: 0.0220 - capsnet_loss: 0.0171 - decoder_loss: 0.0125 - capsnet_accuracy: 0.9944 - val_loss: 0.0483 - val_capsnet_loss: 0.0441 - val_decoder_loss: 0.0106 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0217 - capsnet_loss: 0.0168 - decoder_loss: 0.0123 - capsnet_accuracy: 0.9812\n",
            "Epoch 46: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 963ms/step - loss: 0.0217 - capsnet_loss: 0.0168 - decoder_loss: 0.0123 - capsnet_accuracy: 0.9812 - val_loss: 0.0470 - val_capsnet_loss: 0.0428 - val_decoder_loss: 0.0106 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0225 - capsnet_loss: 0.0179 - decoder_loss: 0.0119 - capsnet_accuracy: 0.9831\n",
            "Epoch 47: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 942ms/step - loss: 0.0225 - capsnet_loss: 0.0179 - decoder_loss: 0.0119 - capsnet_accuracy: 0.9831 - val_loss: 0.0494 - val_capsnet_loss: 0.0453 - val_decoder_loss: 0.0106 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0190 - capsnet_loss: 0.0146 - decoder_loss: 0.0113 - capsnet_accuracy: 0.9925\n",
            "Epoch 48: val_capsnet_accuracy did not improve from 0.95745\n",
            "17/17 [==============================] - 16s 960ms/step - loss: 0.0190 - capsnet_loss: 0.0146 - decoder_loss: 0.0113 - capsnet_accuracy: 0.9925 - val_loss: 0.0521 - val_capsnet_loss: 0.0482 - val_decoder_loss: 0.0101 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0184 - capsnet_loss: 0.0137 - decoder_loss: 0.0120 - capsnet_accuracy: 0.9887\n",
            "Epoch 49: val_capsnet_accuracy improved from 0.95745 to 0.96454, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 17s 989ms/step - loss: 0.0184 - capsnet_loss: 0.0137 - decoder_loss: 0.0120 - capsnet_accuracy: 0.9887 - val_loss: 0.0482 - val_capsnet_loss: 0.0442 - val_decoder_loss: 0.0102 - val_capsnet_accuracy: 0.9645 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0160 - capsnet_loss: 0.0117 - decoder_loss: 0.0109 - capsnet_accuracy: 0.9944\n",
            "Epoch 50: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 944ms/step - loss: 0.0160 - capsnet_loss: 0.0117 - decoder_loss: 0.0109 - capsnet_accuracy: 0.9944 - val_loss: 0.0552 - val_capsnet_loss: 0.0512 - val_decoder_loss: 0.0104 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0184 - capsnet_loss: 0.0139 - decoder_loss: 0.0113 - capsnet_accuracy: 0.9887\n",
            "Epoch 51: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 959ms/step - loss: 0.0184 - capsnet_loss: 0.0139 - decoder_loss: 0.0113 - capsnet_accuracy: 0.9887 - val_loss: 0.0541 - val_capsnet_loss: 0.0500 - val_decoder_loss: 0.0104 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0177 - capsnet_loss: 0.0134 - decoder_loss: 0.0111 - capsnet_accuracy: 0.9868\n",
            "Epoch 52: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 960ms/step - loss: 0.0177 - capsnet_loss: 0.0134 - decoder_loss: 0.0111 - capsnet_accuracy: 0.9868 - val_loss: 0.0544 - val_capsnet_loss: 0.0506 - val_decoder_loss: 0.0098 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0143 - capsnet_loss: 0.0101 - decoder_loss: 0.0108 - capsnet_accuracy: 0.9925\n",
            "Epoch 53: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 957ms/step - loss: 0.0143 - capsnet_loss: 0.0101 - decoder_loss: 0.0108 - capsnet_accuracy: 0.9925 - val_loss: 0.0430 - val_capsnet_loss: 0.0392 - val_decoder_loss: 0.0097 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0155 - capsnet_loss: 0.0112 - decoder_loss: 0.0109 - capsnet_accuracy: 0.9906\n",
            "Epoch 54: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 948ms/step - loss: 0.0155 - capsnet_loss: 0.0112 - decoder_loss: 0.0109 - capsnet_accuracy: 0.9906 - val_loss: 0.0455 - val_capsnet_loss: 0.0418 - val_decoder_loss: 0.0094 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0136 - capsnet_loss: 0.0094 - decoder_loss: 0.0105 - capsnet_accuracy: 0.9890\n",
            "Epoch 55: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 17s 978ms/step - loss: 0.0136 - capsnet_loss: 0.0094 - decoder_loss: 0.0105 - capsnet_accuracy: 0.9890 - val_loss: 0.0433 - val_capsnet_loss: 0.0396 - val_decoder_loss: 0.0093 - val_capsnet_accuracy: 0.9645 - lr: 1.0000e-04\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0156 - capsnet_loss: 0.0115 - decoder_loss: 0.0105 - capsnet_accuracy: 0.9925\n",
            "Epoch 56: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 961ms/step - loss: 0.0156 - capsnet_loss: 0.0115 - decoder_loss: 0.0105 - capsnet_accuracy: 0.9925 - val_loss: 0.0469 - val_capsnet_loss: 0.0433 - val_decoder_loss: 0.0091 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0145 - capsnet_loss: 0.0104 - decoder_loss: 0.0104 - capsnet_accuracy: 0.9925\n",
            "Epoch 57: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 963ms/step - loss: 0.0145 - capsnet_loss: 0.0104 - decoder_loss: 0.0104 - capsnet_accuracy: 0.9925 - val_loss: 0.0471 - val_capsnet_loss: 0.0433 - val_decoder_loss: 0.0097 - val_capsnet_accuracy: 0.9645 - lr: 1.0000e-04\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0140 - capsnet_loss: 0.0100 - decoder_loss: 0.0102 - capsnet_accuracy: 0.9944\n",
            "Epoch 58: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 946ms/step - loss: 0.0140 - capsnet_loss: 0.0100 - decoder_loss: 0.0102 - capsnet_accuracy: 0.9944 - val_loss: 0.0544 - val_capsnet_loss: 0.0508 - val_decoder_loss: 0.0093 - val_capsnet_accuracy: 0.9291 - lr: 1.0000e-04\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0164 - capsnet_loss: 0.0123 - decoder_loss: 0.0105 - capsnet_accuracy: 0.9906\n",
            "Epoch 59: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 945ms/step - loss: 0.0164 - capsnet_loss: 0.0123 - decoder_loss: 0.0105 - capsnet_accuracy: 0.9906 - val_loss: 0.0487 - val_capsnet_loss: 0.0448 - val_decoder_loss: 0.0100 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0164 - capsnet_loss: 0.0124 - decoder_loss: 0.0103 - capsnet_accuracy: 0.9944\n",
            "Epoch 60: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 945ms/step - loss: 0.0164 - capsnet_loss: 0.0124 - decoder_loss: 0.0103 - capsnet_accuracy: 0.9944 - val_loss: 0.0525 - val_capsnet_loss: 0.0487 - val_decoder_loss: 0.0095 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0135 - capsnet_loss: 0.0097 - decoder_loss: 0.0097 - capsnet_accuracy: 0.9962\n",
            "Epoch 61: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 945ms/step - loss: 0.0135 - capsnet_loss: 0.0097 - decoder_loss: 0.0097 - capsnet_accuracy: 0.9962 - val_loss: 0.0452 - val_capsnet_loss: 0.0417 - val_decoder_loss: 0.0089 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0128 - capsnet_loss: 0.0089 - decoder_loss: 0.0099 - capsnet_accuracy: 0.9944\n",
            "Epoch 62: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 957ms/step - loss: 0.0128 - capsnet_loss: 0.0089 - decoder_loss: 0.0099 - capsnet_accuracy: 0.9944 - val_loss: 0.0461 - val_capsnet_loss: 0.0427 - val_decoder_loss: 0.0086 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0152 - capsnet_loss: 0.0115 - decoder_loss: 0.0093 - capsnet_accuracy: 0.9925\n",
            "Epoch 63: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 958ms/step - loss: 0.0152 - capsnet_loss: 0.0115 - decoder_loss: 0.0093 - capsnet_accuracy: 0.9925 - val_loss: 0.0427 - val_capsnet_loss: 0.0393 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0136 - capsnet_loss: 0.0098 - decoder_loss: 0.0097 - capsnet_accuracy: 0.9906\n",
            "Epoch 64: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 942ms/step - loss: 0.0136 - capsnet_loss: 0.0098 - decoder_loss: 0.0097 - capsnet_accuracy: 0.9906 - val_loss: 0.0480 - val_capsnet_loss: 0.0445 - val_decoder_loss: 0.0089 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0120 - capsnet_loss: 0.0082 - decoder_loss: 0.0097 - capsnet_accuracy: 0.9925\n",
            "Epoch 65: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 952ms/step - loss: 0.0120 - capsnet_loss: 0.0082 - decoder_loss: 0.0097 - capsnet_accuracy: 0.9925 - val_loss: 0.0447 - val_capsnet_loss: 0.0413 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0100 - capsnet_loss: 0.0064 - decoder_loss: 0.0093 - capsnet_accuracy: 0.9981\n",
            "Epoch 66: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 957ms/step - loss: 0.0100 - capsnet_loss: 0.0064 - decoder_loss: 0.0093 - capsnet_accuracy: 0.9981 - val_loss: 0.0497 - val_capsnet_loss: 0.0463 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0135 - capsnet_loss: 0.0099 - decoder_loss: 0.0092 - capsnet_accuracy: 0.9906\n",
            "Epoch 67: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 942ms/step - loss: 0.0135 - capsnet_loss: 0.0099 - decoder_loss: 0.0092 - capsnet_accuracy: 0.9906 - val_loss: 0.0437 - val_capsnet_loss: 0.0404 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0121 - capsnet_loss: 0.0086 - decoder_loss: 0.0089 - capsnet_accuracy: 0.9925\n",
            "Epoch 68: val_capsnet_accuracy did not improve from 0.96454\n",
            "17/17 [==============================] - 16s 958ms/step - loss: 0.0121 - capsnet_loss: 0.0086 - decoder_loss: 0.0089 - capsnet_accuracy: 0.9925 - val_loss: 0.0469 - val_capsnet_loss: 0.0436 - val_decoder_loss: 0.0082 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0138 - capsnet_loss: 0.0102 - decoder_loss: 0.0091 - capsnet_accuracy: 0.9944\n",
            "Epoch 69: val_capsnet_accuracy improved from 0.96454 to 0.97163, saving model to ./result/weights.h5\n",
            "17/17 [==============================] - 17s 999ms/step - loss: 0.0138 - capsnet_loss: 0.0102 - decoder_loss: 0.0091 - capsnet_accuracy: 0.9944 - val_loss: 0.0497 - val_capsnet_loss: 0.0461 - val_decoder_loss: 0.0092 - val_capsnet_accuracy: 0.9716 - lr: 1.0000e-04\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0118 - capsnet_loss: 0.0082 - decoder_loss: 0.0093 - capsnet_accuracy: 0.9981\n",
            "Epoch 70: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 943ms/step - loss: 0.0118 - capsnet_loss: 0.0082 - decoder_loss: 0.0093 - capsnet_accuracy: 0.9981 - val_loss: 0.0486 - val_capsnet_loss: 0.0452 - val_decoder_loss: 0.0088 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0112 - capsnet_loss: 0.0077 - decoder_loss: 0.0090 - capsnet_accuracy: 0.9944\n",
            "Epoch 71: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 959ms/step - loss: 0.0112 - capsnet_loss: 0.0077 - decoder_loss: 0.0090 - capsnet_accuracy: 0.9944 - val_loss: 0.0526 - val_capsnet_loss: 0.0493 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0139 - capsnet_loss: 0.0104 - decoder_loss: 0.0090 - capsnet_accuracy: 0.9944\n",
            "Epoch 72: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 962ms/step - loss: 0.0139 - capsnet_loss: 0.0104 - decoder_loss: 0.0090 - capsnet_accuracy: 0.9944 - val_loss: 0.0415 - val_capsnet_loss: 0.0380 - val_decoder_loss: 0.0088 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0095 - capsnet_loss: 0.0061 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9963\n",
            "Epoch 73: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 966ms/step - loss: 0.0095 - capsnet_loss: 0.0061 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9963 - val_loss: 0.0440 - val_capsnet_loss: 0.0409 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0108 - capsnet_loss: 0.0074 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9962\n",
            "Epoch 74: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 979ms/step - loss: 0.0108 - capsnet_loss: 0.0074 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9962 - val_loss: 0.0507 - val_capsnet_loss: 0.0474 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0095 - capsnet_loss: 0.0059 - decoder_loss: 0.0090 - capsnet_accuracy: 0.9981\n",
            "Epoch 75: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 960ms/step - loss: 0.0095 - capsnet_loss: 0.0059 - decoder_loss: 0.0090 - capsnet_accuracy: 0.9981 - val_loss: 0.0409 - val_capsnet_loss: 0.0377 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0079 - capsnet_loss: 0.0047 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9981\n",
            "Epoch 76: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 944ms/step - loss: 0.0079 - capsnet_loss: 0.0047 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9981 - val_loss: 0.0419 - val_capsnet_loss: 0.0388 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.9645 - lr: 1.0000e-04\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0099 - capsnet_loss: 0.0064 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9981\n",
            "Epoch 77: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 960ms/step - loss: 0.0099 - capsnet_loss: 0.0064 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9981 - val_loss: 0.0415 - val_capsnet_loss: 0.0384 - val_decoder_loss: 0.0081 - val_capsnet_accuracy: 0.9645 - lr: 1.0000e-04\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0098 - capsnet_loss: 0.0064 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9962\n",
            "Epoch 78: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 961ms/step - loss: 0.0098 - capsnet_loss: 0.0064 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9962 - val_loss: 0.0415 - val_capsnet_loss: 0.0381 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.9716 - lr: 1.0000e-04\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0119 - capsnet_loss: 0.0085 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9962\n",
            "Epoch 79: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 958ms/step - loss: 0.0119 - capsnet_loss: 0.0085 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9962 - val_loss: 0.0480 - val_capsnet_loss: 0.0445 - val_decoder_loss: 0.0089 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0107 - capsnet_loss: 0.0073 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9981\n",
            "Epoch 80: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 959ms/step - loss: 0.0107 - capsnet_loss: 0.0073 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9981 - val_loss: 0.0419 - val_capsnet_loss: 0.0386 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.9645 - lr: 1.0000e-04\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0082 - capsnet_loss: 0.0050 - decoder_loss: 0.0082 - capsnet_accuracy: 1.0000\n",
            "Epoch 81: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 942ms/step - loss: 0.0082 - capsnet_loss: 0.0050 - decoder_loss: 0.0082 - capsnet_accuracy: 1.0000 - val_loss: 0.0439 - val_capsnet_loss: 0.0407 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0082 - capsnet_loss: 0.0050 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9962\n",
            "Epoch 82: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 944ms/step - loss: 0.0082 - capsnet_loss: 0.0050 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9962 - val_loss: 0.0536 - val_capsnet_loss: 0.0504 - val_decoder_loss: 0.0081 - val_capsnet_accuracy: 0.9362 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0090 - capsnet_loss: 0.0056 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9981\n",
            "Epoch 83: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 959ms/step - loss: 0.0090 - capsnet_loss: 0.0056 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9981 - val_loss: 0.0435 - val_capsnet_loss: 0.0402 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0084 - capsnet_loss: 0.0052 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9981\n",
            "Epoch 84: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 958ms/step - loss: 0.0084 - capsnet_loss: 0.0052 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9981 - val_loss: 0.0387 - val_capsnet_loss: 0.0356 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0071 - capsnet_loss: 0.0039 - decoder_loss: 0.0081 - capsnet_accuracy: 1.0000\n",
            "Epoch 85: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 942ms/step - loss: 0.0071 - capsnet_loss: 0.0039 - decoder_loss: 0.0081 - capsnet_accuracy: 1.0000 - val_loss: 0.0430 - val_capsnet_loss: 0.0398 - val_decoder_loss: 0.0082 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0073 - capsnet_loss: 0.0042 - decoder_loss: 0.0079 - capsnet_accuracy: 0.9981\n",
            "Epoch 86: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 960ms/step - loss: 0.0073 - capsnet_loss: 0.0042 - decoder_loss: 0.0079 - capsnet_accuracy: 0.9981 - val_loss: 0.0395 - val_capsnet_loss: 0.0365 - val_decoder_loss: 0.0076 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0072 - capsnet_loss: 0.0041 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000\n",
            "Epoch 87: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 943ms/step - loss: 0.0072 - capsnet_loss: 0.0041 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000 - val_loss: 0.0417 - val_capsnet_loss: 0.0387 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0079 - capsnet_loss: 0.0048 - decoder_loss: 0.0079 - capsnet_accuracy: 1.0000\n",
            "Epoch 88: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 960ms/step - loss: 0.0079 - capsnet_loss: 0.0048 - decoder_loss: 0.0079 - capsnet_accuracy: 1.0000 - val_loss: 0.0417 - val_capsnet_loss: 0.0387 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.9645 - lr: 1.0000e-04\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0079 - capsnet_loss: 0.0048 - decoder_loss: 0.0078 - capsnet_accuracy: 1.0000\n",
            "Epoch 89: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 944ms/step - loss: 0.0079 - capsnet_loss: 0.0048 - decoder_loss: 0.0078 - capsnet_accuracy: 1.0000 - val_loss: 0.0421 - val_capsnet_loss: 0.0389 - val_decoder_loss: 0.0081 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0073 - capsnet_loss: 0.0042 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000\n",
            "Epoch 90: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 959ms/step - loss: 0.0073 - capsnet_loss: 0.0042 - decoder_loss: 0.0080 - capsnet_accuracy: 1.0000 - val_loss: 0.0542 - val_capsnet_loss: 0.0511 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0073 - capsnet_loss: 0.0043 - decoder_loss: 0.0077 - capsnet_accuracy: 1.0000\n",
            "Epoch 91: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 17s 980ms/step - loss: 0.0073 - capsnet_loss: 0.0043 - decoder_loss: 0.0077 - capsnet_accuracy: 1.0000 - val_loss: 0.0384 - val_capsnet_loss: 0.0355 - val_decoder_loss: 0.0075 - val_capsnet_accuracy: 0.9645 - lr: 1.0000e-04\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0058 - capsnet_loss: 0.0029 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000\n",
            "Epoch 92: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 982ms/step - loss: 0.0058 - capsnet_loss: 0.0029 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000 - val_loss: 0.0410 - val_capsnet_loss: 0.0381 - val_decoder_loss: 0.0075 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0056 - capsnet_loss: 0.0026 - decoder_loss: 0.0077 - capsnet_accuracy: 1.0000\n",
            "Epoch 93: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 948ms/step - loss: 0.0056 - capsnet_loss: 0.0026 - decoder_loss: 0.0077 - capsnet_accuracy: 1.0000 - val_loss: 0.0422 - val_capsnet_loss: 0.0392 - val_decoder_loss: 0.0076 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0053 - capsnet_loss: 0.0024 - decoder_loss: 0.0074 - capsnet_accuracy: 1.0000\n",
            "Epoch 94: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 963ms/step - loss: 0.0053 - capsnet_loss: 0.0024 - decoder_loss: 0.0074 - capsnet_accuracy: 1.0000 - val_loss: 0.0409 - val_capsnet_loss: 0.0380 - val_decoder_loss: 0.0074 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0061 - capsnet_loss: 0.0031 - decoder_loss: 0.0076 - capsnet_accuracy: 1.0000\n",
            "Epoch 95: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 959ms/step - loss: 0.0061 - capsnet_loss: 0.0031 - decoder_loss: 0.0076 - capsnet_accuracy: 1.0000 - val_loss: 0.0421 - val_capsnet_loss: 0.0392 - val_decoder_loss: 0.0073 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0064 - capsnet_loss: 0.0035 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000\n",
            "Epoch 96: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 959ms/step - loss: 0.0064 - capsnet_loss: 0.0035 - decoder_loss: 0.0075 - capsnet_accuracy: 1.0000 - val_loss: 0.0434 - val_capsnet_loss: 0.0404 - val_decoder_loss: 0.0076 - val_capsnet_accuracy: 0.9504 - lr: 1.0000e-04\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0099 - capsnet_loss: 0.0069 - decoder_loss: 0.0076 - capsnet_accuracy: 0.9981\n",
            "Epoch 97: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 944ms/step - loss: 0.0099 - capsnet_loss: 0.0069 - decoder_loss: 0.0076 - capsnet_accuracy: 0.9981 - val_loss: 0.0494 - val_capsnet_loss: 0.0464 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.9574 - lr: 1.0000e-04\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0113 - capsnet_loss: 0.0081 - decoder_loss: 0.0081 - capsnet_accuracy: 1.0000\n",
            "Epoch 98: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 946ms/step - loss: 0.0113 - capsnet_loss: 0.0081 - decoder_loss: 0.0081 - capsnet_accuracy: 1.0000 - val_loss: 0.0433 - val_capsnet_loss: 0.0399 - val_decoder_loss: 0.0086 - val_capsnet_accuracy: 0.9645 - lr: 1.0000e-04\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0081 - capsnet_loss: 0.0049 - decoder_loss: 0.0083 - capsnet_accuracy: 1.0000\n",
            "Epoch 99: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 944ms/step - loss: 0.0081 - capsnet_loss: 0.0049 - decoder_loss: 0.0083 - capsnet_accuracy: 1.0000 - val_loss: 0.0463 - val_capsnet_loss: 0.0428 - val_decoder_loss: 0.0089 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - ETA: 0s - loss: 0.0069 - capsnet_loss: 0.0038 - decoder_loss: 0.0078 - capsnet_accuracy: 1.0000\n",
            "Epoch 100: val_capsnet_accuracy did not improve from 0.97163\n",
            "17/17 [==============================] - 16s 944ms/step - loss: 0.0069 - capsnet_loss: 0.0038 - decoder_loss: 0.0078 - capsnet_accuracy: 1.0000 - val_loss: 0.0565 - val_capsnet_loss: 0.0532 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.9433 - lr: 1.0000e-04\n",
            "Best Validation Accuracy:0.9716312289237976\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------Begin: test------------------------------\n",
            "Test acc: 0.9716312056737588\n",
            "Precision:0.9726027397260274\n",
            "recall:0.9726027397260274\n",
            "f1:0.9726027397260274\n",
            "AUC:0.9715954875100724\n",
            "Sensitivity:0.9726027397260274\n",
            "specificity:0.9705882352941176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RIM-ONE-R2"
      ],
      "metadata": {
        "id": "_FuzBQdQcadk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjhkoFABcpO3",
        "outputId": "44b22ef6-9027-4fae-ed31-f21638602083"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1814"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}