{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "file_extension": ".py",
      "pygments_lexer": "ipython3",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "3.6.3",
      "name": "python"
    },
    "colab": {
      "name": "Copy_of_CapsuleNet_on_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gyanendar/ms_project/blob/main/Copy_of_CapsuleNet_on_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7f4c4917-22fb-4b10-879e-51c600e6c3af",
        "_uuid": "9b086e5ec535ad75eada3ca72bf5e6534251074f",
        "id": "LQnu9movo8xz"
      },
      "source": [
        "# Overview\n",
        "\n",
        "The new model CapsuleNet proposed by Sara Sabour (and Geoffry Hinton) claims to deliver state of the art results on [MNIST](https://arxiv.org/abs/1710.09829). The kernel aims to create and train the model using the Kaggle Dataset and then make a submission to see where it actually ends up. Given the constraint of using a Kaggle Kernel means it can't be trained as long as we would like or with GPU's but IMHO if a model can't be reasonably well trained in an hour on a 28x28 dataset, that model probably won't be too useful in the immediate future.\n",
        "\n",
        "## Implementation Details\n",
        "\n",
        "* Keras implementation of CapsNet in Hinton's paper Dynamic Routing Between Capsules.\n",
        "* Code adapted from https://github.com/XifengGuo/CapsNet-Keras/blob/master/capsulenet.py\n",
        "*  Author: Xifeng Guo, E-mail: `guoxifeng1990@163.com`, Github: `https://github.com/XifengGuo/CapsNet-Keras`\n",
        "*     The current version maybe only works for TensorFlow backend. Actually it will be straightforward to re-write to TF code.\n",
        "*     Adopting to other backends should be easy, but I have not tested this. \n",
        "\n",
        "Result:\n",
        "    Validation accuracy > 99.5% after 20 epochs. Still under-fitting.\n",
        "    About 110 seconds per epoch on a single GTX1070 GPU card\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "e30e2e10-a909-485d-be9d-dc6f592911a7",
        "_uuid": "c7e569699c6d067cd9fdf9c77299775e399b2ef3",
        "id": "qWnuqFe2o8x2",
        "outputId": "d8bc8d35-9227-49bf-fc1e-dec70d47a250",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "#from keras import callbacks\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import callbacks\n",
        "#from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9776fd57-44e0-4211-a7a5-c7e647a10704",
        "_uuid": "f4b5499a472b312d5c5f0274ad429567aced6841",
        "id": "xYHeLw1do8x5"
      },
      "source": [
        "# Capsule Layers \n",
        "Here is the implementation of the necessary layers for the CapsuleNet. These are not optimized yet and can be made significantly more performant. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "167d39ca-ee32-4eec-a83b-86194252b14f",
        "_uuid": "90c180a9a8c20e3fb8a93c3eb42588927cfcd6b6",
        "id": "dQti96GTo8x5",
        "outputId": "56d5b196-e4e2-4a4f-aea7-83b96da7b273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import initializers, layers\n",
        "\n",
        "\n",
        "class Length(layers.Layer):\n",
        "    \"\"\"\n",
        "    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n",
        "    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n",
        "    inputs: shape=[None, num_vectors, dim_vector]\n",
        "    output: shape=[None, num_vectors]\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), -1) + K.epsilon())\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Length, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "class Mask(layers.Layer):\n",
        "    \"\"\"\n",
        "    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional \n",
        "    input mask. Except the max-length capsule (or specified capsule), all vectors are masked to zeros. Then flatten the\n",
        "    masked Tensor.\n",
        "    For example:\n",
        "        ```\n",
        "        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n",
        "        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n",
        "        out = Mask()(x)  # out.shape=[8, 6]\n",
        "        # or\n",
        "        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n",
        "        ```\n",
        "    \"\"\"\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
        "            # compute lengths of capsules\n",
        "            x = tf.sqrt(tf.reduce_sum(tf.square(inputs), -1))\n",
        "            # generate the mask which is a one-hot code.\n",
        "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
        "            mask = tf.one_hot(indices=tf.argmax(x, 1), depth=x.shape[1])\n",
        "\n",
        "        # inputs.shape=[None, num_capsule, dim_capsule]\n",
        "        # mask.shape=[None, num_capsule]\n",
        "        # masked.shape=[None, num_capsule * dim_capsule]\n",
        "        masked = K.batch_flatten(inputs * tf.expand_dims(mask, -1))\n",
        "        return masked\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if type(input_shape[0]) is tuple:  # true label provided\n",
        "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
        "        else:  # no true label provided\n",
        "            return tuple([None, input_shape[1] * input_shape[2]])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Mask, self).get_config()\n",
        "        return config\n",
        "\n",
        "\n",
        "def squash(vectors, axis=-1):\n",
        "    \"\"\"\n",
        "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
        "    :param vectors: some vectors to be squashed, N-dim tensor\n",
        "    :param axis: the axis to squash\n",
        "    :return: a Tensor with same shape as input vectors\n",
        "    \"\"\"\n",
        "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / tf.sqrt(s_squared_norm + K.epsilon())\n",
        "    return scale * vectors\n",
        "\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    \"\"\"\n",
        "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the\n",
        "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
        "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_capsule] and output shape = \\\n",
        "    [None, num_capsule, dim_capsule]. For Dense Layer, input_dim_capsule = dim_capsule = 1.\n",
        "    :param num_capsule: number of capsules in this layer\n",
        "    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n",
        "    :param routings: number of iterations for the routing algorithm\n",
        "    \"\"\"\n",
        "    def __init__(self, num_capsule, dim_capsule, routings=3,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
        "        self.input_num_capsule = input_shape[1]\n",
        "        self.input_dim_capsule = input_shape[2]\n",
        "\n",
        "        # Transform matrix, from each input capsule to each output capsule, there's a unique weight as in Dense layer.\n",
        "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
        "                                        self.dim_capsule, self.input_dim_capsule],\n",
        "                                 initializer=self.kernel_initializer,\n",
        "                                 name='W')\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n",
        "        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule, 1]\n",
        "        inputs_expand = tf.expand_dims(tf.expand_dims(inputs, 1), -1)\n",
        "\n",
        "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
        "        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule, 1]\n",
        "        inputs_tiled = tf.tile(inputs_expand, [1, self.num_capsule, 1, 1, 1])\n",
        "\n",
        "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n",
        "        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n",
        "        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule, 1]\n",
        "        # Regard the first two dimensions as `batch` dimension, then\n",
        "        # matmul(W, x): [..., dim_capsule, input_dim_capsule] x [..., input_dim_capsule, 1] -> [..., dim_capsule, 1].\n",
        "        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
        "        inputs_hat = tf.squeeze(tf.map_fn(lambda x: tf.matmul(self.W, x), elems=inputs_tiled))\n",
        "\n",
        "        # Begin: Routing algorithm ---------------------------------------------------------------------#\n",
        "        # The prior for coupling coefficient, initialized as zeros.\n",
        "        # b.shape = [None, self.num_capsule, 1, self.input_num_capsule].\n",
        "        b = tf.zeros(shape=[inputs.shape[0], self.num_capsule, 1, self.input_num_capsule])\n",
        "\n",
        "        assert self.routings > 0, 'The routings should be > 0.'\n",
        "        for i in range(self.routings):\n",
        "            # c.shape=[batch_size, num_capsule, 1, input_num_capsule]\n",
        "            c = tf.nn.softmax(b, axis=1)\n",
        "\n",
        "            # c.shape = [batch_size, num_capsule, 1, input_num_capsule]\n",
        "            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "            # The first two dimensions as `batch` dimension,\n",
        "            # then matmal: [..., 1, input_num_capsule] x [..., input_num_capsule, dim_capsule] -> [..., 1, dim_capsule].\n",
        "            # outputs.shape=[None, num_capsule, 1, dim_capsule]\n",
        "            outputs = squash(tf.matmul(c, inputs_hat))  # [None, 10, 1, 16]\n",
        "\n",
        "            if i < self.routings - 1:\n",
        "                # outputs.shape =  [None, num_capsule, 1, dim_capsule]\n",
        "                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
        "                # The first two dimensions as `batch` dimension, then\n",
        "                # matmal:[..., 1, dim_capsule] x [..., input_num_capsule, dim_capsule]^T -> [..., 1, input_num_capsule].\n",
        "                # b.shape=[batch_size, num_capsule, 1, input_num_capsule]\n",
        "                b += tf.matmul(outputs, inputs_hat, transpose_b=True)\n",
        "        # End: Routing algorithm -----------------------------------------------------------------------#\n",
        "\n",
        "        return tf.squeeze(outputs)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'num_capsule': self.num_capsule,\n",
        "            'dim_capsule': self.dim_capsule,\n",
        "            'routings': self.routings\n",
        "        }\n",
        "        base_config = super(CapsuleLayer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "    \"\"\"\n",
        "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "    :param inputs: 4D tensor, shape=[None, width, height, channels]\n",
        "    :param dim_capsule: the dim of the output vector of capsule\n",
        "    :param n_channels: the number of types of capsules\n",
        "    :return: output tensor, shape=[None, num_capsule, dim_capsule]\n",
        "    \"\"\"\n",
        "    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
        "                           name='primarycap_conv2d')(inputs)\n",
        "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n",
        "    return layers.Lambda(squash, name='primarycap_squash')(outputs)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "# The following is another way to implement primary capsule layer. This is much slower.\n",
        "# Apply Conv2D `n_channels` times and concatenate all capsules\n",
        "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "    outputs = []\n",
        "    for _ in range(n_channels):\n",
        "        output = layers.Conv2D(filters=dim_capsule, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n",
        "        outputs.append(layers.Reshape([output.get_shape().as_list()[1] ** 2, dim_capsule])(output))\n",
        "    outputs = layers.Concatenate(axis=1)(outputs)\n",
        "    return layers.Lambda(squash)(outputs)\n",
        "\"\"\""
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# The following is another way to implement primary capsule layer. This is much slower.\\n# Apply Conv2D `n_channels` times and concatenate all capsules\\ndef PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\\n    outputs = []\\n    for _ in range(n_channels):\\n        output = layers.Conv2D(filters=dim_capsule, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\\n        outputs.append(layers.Reshape([output.get_shape().as_list()[1] ** 2, dim_capsule])(output))\\n    outputs = layers.Concatenate(axis=1)(outputs)\\n    return layers.Lambda(squash)(outputs)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7cd17730-22b6-4ac3-a612-31f18902fa78",
        "_uuid": "61c38c7ee701bb3ee2190263cf907fcdbe40dca2",
        "id": "UDdQcGoko8x8"
      },
      "source": [
        "# Build the Model\n",
        "Here we use the layers to build up the model. The model is a bit different from a standard $X\\rightarrow y$  model, it is $(X,y)\\rightarrow (y,X)$ meaning it attempts to predict the class from the image, and then at the same time, using the same capsule reconstruct the image from the class. The approach appears very cGAN-like where the task of reconstructing better helps the model 'understand' the image data better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "bc101123-d53c-4c2e-a187-101c434885da",
        "_uuid": "2497453eb1895f624ad84617dd98c230f5640304",
        "id": "HCMIciV0o8x9"
      },
      "source": [
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "K.set_image_data_format('channels_last')\n",
        "\n",
        "def CapsNet(input_shape, n_class, routings, batch_size):\n",
        "    \"\"\"\n",
        "    A Capsule Network on MNIST.\n",
        "    :param input_shape: data shape, 3d, [width, height, channels]\n",
        "    :param n_class: number of classes\n",
        "    :param routings: number of routing iterations\n",
        "    :param batch_size: size of batch\n",
        "    :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
        "            `eval_model` can also be used for training.\n",
        "    \"\"\"\n",
        "    x = layers.Input(shape=input_shape, batch_size=batch_size)\n",
        "\n",
        "    # Layer 1: Just a conventional Conv2D layer\n",
        "    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "\n",
        "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
        "    primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
        "\n",
        "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
        "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings, name='digitcaps')(primarycaps)\n",
        "\n",
        "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
        "    # If using tensorflow, this will not be necessary. :)\n",
        "    out_caps = Length(name='capsnet')(digitcaps)\n",
        "\n",
        "    # Decoder network.\n",
        "    y = layers.Input(shape=(n_class,))\n",
        "    masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
        "    masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
        "\n",
        "    # Shared Decoder model in training and prediction\n",
        "    decoder = models.Sequential(name='decoder')\n",
        "    decoder.add(layers.Dense(512, activation='relu', input_dim=16 * n_class))\n",
        "    decoder.add(layers.Dense(1024, activation='relu'))\n",
        "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
        "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
        "\n",
        "    # Models for training and evaluation (prediction)\n",
        "    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
        "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
        "\n",
        "    # manipulate model\n",
        "    noise = layers.Input(shape=(n_class, 16))\n",
        "    noised_digitcaps = layers.Add()([digitcaps, noise])\n",
        "    masked_noised_y = Mask()([noised_digitcaps, y])\n",
        "    manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
        "    return train_model, eval_model, manipulate_model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "c6d84e5a-c33c-40c8-89c3-aba3454f7025",
        "_uuid": "9f27c6b0623ebffb6c8a24579f9dd4e321d6b1c2",
        "id": "LS09Ic7qo8x_"
      },
      "source": [
        "def margin_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
        "    :param y_true: [None, n_classes]\n",
        "    :param y_pred: [None, num_capsule]\n",
        "    :return: a scalar loss value.\n",
        "    \"\"\"\n",
        "    # return tf.reduce_mean(tf.square(y_pred))\n",
        "    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return tf.reduce_mean(tf.reduce_sum(L, 1))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "6f168849-f8f9-4241-9ba8-59abc59573f1",
        "_uuid": "d21637e677fca5be415b2ff2e8a94ef7db2ea8a1",
        "id": "oa3i75Dao8yC"
      },
      "source": [
        "# define model\n",
        "#(input_shape, n_class, routings, batch_size):\n",
        "#model = CapsNet(input_shape=[28, 28, 1],\n",
        "#                n_class=10,\n",
        "#                routings=3,batch_size=100)\n",
        "#model.summary()\n",
        "#try:\n",
        "#    plot_model(model, to_file='model.png', show_shapes=True)\n",
        "#except Exception as e:\n",
        "#    print('No fancy plot {}'.format(e))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7d75c4e0-ffca-45fc-8acc-620fe2825f82",
        "_uuid": "3e810fabad89045b7f4b51fe8540164f90e7698c",
        "id": "LjrtUDsVo8yE"
      },
      "source": [
        "# Load MNIST Data\n",
        "Here we load and reformat the Kaggle contest data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JBMdPcyZrla"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "169b7f78-12c7-4fed-886e-60024fe59339",
        "_uuid": "02b7db879a533e7bfb3116522bebf3867b23498c",
        "id": "0zSuXAxxo8yQ"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import csv\n",
        "import math\n",
        "import pandas\n",
        "\n",
        "def combine_images(generated_images, height=None, width=None):\n",
        "    num = generated_images.shape[0]\n",
        "    if width is None and height is None:\n",
        "        width = int(math.sqrt(num))\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif width is not None and height is None:  # height not given\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif height is not None and width is None:  # width not given\n",
        "        width = int(math.ceil(float(num)/height))\n",
        "\n",
        "    shape = generated_images.shape[1:3]\n",
        "    image = np.zeros((height*shape[0], width*shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[:, :, 0]\n",
        "    return image\n",
        "\n",
        "def plot_log(filename, show=True):\n",
        "\n",
        "    data = pandas.read_csv(filename)\n",
        "\n",
        "    fig = plt.figure(figsize=(4,6))\n",
        "    fig.subplots_adjust(top=0.95, bottom=0.05, right=0.95)\n",
        "    fig.add_subplot(211)\n",
        "    for key in data.keys():\n",
        "        if key.find('loss') >= 0 and not key.find('val') >= 0:  # training loss\n",
        "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
        "    plt.legend()\n",
        "    plt.title('Training loss')\n",
        "\n",
        "    fig.add_subplot(212)\n",
        "    for key in data.keys():\n",
        "        if key.find('acc') >= 0:  # acc\n",
        "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
        "    plt.legend()\n",
        "    plt.title('Training and validation accuracy')\n",
        "\n",
        "    # fig.savefig('result/log.png')\n",
        "    if show:\n",
        "        plt.show()    \n",
        "\n",
        "def test(model, data, args):\n",
        "    x_test, y_test = data\n",
        "    y_pred, x_recon = model.predict(x_test)#, batch_size=args.batch_size)\n",
        "    print('-' * 30 + 'Begin: test' + '-' * 30)\n",
        "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)) / y_test.shape[0])\n",
        "\n",
        "    img = combine_images(np.concatenate([x_test[:50], x_recon[:50]]))\n",
        "    image = img * 255\n",
        "    Image.fromarray(image.astype(np.uint8)).save(args.save_dir + \"/real_and_recon.png\")\n",
        "    print()\n",
        "    print('Reconstructed images are saved to %s/real_and_recon.png' % args.save_dir)\n",
        "    print('-' * 30 + 'End: test' + '-' * 30)\n",
        "    plt.imshow(plt.imread(args.save_dir + \"/real_and_recon.png\"))\n",
        "    plt.show()"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "e698ab37-4e74-43e6-b35b-a0507449d916",
        "_uuid": "c0374dabdf452026e3f231ffe689b5dd9f99288b",
        "id": "TZJyVmido8yK"
      },
      "source": [
        "def train(model, data, args):\n",
        "    \"\"\"\n",
        "    Training a CapsuleNet\n",
        "    :param model: the CapsuleNet model\n",
        "    :param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
        "    :param args: arguments\n",
        "    :return: The trained model\n",
        "    \"\"\"\n",
        "    # unpacking the data\n",
        "    (x_train, y_train), (x_test, y_test) = data\n",
        "\n",
        "    # callbacks\n",
        "    log = callbacks.CSVLogger(args.save_dir + '/log.csv')\n",
        "    checkpoint = callbacks.ModelCheckpoint(args.save_dir + '/weights-{epoch:02d}.h5', monitor='val_capsnet_accuracy',\n",
        "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
        "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args.lr * (args.lr_decay ** epoch))\n",
        "\n",
        "    # compile the model\n",
        "    model.compile(optimizer=optimizers.Adam(lr=args.lr),\n",
        "                  loss=[margin_loss, 'mse'],\n",
        "                  loss_weights=[1., args.lam_recon],run_eagerly=True,\n",
        "                  metrics={'capsnet': 'accuracy'})\n",
        "\n",
        "    \"\"\"\n",
        "    # Training without data augmentation:\n",
        "    model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\n",
        "              validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, tb, checkpoint, lr_decay])\n",
        "    \"\"\"\n",
        "\n",
        "    # Begin: Training with data augmentation ---------------------------------------------------------------------#\n",
        "    def train_generator(x, y, batch_size, shift_fraction=0.):\n",
        "        train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
        "                                           height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n",
        "        generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
        "        while 1:\n",
        "            x_batch, y_batch = generator.next()\n",
        "            yield (x_batch, y_batch), (y_batch, x_batch)\n",
        "\n",
        "    # Training with data augmentation. If shift_fraction=0., no augmentation.\n",
        "    model.fit(train_generator(x_train, y_train, args.batch_size, args.shift_fraction),\n",
        "              steps_per_epoch=int(y_train.shape[0] / args.batch_size),\n",
        "              epochs=args.epochs,\n",
        "              validation_data=((x_test, y_test), (y_test, x_test)), batch_size=args.batch_size,\n",
        "              callbacks=[log, checkpoint, lr_decay])\n",
        "        \n",
        "    # End: Training with data augmentation -----------------------------------------------------------------------#\n",
        "\n",
        "    model.save_weights(args.save_dir + '/trained_model.h5')\n",
        "    print('Trained model saved to \\'%s/trained_model.h5\\'' % args.save_dir)\n",
        "\n",
        "    plot_log(args.save_dir + '/log.csv', show=True)\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EKbfeEhiYkr",
        "outputId": "113f7dbe-ca54-4977-c958-524661a082c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"Capsule Network on MNIST.\")\n",
        "parser.add_argument('--epochs', default=200, type=int)\n",
        "parser.add_argument('--batch_size', default=64, type=int)\n",
        "parser.add_argument('--lr', default=0.0001, type=float,\n",
        "                        help=\"Initial learning rate\")\n",
        "parser.add_argument('--lr_decay', default=1, type=float,\n",
        "                        help=\"The value multiplied by lr at each epoch. Set a larger value for larger epochs\")\n",
        "parser.add_argument('--lam_recon', default=0.392, type=float,\n",
        "                        help=\"The coefficient for the loss of decoder\")\n",
        "parser.add_argument('-r', '--routings', default=8, type=int,\n",
        "                        help=\"Number of iterations used in routing algorithm. should > 0\")\n",
        "parser.add_argument('--shift_fraction', default=0.1, type=float,\n",
        "                        help=\"Fraction of pixels to shift at most in each direction.\")\n",
        "parser.add_argument('--debug', action='store_true',\n",
        "                        help=\"Save weights by TensorBoard\")\n",
        "parser.add_argument('--save_dir', default='./result')\n",
        "parser.add_argument('-t', '--testing', action='store_true',\n",
        "                        help=\"Test the trained model on testing dataset\")\n",
        "parser.add_argument('--digit', default=5, type=int,\n",
        "                        help=\"Digit to manipulate\")\n",
        "parser.add_argument('-w', '--weights', default=None,\n",
        "                        help=\"The path of the saved weights. Should be specified when testing\")\n",
        "args, unknown = parser.parse_known_args()\n",
        "print(args)\n",
        "\n",
        "if not os.path.exists(args.save_dir):\n",
        "    os.makedirs(args.save_dir)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=64, debug=False, digit=5, epochs=200, lam_recon=0.392, lr=0.0001, lr_decay=1, routings=8, save_dir='./result', shift_fraction=0.1, testing=False, weights=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "9dbcd67c-8f99-4d8b-8cf7-480d8dc069a4",
        "_uuid": "526436cc40013621251285812ba95725d4a6d749",
        "id": "7UfmktlEo8yF"
      },
      "source": [
        "def load_mnist():\n",
        "    # the data, shuffled and split between train and test sets\n",
        "    #from tensorflow.keras.datasets import mnist\n",
        "    #(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
        "    y_train = to_categorical(y_train.astype('float32'))\n",
        "    y_test = to_categorical(y_test.astype('float32'))\n",
        "\n",
        "    # data_slice = 10000\n",
        "    # x_train = x_train[:data_slice,:]\n",
        "    # y_train = y_train[:data_slice,:]\n",
        "    # x_test = x_test[:data_slice,:]\n",
        "    # y_test = y_test[:data_slice,:]\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVhC0mWybBFf",
        "outputId": "ae353dc6-f32a-465b-cb85-0d90a7784cb4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RIM_ONE_DL_DIR = '/content/gdrive/My Drive/MSC_Project/Dataset/RIM-ONE_DL_images/partitioned_randomly'\n",
        "RIM_ONE_R2_DIR = '/content/gdrive/My Drive/MSC_Project/Dataset/RIMONE-db-r2'"
      ],
      "metadata": {
        "id": "99C4kIlhbJdD"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HEIGHT= 64\n",
        "WIDTH = 64\n",
        "BATCH_SIZE = 32\n",
        "CLASS_COUNT = 2\n",
        "NUM_EPOCHS_A = 25\n",
        "NUM_EPOCHS_B = 40"
      ],
      "metadata": {
        "id": "kv4_0aYMbNC_"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize image to 256*256\n",
        "# Convert to numpy array\n",
        "def process_image(data_set_dir, label_dict, width,height):\n",
        "    \n",
        "    x = [] # will store images as arrays\n",
        "    y = [] # store labels\n",
        "    # list folders in directory\n",
        "    directories = os.listdir(data_set_dir)\n",
        "     \n",
        "    # for each folder (train and validation) \n",
        "    for label in directories:\n",
        "        \n",
        "        # add class label to label dictionary\n",
        "        if label not in label_dict:\n",
        "            label_dict[label] = len(label_dict)\n",
        "        \n",
        "        # create full path for image directory \n",
        "        source_images = os.path.join(data_set_dir, label)\n",
        "        images = os.listdir(source_images)\n",
        "        # for each image in directory, \n",
        "        for image in images:\n",
        "            #folder have .txt files which needs to be ignored\n",
        "            if '.txt'not in image:\n",
        "                # read the image from file, resize and add to a list\n",
        "                full_size_image = cv2.imread(os.path.join(source_images, image))\n",
        "                #gray_image = cv2.cvtColor(full_size_image, cv2.COLOR_BGR2GRAY)\n",
        "                \n",
        "                #append the image to x\n",
        "                x.append(cv2.resize(full_size_image, (width,height), \n",
        "                                                            interpolation=cv2.INTER_CUBIC))\n",
        "                # add the class label to y\n",
        "                y.append(label)\n",
        "\n",
        "    data = np.array(x, dtype=\"float\") / 255.0                \n",
        "    label = np.array(y)\n",
        "    \n",
        "    return data,label"
      ],
      "metadata": {
        "id": "RwbtEuh3bQXF"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rim_one_dl():\n",
        "  class_labels = {}\n",
        "  training_images,training_labels = process_image(RIM_ONE_DL_DIR+\"/training_set\",class_labels,WIDTH,HEIGHT)\n",
        "  training_label = (pd.Series(training_labels).map(class_labels)).values\n",
        "  training_label = to_categorical(training_label.astype('float32'))\n",
        "  training_images = training_images.reshape(-1, WIDTH, WIDTH, 3).astype('float32')\n",
        "\n",
        "  test_images,test_labels = process_image(RIM_ONE_DL_DIR+\"/test_set\",class_labels,WIDTH,HEIGHT)\n",
        "  test_label = (pd.Series(test_labels).map(class_labels)).values\n",
        "  test_label = to_categorical(test_label.astype('float32'))\n",
        "  test_images = test_images.reshape(-1, WIDTH, WIDTH, 3).astype('float32')\n",
        "\n",
        "  return (training_images,training_label),(test_images,test_label)"
      ],
      "metadata": {
        "id": "WYYvphuBabld"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rim_one_db_r2():\n",
        "  class_labels = {}\n",
        "  training_images,training_labels = process_image(RIM_ONE_R2_DIR,class_labels,WIDTH,HEIGHT)\n",
        "  training_label = (pd.Series(training_labels).map(class_labels)).values\n",
        "  training_label = to_categorical(training_label.astype('float32'))\n",
        "  training_images = training_images.reshape(-1, WIDTH, WIDTH, 3).astype('float32')\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(training_images, training_label, test_size=0.2, random_state=100)\n",
        "\n",
        "  return (X_train,y_train),(X_test,y_test)"
      ],
      "metadata": {
        "id": "aI44L23fgLGf"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_mnist()"
      ],
      "metadata": {
        "id": "N82zh4IKhTsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x1_train, y1_train), (x1_test, y1_test) = load_mnist()\n",
        "(x2_train, y2_train), (x2_test, y2_test) = get_rim_one_dl()"
      ],
      "metadata": {
        "id": "WaTRVj6MbsAQ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIid19COcqir",
        "outputId": "e2474566-e00f-4db3-c3d8-dd2d6a16fbeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQi3wkNtck-z",
        "outputId": "bb6161d2-3b1b-4947-ee87-e0a183f1c10e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(339, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed = 100):\n",
        "  tf.random.set_seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)"
      ],
      "metadata": {
        "id": "oeRFsDfUlXC0"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-i3c_UESE2P",
        "outputId": "8760a736-31ee-433f-be12-fee30c222d81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "set_seed()\n",
        " # load data\n",
        "#(x_train, y_train), (x_test, y_test) = load_mnist()\n",
        "(x_train, y_train), (x_test, y_test) = get_rim_one_db_r2()\n",
        "\n",
        "    # define model\n",
        "model, eval_model, manipulate_model = CapsNet(input_shape=x_train.shape[1:],\n",
        "                                                  n_class=2,\n",
        "                                                  routings=args.routings,\n",
        "                                                  batch_size=args.batch_size)\n",
        "model.summary()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_36\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_37 (InputLayer)          [(64, 64, 64, 3)]    0           []                               \n",
            "                                                                                                  \n",
            " conv1 (Conv2D)                 (64, 56, 56, 256)    62464       ['input_37[0][0]']               \n",
            "                                                                                                  \n",
            " primarycap_conv2d (Conv2D)     (64, 24, 24, 256)    5308672     ['conv1[0][0]']                  \n",
            "                                                                                                  \n",
            " primarycap_reshape (Reshape)   (64, 18432, 8)       0           ['primarycap_conv2d[0][0]']      \n",
            "                                                                                                  \n",
            " primarycap_squash (Lambda)     (64, 18432, 8)       0           ['primarycap_reshape[0][0]']     \n",
            "                                                                                                  \n",
            " digitcaps (CapsuleLayer)       (64, 2, 16)          4718592     ['primarycap_squash[0][0]']      \n",
            "                                                                                                  \n",
            " input_38 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " mask_36 (Mask)                 (64, 32)             0           ['digitcaps[0][0]',              \n",
            "                                                                  'input_38[0][0]']               \n",
            "                                                                                                  \n",
            " capsnet (Length)               (64, 2)              0           ['digitcaps[0][0]']              \n",
            "                                                                                                  \n",
            " decoder (Sequential)           (None, 64, 64, 3)    13137408    ['mask_36[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,227,136\n",
            "Trainable params: 23,227,136\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJxjBAqnX-IQ",
        "outputId": "b52cbe19-b0fd-4689-ffdb-86c752dbe438"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3034"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "2fda2834-7c9e-4ed6-b322-0b9e86415201",
        "_uuid": "07bbb33aaa1c7ec875798359e300bbcdba374659",
        "id": "8NCOZGHlo8yM",
        "outputId": "8da03841-47c5-48b4-c86e-1efed22f2d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#train(model=model, data=((x_train, y_train), (x_test[:60], y_test[:60])), \n",
        " #     epoch_size_frac = 0.5) # do 10% of an epoch (takes too long)\n",
        "train(model=model, data=((x_train, y_train), (x_test, y_test)), args=args)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - ETA: 0s - loss: 0.5265 - capsnet_loss: 0.4997 - decoder_loss: 0.0684 - capsnet_accuracy: 0.5562\n",
            "Epoch 1: val_capsnet_accuracy improved from -inf to 0.54348, saving model to ./result/weights-01.h5\n",
            "5/5 [==============================] - 8s 2s/step - loss: 0.5265 - capsnet_loss: 0.4997 - decoder_loss: 0.0684 - capsnet_accuracy: 0.5562 - val_loss: 0.4144 - val_capsnet_loss: 0.3885 - val_decoder_loss: 0.0660 - val_capsnet_accuracy: 0.5435 - lr: 1.0000e-04\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4184 - capsnet_loss: 0.3917 - decoder_loss: 0.0682 - capsnet_accuracy: 0.6020\n",
            "Epoch 2: val_capsnet_accuracy did not improve from 0.54348\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.4184 - capsnet_loss: 0.3917 - decoder_loss: 0.0682 - capsnet_accuracy: 0.6020 - val_loss: 0.4183 - val_capsnet_loss: 0.3925 - val_decoder_loss: 0.0659 - val_capsnet_accuracy: 0.5435 - lr: 1.0000e-04\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.4073 - capsnet_loss: 0.3807 - decoder_loss: 0.0680 - capsnet_accuracy: 0.5493\n",
            "Epoch 3: val_capsnet_accuracy did not improve from 0.54348\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.4073 - capsnet_loss: 0.3807 - decoder_loss: 0.0680 - capsnet_accuracy: 0.5493 - val_loss: 0.3336 - val_capsnet_loss: 0.3078 - val_decoder_loss: 0.0658 - val_capsnet_accuracy: 0.5435 - lr: 1.0000e-04\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3349 - capsnet_loss: 0.3081 - decoder_loss: 0.0682 - capsnet_accuracy: 0.5888\n",
            "Epoch 4: val_capsnet_accuracy did not improve from 0.54348\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.3349 - capsnet_loss: 0.3081 - decoder_loss: 0.0682 - capsnet_accuracy: 0.5888 - val_loss: 0.3332 - val_capsnet_loss: 0.3074 - val_decoder_loss: 0.0657 - val_capsnet_accuracy: 0.5435 - lr: 1.0000e-04\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.3024 - capsnet_loss: 0.2752 - decoder_loss: 0.0693 - capsnet_accuracy: 0.5395\n",
            "Epoch 5: val_capsnet_accuracy did not improve from 0.54348\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.3024 - capsnet_loss: 0.2752 - decoder_loss: 0.0693 - capsnet_accuracy: 0.5395 - val_loss: 0.2530 - val_capsnet_loss: 0.2273 - val_decoder_loss: 0.0655 - val_capsnet_accuracy: 0.4565 - lr: 1.0000e-04\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2744 - capsnet_loss: 0.2479 - decoder_loss: 0.0675 - capsnet_accuracy: 0.5230\n",
            "Epoch 6: val_capsnet_accuracy did not improve from 0.54348\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.2744 - capsnet_loss: 0.2479 - decoder_loss: 0.0675 - capsnet_accuracy: 0.5230 - val_loss: 0.2590 - val_capsnet_loss: 0.2334 - val_decoder_loss: 0.0654 - val_capsnet_accuracy: 0.5435 - lr: 1.0000e-04\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2667 - capsnet_loss: 0.2401 - decoder_loss: 0.0679 - capsnet_accuracy: 0.5625\n",
            "Epoch 7: val_capsnet_accuracy did not improve from 0.54348\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.2667 - capsnet_loss: 0.2401 - decoder_loss: 0.0679 - capsnet_accuracy: 0.5625 - val_loss: 0.2662 - val_capsnet_loss: 0.2407 - val_decoder_loss: 0.0651 - val_capsnet_accuracy: 0.5435 - lr: 1.0000e-04\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2581 - capsnet_loss: 0.2315 - decoder_loss: 0.0681 - capsnet_accuracy: 0.5921\n",
            "Epoch 8: val_capsnet_accuracy improved from 0.54348 to 0.59783, saving model to ./result/weights-08.h5\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.2581 - capsnet_loss: 0.2315 - decoder_loss: 0.0681 - capsnet_accuracy: 0.5921 - val_loss: 0.2634 - val_capsnet_loss: 0.2379 - val_decoder_loss: 0.0650 - val_capsnet_accuracy: 0.5978 - lr: 1.0000e-04\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2598 - capsnet_loss: 0.2337 - decoder_loss: 0.0666 - capsnet_accuracy: 0.6184\n",
            "Epoch 9: val_capsnet_accuracy did not improve from 0.59783\n",
            "5/5 [==============================] - 8s 2s/step - loss: 0.2598 - capsnet_loss: 0.2337 - decoder_loss: 0.0666 - capsnet_accuracy: 0.6184 - val_loss: 0.2593 - val_capsnet_loss: 0.2341 - val_decoder_loss: 0.0643 - val_capsnet_accuracy: 0.5543 - lr: 1.0000e-04\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2535 - capsnet_loss: 0.2274 - decoder_loss: 0.0666 - capsnet_accuracy: 0.6086\n",
            "Epoch 10: val_capsnet_accuracy did not improve from 0.59783\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.2535 - capsnet_loss: 0.2274 - decoder_loss: 0.0666 - capsnet_accuracy: 0.6086 - val_loss: 0.2496 - val_capsnet_loss: 0.2245 - val_decoder_loss: 0.0641 - val_capsnet_accuracy: 0.5435 - lr: 1.0000e-04\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2395 - capsnet_loss: 0.2137 - decoder_loss: 0.0659 - capsnet_accuracy: 0.6612\n",
            "Epoch 11: val_capsnet_accuracy improved from 0.59783 to 0.66304, saving model to ./result/weights-11.h5\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.2395 - capsnet_loss: 0.2137 - decoder_loss: 0.0659 - capsnet_accuracy: 0.6612 - val_loss: 0.2364 - val_capsnet_loss: 0.2116 - val_decoder_loss: 0.0633 - val_capsnet_accuracy: 0.6630 - lr: 1.0000e-04\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2367 - capsnet_loss: 0.2108 - decoder_loss: 0.0660 - capsnet_accuracy: 0.6349\n",
            "Epoch 12: val_capsnet_accuracy did not improve from 0.66304\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.2367 - capsnet_loss: 0.2108 - decoder_loss: 0.0660 - capsnet_accuracy: 0.6349 - val_loss: 0.2359 - val_capsnet_loss: 0.2115 - val_decoder_loss: 0.0624 - val_capsnet_accuracy: 0.5978 - lr: 1.0000e-04\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2292 - capsnet_loss: 0.2039 - decoder_loss: 0.0647 - capsnet_accuracy: 0.6406\n",
            "Epoch 13: val_capsnet_accuracy did not improve from 0.66304\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.2292 - capsnet_loss: 0.2039 - decoder_loss: 0.0647 - capsnet_accuracy: 0.6406 - val_loss: 0.2323 - val_capsnet_loss: 0.2083 - val_decoder_loss: 0.0613 - val_capsnet_accuracy: 0.5761 - lr: 1.0000e-04\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2320 - capsnet_loss: 0.2074 - decoder_loss: 0.0628 - capsnet_accuracy: 0.6217\n",
            "Epoch 14: val_capsnet_accuracy did not improve from 0.66304\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.2320 - capsnet_loss: 0.2074 - decoder_loss: 0.0628 - capsnet_accuracy: 0.6217 - val_loss: 0.2194 - val_capsnet_loss: 0.1958 - val_decoder_loss: 0.0600 - val_capsnet_accuracy: 0.6413 - lr: 1.0000e-04\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2140 - capsnet_loss: 0.1901 - decoder_loss: 0.0609 - capsnet_accuracy: 0.6612\n",
            "Epoch 15: val_capsnet_accuracy improved from 0.66304 to 0.68478, saving model to ./result/weights-15.h5\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.2140 - capsnet_loss: 0.1901 - decoder_loss: 0.0609 - capsnet_accuracy: 0.6612 - val_loss: 0.2065 - val_capsnet_loss: 0.1837 - val_decoder_loss: 0.0582 - val_capsnet_accuracy: 0.6848 - lr: 1.0000e-04\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1995 - capsnet_loss: 0.1758 - decoder_loss: 0.0603 - capsnet_accuracy: 0.7171\n",
            "Epoch 16: val_capsnet_accuracy did not improve from 0.68478\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1995 - capsnet_loss: 0.1758 - decoder_loss: 0.0603 - capsnet_accuracy: 0.7171 - val_loss: 0.2035 - val_capsnet_loss: 0.1819 - val_decoder_loss: 0.0552 - val_capsnet_accuracy: 0.6522 - lr: 1.0000e-04\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2076 - capsnet_loss: 0.1856 - decoder_loss: 0.0561 - capsnet_accuracy: 0.6941\n",
            "Epoch 17: val_capsnet_accuracy did not improve from 0.68478\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.2076 - capsnet_loss: 0.1856 - decoder_loss: 0.0561 - capsnet_accuracy: 0.6941 - val_loss: 0.2050 - val_capsnet_loss: 0.1848 - val_decoder_loss: 0.0516 - val_capsnet_accuracy: 0.6522 - lr: 1.0000e-04\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2011 - capsnet_loss: 0.1799 - decoder_loss: 0.0542 - capsnet_accuracy: 0.7500\n",
            "Epoch 18: val_capsnet_accuracy improved from 0.68478 to 0.75000, saving model to ./result/weights-18.h5\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.2011 - capsnet_loss: 0.1799 - decoder_loss: 0.0542 - capsnet_accuracy: 0.7500 - val_loss: 0.1878 - val_capsnet_loss: 0.1686 - val_decoder_loss: 0.0489 - val_capsnet_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2150 - capsnet_loss: 0.1962 - decoder_loss: 0.0480 - capsnet_accuracy: 0.6687\n",
            "Epoch 19: val_capsnet_accuracy did not improve from 0.75000\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.2150 - capsnet_loss: 0.1962 - decoder_loss: 0.0480 - capsnet_accuracy: 0.6687 - val_loss: 0.2275 - val_capsnet_loss: 0.2106 - val_decoder_loss: 0.0430 - val_capsnet_accuracy: 0.6196 - lr: 1.0000e-04\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.2007 - capsnet_loss: 0.1834 - decoder_loss: 0.0443 - capsnet_accuracy: 0.6974\n",
            "Epoch 20: val_capsnet_accuracy improved from 0.75000 to 0.76087, saving model to ./result/weights-20.h5\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.2007 - capsnet_loss: 0.1834 - decoder_loss: 0.0443 - capsnet_accuracy: 0.6974 - val_loss: 0.1846 - val_capsnet_loss: 0.1689 - val_decoder_loss: 0.0399 - val_capsnet_accuracy: 0.7609 - lr: 1.0000e-04\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1735 - capsnet_loss: 0.1584 - decoder_loss: 0.0384 - capsnet_accuracy: 0.7566\n",
            "Epoch 21: val_capsnet_accuracy did not improve from 0.76087\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1735 - capsnet_loss: 0.1584 - decoder_loss: 0.0384 - capsnet_accuracy: 0.7566 - val_loss: 0.1959 - val_capsnet_loss: 0.1829 - val_decoder_loss: 0.0331 - val_capsnet_accuracy: 0.6522 - lr: 1.0000e-04\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1725 - capsnet_loss: 0.1598 - decoder_loss: 0.0325 - capsnet_accuracy: 0.7368\n",
            "Epoch 22: val_capsnet_accuracy did not improve from 0.76087\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1725 - capsnet_loss: 0.1598 - decoder_loss: 0.0325 - capsnet_accuracy: 0.7368 - val_loss: 0.1868 - val_capsnet_loss: 0.1759 - val_decoder_loss: 0.0279 - val_capsnet_accuracy: 0.6522 - lr: 1.0000e-04\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1791 - capsnet_loss: 0.1682 - decoder_loss: 0.0276 - capsnet_accuracy: 0.7237\n",
            "Epoch 23: val_capsnet_accuracy improved from 0.76087 to 0.78261, saving model to ./result/weights-23.h5\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1791 - capsnet_loss: 0.1682 - decoder_loss: 0.0276 - capsnet_accuracy: 0.7237 - val_loss: 0.1760 - val_capsnet_loss: 0.1674 - val_decoder_loss: 0.0218 - val_capsnet_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1718 - capsnet_loss: 0.1632 - decoder_loss: 0.0217 - capsnet_accuracy: 0.7368\n",
            "Epoch 24: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1718 - capsnet_loss: 0.1632 - decoder_loss: 0.0217 - capsnet_accuracy: 0.7368 - val_loss: 0.1771 - val_capsnet_loss: 0.1707 - val_decoder_loss: 0.0165 - val_capsnet_accuracy: 0.6630 - lr: 1.0000e-04\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1639 - capsnet_loss: 0.1572 - decoder_loss: 0.0172 - capsnet_accuracy: 0.7531\n",
            "Epoch 25: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1639 - capsnet_loss: 0.1572 - decoder_loss: 0.0172 - capsnet_accuracy: 0.7531 - val_loss: 0.1712 - val_capsnet_loss: 0.1657 - val_decoder_loss: 0.0139 - val_capsnet_accuracy: 0.7391 - lr: 1.0000e-04\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1628 - capsnet_loss: 0.1573 - decoder_loss: 0.0141 - capsnet_accuracy: 0.7105\n",
            "Epoch 26: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1628 - capsnet_loss: 0.1573 - decoder_loss: 0.0141 - capsnet_accuracy: 0.7105 - val_loss: 0.1677 - val_capsnet_loss: 0.1631 - val_decoder_loss: 0.0116 - val_capsnet_accuracy: 0.6739 - lr: 1.0000e-04\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1430 - capsnet_loss: 0.1383 - decoder_loss: 0.0122 - capsnet_accuracy: 0.7467\n",
            "Epoch 27: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1430 - capsnet_loss: 0.1383 - decoder_loss: 0.0122 - capsnet_accuracy: 0.7467 - val_loss: 0.1625 - val_capsnet_loss: 0.1584 - val_decoder_loss: 0.0106 - val_capsnet_accuracy: 0.7283 - lr: 1.0000e-04\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1507 - capsnet_loss: 0.1463 - decoder_loss: 0.0113 - capsnet_accuracy: 0.7566\n",
            "Epoch 28: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1507 - capsnet_loss: 0.1463 - decoder_loss: 0.0113 - capsnet_accuracy: 0.7566 - val_loss: 0.1589 - val_capsnet_loss: 0.1548 - val_decoder_loss: 0.0104 - val_capsnet_accuracy: 0.7174 - lr: 1.0000e-04\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1347 - capsnet_loss: 0.1302 - decoder_loss: 0.0117 - capsnet_accuracy: 0.8092\n",
            "Epoch 29: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1347 - capsnet_loss: 0.1302 - decoder_loss: 0.0117 - capsnet_accuracy: 0.8092 - val_loss: 0.1568 - val_capsnet_loss: 0.1528 - val_decoder_loss: 0.0102 - val_capsnet_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1442 - capsnet_loss: 0.1400 - decoder_loss: 0.0107 - capsnet_accuracy: 0.7566\n",
            "Epoch 30: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1442 - capsnet_loss: 0.1400 - decoder_loss: 0.0107 - capsnet_accuracy: 0.7566 - val_loss: 0.1465 - val_capsnet_loss: 0.1428 - val_decoder_loss: 0.0095 - val_capsnet_accuracy: 0.7391 - lr: 1.0000e-04\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1390 - capsnet_loss: 0.1349 - decoder_loss: 0.0105 - capsnet_accuracy: 0.7750\n",
            "Epoch 31: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1390 - capsnet_loss: 0.1349 - decoder_loss: 0.0105 - capsnet_accuracy: 0.7750 - val_loss: 0.1840 - val_capsnet_loss: 0.1798 - val_decoder_loss: 0.0108 - val_capsnet_accuracy: 0.6413 - lr: 1.0000e-04\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1469 - capsnet_loss: 0.1425 - decoder_loss: 0.0111 - capsnet_accuracy: 0.7730\n",
            "Epoch 32: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1469 - capsnet_loss: 0.1425 - decoder_loss: 0.0111 - capsnet_accuracy: 0.7730 - val_loss: 0.1493 - val_capsnet_loss: 0.1457 - val_decoder_loss: 0.0092 - val_capsnet_accuracy: 0.7391 - lr: 1.0000e-04\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1436 - capsnet_loss: 0.1393 - decoder_loss: 0.0109 - capsnet_accuracy: 0.7730\n",
            "Epoch 33: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1436 - capsnet_loss: 0.1393 - decoder_loss: 0.0109 - capsnet_accuracy: 0.7730 - val_loss: 0.1442 - val_capsnet_loss: 0.1406 - val_decoder_loss: 0.0092 - val_capsnet_accuracy: 0.7609 - lr: 1.0000e-04\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1315 - capsnet_loss: 0.1274 - decoder_loss: 0.0105 - capsnet_accuracy: 0.7862\n",
            "Epoch 34: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1315 - capsnet_loss: 0.1274 - decoder_loss: 0.0105 - capsnet_accuracy: 0.7862 - val_loss: 0.1494 - val_capsnet_loss: 0.1458 - val_decoder_loss: 0.0090 - val_capsnet_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1420 - capsnet_loss: 0.1379 - decoder_loss: 0.0103 - capsnet_accuracy: 0.7664\n",
            "Epoch 35: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1420 - capsnet_loss: 0.1379 - decoder_loss: 0.0103 - capsnet_accuracy: 0.7664 - val_loss: 0.1460 - val_capsnet_loss: 0.1423 - val_decoder_loss: 0.0092 - val_capsnet_accuracy: 0.7174 - lr: 1.0000e-04\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1324 - capsnet_loss: 0.1283 - decoder_loss: 0.0104 - capsnet_accuracy: 0.8092\n",
            "Epoch 36: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1324 - capsnet_loss: 0.1283 - decoder_loss: 0.0104 - capsnet_accuracy: 0.8092 - val_loss: 0.1466 - val_capsnet_loss: 0.1430 - val_decoder_loss: 0.0091 - val_capsnet_accuracy: 0.7391 - lr: 1.0000e-04\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1315 - capsnet_loss: 0.1274 - decoder_loss: 0.0104 - capsnet_accuracy: 0.7844\n",
            "Epoch 37: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.1315 - capsnet_loss: 0.1274 - decoder_loss: 0.0104 - capsnet_accuracy: 0.7844 - val_loss: 0.1532 - val_capsnet_loss: 0.1496 - val_decoder_loss: 0.0094 - val_capsnet_accuracy: 0.7391 - lr: 1.0000e-04\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1339 - capsnet_loss: 0.1299 - decoder_loss: 0.0102 - capsnet_accuracy: 0.7763\n",
            "Epoch 38: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1339 - capsnet_loss: 0.1299 - decoder_loss: 0.0102 - capsnet_accuracy: 0.7763 - val_loss: 0.1483 - val_capsnet_loss: 0.1446 - val_decoder_loss: 0.0094 - val_capsnet_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1249 - capsnet_loss: 0.1209 - decoder_loss: 0.0103 - capsnet_accuracy: 0.8026\n",
            "Epoch 39: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1249 - capsnet_loss: 0.1209 - decoder_loss: 0.0103 - capsnet_accuracy: 0.8026 - val_loss: 0.1379 - val_capsnet_loss: 0.1345 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1264 - capsnet_loss: 0.1223 - decoder_loss: 0.0106 - capsnet_accuracy: 0.8289\n",
            "Epoch 40: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1264 - capsnet_loss: 0.1223 - decoder_loss: 0.0106 - capsnet_accuracy: 0.8289 - val_loss: 0.1401 - val_capsnet_loss: 0.1368 - val_decoder_loss: 0.0086 - val_capsnet_accuracy: 0.7609 - lr: 1.0000e-04\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1354 - capsnet_loss: 0.1313 - decoder_loss: 0.0106 - capsnet_accuracy: 0.7862\n",
            "Epoch 41: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1354 - capsnet_loss: 0.1313 - decoder_loss: 0.0106 - capsnet_accuracy: 0.7862 - val_loss: 0.1530 - val_capsnet_loss: 0.1494 - val_decoder_loss: 0.0091 - val_capsnet_accuracy: 0.7283 - lr: 1.0000e-04\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1239 - capsnet_loss: 0.1201 - decoder_loss: 0.0096 - capsnet_accuracy: 0.7895\n",
            "Epoch 42: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1239 - capsnet_loss: 0.1201 - decoder_loss: 0.0096 - capsnet_accuracy: 0.7895 - val_loss: 0.1458 - val_capsnet_loss: 0.1423 - val_decoder_loss: 0.0090 - val_capsnet_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1226 - capsnet_loss: 0.1186 - decoder_loss: 0.0102 - capsnet_accuracy: 0.8375\n",
            "Epoch 43: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1226 - capsnet_loss: 0.1186 - decoder_loss: 0.0102 - capsnet_accuracy: 0.8375 - val_loss: 0.1389 - val_capsnet_loss: 0.1353 - val_decoder_loss: 0.0092 - val_capsnet_accuracy: 0.7717 - lr: 1.0000e-04\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1236 - capsnet_loss: 0.1196 - decoder_loss: 0.0103 - capsnet_accuracy: 0.8355\n",
            "Epoch 44: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1236 - capsnet_loss: 0.1196 - decoder_loss: 0.0103 - capsnet_accuracy: 0.8355 - val_loss: 0.1416 - val_capsnet_loss: 0.1381 - val_decoder_loss: 0.0089 - val_capsnet_accuracy: 0.7609 - lr: 1.0000e-04\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1183 - capsnet_loss: 0.1145 - decoder_loss: 0.0097 - capsnet_accuracy: 0.8224\n",
            "Epoch 45: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1183 - capsnet_loss: 0.1145 - decoder_loss: 0.0097 - capsnet_accuracy: 0.8224 - val_loss: 0.1441 - val_capsnet_loss: 0.1406 - val_decoder_loss: 0.0090 - val_capsnet_accuracy: 0.7174 - lr: 1.0000e-04\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1151 - capsnet_loss: 0.1111 - decoder_loss: 0.0104 - capsnet_accuracy: 0.8224\n",
            "Epoch 46: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1151 - capsnet_loss: 0.1111 - decoder_loss: 0.0104 - capsnet_accuracy: 0.8224 - val_loss: 0.1351 - val_capsnet_loss: 0.1317 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.7609 - lr: 1.0000e-04\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1169 - capsnet_loss: 0.1130 - decoder_loss: 0.0099 - capsnet_accuracy: 0.8454\n",
            "Epoch 47: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1169 - capsnet_loss: 0.1130 - decoder_loss: 0.0099 - capsnet_accuracy: 0.8454 - val_loss: 0.1543 - val_capsnet_loss: 0.1506 - val_decoder_loss: 0.0094 - val_capsnet_accuracy: 0.7609 - lr: 1.0000e-04\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1336 - capsnet_loss: 0.1297 - decoder_loss: 0.0098 - capsnet_accuracy: 0.8125\n",
            "Epoch 48: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1336 - capsnet_loss: 0.1297 - decoder_loss: 0.0098 - capsnet_accuracy: 0.8125 - val_loss: 0.1471 - val_capsnet_loss: 0.1436 - val_decoder_loss: 0.0091 - val_capsnet_accuracy: 0.7609 - lr: 1.0000e-04\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1169 - capsnet_loss: 0.1129 - decoder_loss: 0.0101 - capsnet_accuracy: 0.8188\n",
            "Epoch 49: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.1169 - capsnet_loss: 0.1129 - decoder_loss: 0.0101 - capsnet_accuracy: 0.8188 - val_loss: 0.1410 - val_capsnet_loss: 0.1376 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.7717 - lr: 1.0000e-04\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1146 - capsnet_loss: 0.1106 - decoder_loss: 0.0101 - capsnet_accuracy: 0.8586\n",
            "Epoch 50: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.1146 - capsnet_loss: 0.1106 - decoder_loss: 0.0101 - capsnet_accuracy: 0.8586 - val_loss: 0.1844 - val_capsnet_loss: 0.1804 - val_decoder_loss: 0.0101 - val_capsnet_accuracy: 0.7174 - lr: 1.0000e-04\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1266 - capsnet_loss: 0.1228 - decoder_loss: 0.0097 - capsnet_accuracy: 0.7763\n",
            "Epoch 51: val_capsnet_accuracy did not improve from 0.78261\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1266 - capsnet_loss: 0.1228 - decoder_loss: 0.0097 - capsnet_accuracy: 0.7763 - val_loss: 0.1345 - val_capsnet_loss: 0.1310 - val_decoder_loss: 0.0088 - val_capsnet_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1093 - capsnet_loss: 0.1054 - decoder_loss: 0.0099 - capsnet_accuracy: 0.8520\n",
            "Epoch 52: val_capsnet_accuracy improved from 0.78261 to 0.80435, saving model to ./result/weights-52.h5\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1093 - capsnet_loss: 0.1054 - decoder_loss: 0.0099 - capsnet_accuracy: 0.8520 - val_loss: 0.1336 - val_capsnet_loss: 0.1303 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1170 - capsnet_loss: 0.1133 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8059\n",
            "Epoch 53: val_capsnet_accuracy did not improve from 0.80435\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1170 - capsnet_loss: 0.1133 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8059 - val_loss: 0.1428 - val_capsnet_loss: 0.1392 - val_decoder_loss: 0.0093 - val_capsnet_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1161 - capsnet_loss: 0.1122 - decoder_loss: 0.0101 - capsnet_accuracy: 0.8454\n",
            "Epoch 54: val_capsnet_accuracy did not improve from 0.80435\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1161 - capsnet_loss: 0.1122 - decoder_loss: 0.0101 - capsnet_accuracy: 0.8454 - val_loss: 0.1529 - val_capsnet_loss: 0.1494 - val_decoder_loss: 0.0091 - val_capsnet_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1086 - capsnet_loss: 0.1049 - decoder_loss: 0.0095 - capsnet_accuracy: 0.8594\n",
            "Epoch 55: val_capsnet_accuracy did not improve from 0.80435\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.1086 - capsnet_loss: 0.1049 - decoder_loss: 0.0095 - capsnet_accuracy: 0.8594 - val_loss: 0.1259 - val_capsnet_loss: 0.1225 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1118 - capsnet_loss: 0.1079 - decoder_loss: 0.0100 - capsnet_accuracy: 0.8487\n",
            "Epoch 56: val_capsnet_accuracy did not improve from 0.80435\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1118 - capsnet_loss: 0.1079 - decoder_loss: 0.0100 - capsnet_accuracy: 0.8487 - val_loss: 0.1330 - val_capsnet_loss: 0.1296 - val_decoder_loss: 0.0086 - val_capsnet_accuracy: 0.7935 - lr: 1.0000e-04\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1261 - capsnet_loss: 0.1223 - decoder_loss: 0.0098 - capsnet_accuracy: 0.8191\n",
            "Epoch 57: val_capsnet_accuracy did not improve from 0.80435\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1261 - capsnet_loss: 0.1223 - decoder_loss: 0.0098 - capsnet_accuracy: 0.8191 - val_loss: 0.1348 - val_capsnet_loss: 0.1315 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1253 - capsnet_loss: 0.1214 - decoder_loss: 0.0101 - capsnet_accuracy: 0.8059\n",
            "Epoch 58: val_capsnet_accuracy did not improve from 0.80435\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1253 - capsnet_loss: 0.1214 - decoder_loss: 0.0101 - capsnet_accuracy: 0.8059 - val_loss: 0.1581 - val_capsnet_loss: 0.1544 - val_decoder_loss: 0.0096 - val_capsnet_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1078 - capsnet_loss: 0.1040 - decoder_loss: 0.0099 - capsnet_accuracy: 0.8520\n",
            "Epoch 59: val_capsnet_accuracy improved from 0.80435 to 0.81522, saving model to ./result/weights-59.h5\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1078 - capsnet_loss: 0.1040 - decoder_loss: 0.0099 - capsnet_accuracy: 0.8520 - val_loss: 0.1348 - val_capsnet_loss: 0.1313 - val_decoder_loss: 0.0088 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1128 - capsnet_loss: 0.1092 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8191\n",
            "Epoch 60: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1128 - capsnet_loss: 0.1092 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8191 - val_loss: 0.1349 - val_capsnet_loss: 0.1316 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1087 - capsnet_loss: 0.1051 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8438\n",
            "Epoch 61: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1087 - capsnet_loss: 0.1051 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8438 - val_loss: 0.1458 - val_capsnet_loss: 0.1423 - val_decoder_loss: 0.0088 - val_capsnet_accuracy: 0.7717 - lr: 1.0000e-04\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1060 - capsnet_loss: 0.1023 - decoder_loss: 0.0095 - capsnet_accuracy: 0.8421\n",
            "Epoch 62: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1060 - capsnet_loss: 0.1023 - decoder_loss: 0.0095 - capsnet_accuracy: 0.8421 - val_loss: 0.1408 - val_capsnet_loss: 0.1374 - val_decoder_loss: 0.0087 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1148 - capsnet_loss: 0.1111 - decoder_loss: 0.0096 - capsnet_accuracy: 0.8487\n",
            "Epoch 63: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1148 - capsnet_loss: 0.1111 - decoder_loss: 0.0096 - capsnet_accuracy: 0.8487 - val_loss: 0.1331 - val_capsnet_loss: 0.1296 - val_decoder_loss: 0.0088 - val_capsnet_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1119 - capsnet_loss: 0.1077 - decoder_loss: 0.0107 - capsnet_accuracy: 0.8454\n",
            "Epoch 64: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1119 - capsnet_loss: 0.1077 - decoder_loss: 0.0107 - capsnet_accuracy: 0.8454 - val_loss: 0.1601 - val_capsnet_loss: 0.1566 - val_decoder_loss: 0.0090 - val_capsnet_accuracy: 0.7717 - lr: 1.0000e-04\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1157 - capsnet_loss: 0.1124 - decoder_loss: 0.0085 - capsnet_accuracy: 0.8355\n",
            "Epoch 65: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1157 - capsnet_loss: 0.1124 - decoder_loss: 0.0085 - capsnet_accuracy: 0.8355 - val_loss: 0.1825 - val_capsnet_loss: 0.1790 - val_decoder_loss: 0.0091 - val_capsnet_accuracy: 0.6848 - lr: 1.0000e-04\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1224 - capsnet_loss: 0.1186 - decoder_loss: 0.0097 - capsnet_accuracy: 0.8092\n",
            "Epoch 66: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1224 - capsnet_loss: 0.1186 - decoder_loss: 0.0097 - capsnet_accuracy: 0.8092 - val_loss: 0.1467 - val_capsnet_loss: 0.1431 - val_decoder_loss: 0.0092 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1138 - capsnet_loss: 0.1098 - decoder_loss: 0.0102 - capsnet_accuracy: 0.8375\n",
            "Epoch 67: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.1138 - capsnet_loss: 0.1098 - decoder_loss: 0.0102 - capsnet_accuracy: 0.8375 - val_loss: 0.1397 - val_capsnet_loss: 0.1363 - val_decoder_loss: 0.0088 - val_capsnet_accuracy: 0.7717 - lr: 1.0000e-04\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1120 - capsnet_loss: 0.1083 - decoder_loss: 0.0095 - capsnet_accuracy: 0.8586\n",
            "Epoch 68: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1120 - capsnet_loss: 0.1083 - decoder_loss: 0.0095 - capsnet_accuracy: 0.8586 - val_loss: 0.1345 - val_capsnet_loss: 0.1312 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.7935 - lr: 1.0000e-04\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1250 - capsnet_loss: 0.1210 - decoder_loss: 0.0101 - capsnet_accuracy: 0.8191\n",
            "Epoch 69: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1250 - capsnet_loss: 0.1210 - decoder_loss: 0.0101 - capsnet_accuracy: 0.8191 - val_loss: 0.1259 - val_capsnet_loss: 0.1227 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1158 - capsnet_loss: 0.1121 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8158\n",
            "Epoch 70: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1158 - capsnet_loss: 0.1121 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8158 - val_loss: 0.1779 - val_capsnet_loss: 0.1743 - val_decoder_loss: 0.0091 - val_capsnet_accuracy: 0.7283 - lr: 1.0000e-04\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1071 - capsnet_loss: 0.1035 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8487\n",
            "Epoch 71: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1071 - capsnet_loss: 0.1035 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8487 - val_loss: 0.1290 - val_capsnet_loss: 0.1258 - val_decoder_loss: 0.0082 - val_capsnet_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1063 - capsnet_loss: 0.1027 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8520\n",
            "Epoch 72: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1063 - capsnet_loss: 0.1027 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8520 - val_loss: 0.1329 - val_capsnet_loss: 0.1296 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1096 - capsnet_loss: 0.1059 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8500\n",
            "Epoch 73: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1096 - capsnet_loss: 0.1059 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8500 - val_loss: 0.1482 - val_capsnet_loss: 0.1448 - val_decoder_loss: 0.0088 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1008 - capsnet_loss: 0.0972 - decoder_loss: 0.0092 - capsnet_accuracy: 0.8684\n",
            "Epoch 74: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.1008 - capsnet_loss: 0.0972 - decoder_loss: 0.0092 - capsnet_accuracy: 0.8684 - val_loss: 0.1321 - val_capsnet_loss: 0.1288 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.7609 - lr: 1.0000e-04\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1074 - capsnet_loss: 0.1037 - decoder_loss: 0.0096 - capsnet_accuracy: 0.8388\n",
            "Epoch 75: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1074 - capsnet_loss: 0.1037 - decoder_loss: 0.0096 - capsnet_accuracy: 0.8388 - val_loss: 0.1381 - val_capsnet_loss: 0.1347 - val_decoder_loss: 0.0086 - val_capsnet_accuracy: 0.7935 - lr: 1.0000e-04\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0949 - capsnet_loss: 0.0915 - decoder_loss: 0.0087 - capsnet_accuracy: 0.8816\n",
            "Epoch 76: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0949 - capsnet_loss: 0.0915 - decoder_loss: 0.0087 - capsnet_accuracy: 0.8816 - val_loss: 0.1353 - val_capsnet_loss: 0.1320 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0997 - capsnet_loss: 0.0959 - decoder_loss: 0.0095 - capsnet_accuracy: 0.8684\n",
            "Epoch 77: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0997 - capsnet_loss: 0.0959 - decoder_loss: 0.0095 - capsnet_accuracy: 0.8684 - val_loss: 0.1222 - val_capsnet_loss: 0.1190 - val_decoder_loss: 0.0081 - val_capsnet_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0982 - capsnet_loss: 0.0946 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8586\n",
            "Epoch 78: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0982 - capsnet_loss: 0.0946 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8586 - val_loss: 0.1721 - val_capsnet_loss: 0.1684 - val_decoder_loss: 0.0093 - val_capsnet_accuracy: 0.7717 - lr: 1.0000e-04\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0986 - capsnet_loss: 0.0950 - decoder_loss: 0.0092 - capsnet_accuracy: 0.8500\n",
            "Epoch 79: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0986 - capsnet_loss: 0.0950 - decoder_loss: 0.0092 - capsnet_accuracy: 0.8500 - val_loss: 0.1348 - val_capsnet_loss: 0.1315 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.7717 - lr: 1.0000e-04\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1161 - capsnet_loss: 0.1125 - decoder_loss: 0.0090 - capsnet_accuracy: 0.8125\n",
            "Epoch 80: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.1161 - capsnet_loss: 0.1125 - decoder_loss: 0.0090 - capsnet_accuracy: 0.8125 - val_loss: 0.1270 - val_capsnet_loss: 0.1238 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.7935 - lr: 1.0000e-04\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0913 - capsnet_loss: 0.0877 - decoder_loss: 0.0092 - capsnet_accuracy: 0.8783\n",
            "Epoch 81: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0913 - capsnet_loss: 0.0877 - decoder_loss: 0.0092 - capsnet_accuracy: 0.8783 - val_loss: 0.1191 - val_capsnet_loss: 0.1159 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.7935 - lr: 1.0000e-04\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0959 - capsnet_loss: 0.0923 - decoder_loss: 0.0092 - capsnet_accuracy: 0.8651\n",
            "Epoch 82: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0959 - capsnet_loss: 0.0923 - decoder_loss: 0.0092 - capsnet_accuracy: 0.8651 - val_loss: 0.1219 - val_capsnet_loss: 0.1186 - val_decoder_loss: 0.0082 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1048 - capsnet_loss: 0.1012 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8553\n",
            "Epoch 83: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1048 - capsnet_loss: 0.1012 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8553 - val_loss: 0.1422 - val_capsnet_loss: 0.1389 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0860 - capsnet_loss: 0.0825 - decoder_loss: 0.0091 - capsnet_accuracy: 0.9013\n",
            "Epoch 84: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0860 - capsnet_loss: 0.0825 - decoder_loss: 0.0091 - capsnet_accuracy: 0.9013 - val_loss: 0.1498 - val_capsnet_loss: 0.1465 - val_decoder_loss: 0.0086 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0986 - capsnet_loss: 0.0951 - decoder_loss: 0.0089 - capsnet_accuracy: 0.8531\n",
            "Epoch 85: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0986 - capsnet_loss: 0.0951 - decoder_loss: 0.0089 - capsnet_accuracy: 0.8531 - val_loss: 0.1296 - val_capsnet_loss: 0.1264 - val_decoder_loss: 0.0082 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0985 - capsnet_loss: 0.0948 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8684\n",
            "Epoch 86: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0985 - capsnet_loss: 0.0948 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8684 - val_loss: 0.1184 - val_capsnet_loss: 0.1153 - val_decoder_loss: 0.0081 - val_capsnet_accuracy: 0.7935 - lr: 1.0000e-04\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0926 - capsnet_loss: 0.0891 - decoder_loss: 0.0089 - capsnet_accuracy: 0.8717\n",
            "Epoch 87: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0926 - capsnet_loss: 0.0891 - decoder_loss: 0.0089 - capsnet_accuracy: 0.8717 - val_loss: 0.1184 - val_capsnet_loss: 0.1152 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0906 - capsnet_loss: 0.0870 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8717\n",
            "Epoch 88: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0906 - capsnet_loss: 0.0870 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8717 - val_loss: 0.1322 - val_capsnet_loss: 0.1289 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0935 - capsnet_loss: 0.0901 - decoder_loss: 0.0087 - capsnet_accuracy: 0.8618\n",
            "Epoch 89: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0935 - capsnet_loss: 0.0901 - decoder_loss: 0.0087 - capsnet_accuracy: 0.8618 - val_loss: 0.1413 - val_capsnet_loss: 0.1381 - val_decoder_loss: 0.0081 - val_capsnet_accuracy: 0.7935 - lr: 1.0000e-04\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1027 - capsnet_loss: 0.0992 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8553\n",
            "Epoch 90: val_capsnet_accuracy did not improve from 0.81522\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1027 - capsnet_loss: 0.0992 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8553 - val_loss: 0.1196 - val_capsnet_loss: 0.1165 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0971 - capsnet_loss: 0.0936 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8969\n",
            "Epoch 91: val_capsnet_accuracy improved from 0.81522 to 0.82609, saving model to ./result/weights-91.h5\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.0971 - capsnet_loss: 0.0936 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8969 - val_loss: 0.1168 - val_capsnet_loss: 0.1136 - val_decoder_loss: 0.0082 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1091 - capsnet_loss: 0.1053 - decoder_loss: 0.0096 - capsnet_accuracy: 0.8224\n",
            "Epoch 92: val_capsnet_accuracy did not improve from 0.82609\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1091 - capsnet_loss: 0.1053 - decoder_loss: 0.0096 - capsnet_accuracy: 0.8224 - val_loss: 0.1608 - val_capsnet_loss: 0.1574 - val_decoder_loss: 0.0085 - val_capsnet_accuracy: 0.7609 - lr: 1.0000e-04\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1027 - capsnet_loss: 0.0994 - decoder_loss: 0.0085 - capsnet_accuracy: 0.8454\n",
            "Epoch 93: val_capsnet_accuracy did not improve from 0.82609\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1027 - capsnet_loss: 0.0994 - decoder_loss: 0.0085 - capsnet_accuracy: 0.8454 - val_loss: 0.1246 - val_capsnet_loss: 0.1214 - val_decoder_loss: 0.0081 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0893 - capsnet_loss: 0.0857 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8947\n",
            "Epoch 94: val_capsnet_accuracy did not improve from 0.82609\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0893 - capsnet_loss: 0.0857 - decoder_loss: 0.0093 - capsnet_accuracy: 0.8947 - val_loss: 0.1210 - val_capsnet_loss: 0.1179 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0856 - capsnet_loss: 0.0821 - decoder_loss: 0.0089 - capsnet_accuracy: 0.8849\n",
            "Epoch 95: val_capsnet_accuracy did not improve from 0.82609\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0856 - capsnet_loss: 0.0821 - decoder_loss: 0.0089 - capsnet_accuracy: 0.8849 - val_loss: 0.1599 - val_capsnet_loss: 0.1564 - val_decoder_loss: 0.0090 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1040 - capsnet_loss: 0.1004 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8553\n",
            "Epoch 96: val_capsnet_accuracy did not improve from 0.82609\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1040 - capsnet_loss: 0.1004 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8553 - val_loss: 0.1194 - val_capsnet_loss: 0.1163 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1100 - capsnet_loss: 0.1065 - decoder_loss: 0.0090 - capsnet_accuracy: 0.8594\n",
            "Epoch 97: val_capsnet_accuracy improved from 0.82609 to 0.84783, saving model to ./result/weights-97.h5\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.1100 - capsnet_loss: 0.1065 - decoder_loss: 0.0090 - capsnet_accuracy: 0.8594 - val_loss: 0.1179 - val_capsnet_loss: 0.1147 - val_decoder_loss: 0.0081 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1053 - capsnet_loss: 0.1018 - decoder_loss: 0.0089 - capsnet_accuracy: 0.8388\n",
            "Epoch 98: val_capsnet_accuracy did not improve from 0.84783\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1053 - capsnet_loss: 0.1018 - decoder_loss: 0.0089 - capsnet_accuracy: 0.8388 - val_loss: 0.1441 - val_capsnet_loss: 0.1406 - val_decoder_loss: 0.0089 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1051 - capsnet_loss: 0.1017 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8487\n",
            "Epoch 99: val_capsnet_accuracy improved from 0.84783 to 0.85870, saving model to ./result/weights-99.h5\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1051 - capsnet_loss: 0.1017 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8487 - val_loss: 0.1215 - val_capsnet_loss: 0.1184 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0969 - capsnet_loss: 0.0932 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8816\n",
            "Epoch 100: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0969 - capsnet_loss: 0.0932 - decoder_loss: 0.0094 - capsnet_accuracy: 0.8816 - val_loss: 0.1287 - val_capsnet_loss: 0.1256 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0914 - capsnet_loss: 0.0881 - decoder_loss: 0.0085 - capsnet_accuracy: 0.8717\n",
            "Epoch 101: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0914 - capsnet_loss: 0.0881 - decoder_loss: 0.0085 - capsnet_accuracy: 0.8717 - val_loss: 0.1158 - val_capsnet_loss: 0.1127 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0892 - capsnet_loss: 0.0857 - decoder_loss: 0.0090 - capsnet_accuracy: 0.8882\n",
            "Epoch 102: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0892 - capsnet_loss: 0.0857 - decoder_loss: 0.0090 - capsnet_accuracy: 0.8882 - val_loss: 0.1487 - val_capsnet_loss: 0.1454 - val_decoder_loss: 0.0083 - val_capsnet_accuracy: 0.7826 - lr: 1.0000e-04\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1017 - capsnet_loss: 0.0981 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8438\n",
            "Epoch 103: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1017 - capsnet_loss: 0.0981 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8438 - val_loss: 0.1521 - val_capsnet_loss: 0.1488 - val_decoder_loss: 0.0082 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1102 - capsnet_loss: 0.1068 - decoder_loss: 0.0086 - capsnet_accuracy: 0.8388\n",
            "Epoch 104: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1102 - capsnet_loss: 0.1068 - decoder_loss: 0.0086 - capsnet_accuracy: 0.8388 - val_loss: 0.1241 - val_capsnet_loss: 0.1210 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1133 - capsnet_loss: 0.1094 - decoder_loss: 0.0099 - capsnet_accuracy: 0.8322\n",
            "Epoch 105: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1133 - capsnet_loss: 0.1094 - decoder_loss: 0.0099 - capsnet_accuracy: 0.8322 - val_loss: 0.1127 - val_capsnet_loss: 0.1096 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0939 - capsnet_loss: 0.0907 - decoder_loss: 0.0083 - capsnet_accuracy: 0.8783\n",
            "Epoch 106: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0939 - capsnet_loss: 0.0907 - decoder_loss: 0.0083 - capsnet_accuracy: 0.8783 - val_loss: 0.1487 - val_capsnet_loss: 0.1454 - val_decoder_loss: 0.0084 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1013 - capsnet_loss: 0.0979 - decoder_loss: 0.0087 - capsnet_accuracy: 0.8816\n",
            "Epoch 107: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1013 - capsnet_loss: 0.0979 - decoder_loss: 0.0087 - capsnet_accuracy: 0.8816 - val_loss: 0.1223 - val_capsnet_loss: 0.1193 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.1008 - capsnet_loss: 0.0973 - decoder_loss: 0.0089 - capsnet_accuracy: 0.8651\n",
            "Epoch 108: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.1008 - capsnet_loss: 0.0973 - decoder_loss: 0.0089 - capsnet_accuracy: 0.8651 - val_loss: 0.1192 - val_capsnet_loss: 0.1161 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0897 - capsnet_loss: 0.0863 - decoder_loss: 0.0086 - capsnet_accuracy: 0.8625\n",
            "Epoch 109: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0897 - capsnet_loss: 0.0863 - decoder_loss: 0.0086 - capsnet_accuracy: 0.8625 - val_loss: 0.1277 - val_capsnet_loss: 0.1246 - val_decoder_loss: 0.0081 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0965 - capsnet_loss: 0.0931 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8980\n",
            "Epoch 110: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0965 - capsnet_loss: 0.0931 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8980 - val_loss: 0.1254 - val_capsnet_loss: 0.1223 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0962 - capsnet_loss: 0.0927 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8520\n",
            "Epoch 111: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0962 - capsnet_loss: 0.0927 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8520 - val_loss: 0.1239 - val_capsnet_loss: 0.1208 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0857 - capsnet_loss: 0.0822 - decoder_loss: 0.0089 - capsnet_accuracy: 0.9046\n",
            "Epoch 112: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0857 - capsnet_loss: 0.0822 - decoder_loss: 0.0089 - capsnet_accuracy: 0.9046 - val_loss: 0.1240 - val_capsnet_loss: 0.1208 - val_decoder_loss: 0.0081 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0906 - capsnet_loss: 0.0871 - decoder_loss: 0.0090 - capsnet_accuracy: 0.8750\n",
            "Epoch 113: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0906 - capsnet_loss: 0.0871 - decoder_loss: 0.0090 - capsnet_accuracy: 0.8750 - val_loss: 0.1103 - val_capsnet_loss: 0.1072 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0917 - capsnet_loss: 0.0883 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8849\n",
            "Epoch 114: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0917 - capsnet_loss: 0.0883 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8849 - val_loss: 0.1139 - val_capsnet_loss: 0.1108 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0844 - capsnet_loss: 0.0810 - decoder_loss: 0.0086 - capsnet_accuracy: 0.8875\n",
            "Epoch 115: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0844 - capsnet_loss: 0.0810 - decoder_loss: 0.0086 - capsnet_accuracy: 0.8875 - val_loss: 0.1171 - val_capsnet_loss: 0.1140 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0783 - capsnet_loss: 0.0749 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9145\n",
            "Epoch 116: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0783 - capsnet_loss: 0.0749 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9145 - val_loss: 0.1165 - val_capsnet_loss: 0.1134 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0917 - capsnet_loss: 0.0881 - decoder_loss: 0.0092 - capsnet_accuracy: 0.8849\n",
            "Epoch 117: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0917 - capsnet_loss: 0.0881 - decoder_loss: 0.0092 - capsnet_accuracy: 0.8849 - val_loss: 0.1139 - val_capsnet_loss: 0.1107 - val_decoder_loss: 0.0081 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0897 - capsnet_loss: 0.0863 - decoder_loss: 0.0086 - capsnet_accuracy: 0.8684\n",
            "Epoch 118: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0897 - capsnet_loss: 0.0863 - decoder_loss: 0.0086 - capsnet_accuracy: 0.8684 - val_loss: 0.1458 - val_capsnet_loss: 0.1427 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0933 - capsnet_loss: 0.0898 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8651\n",
            "Epoch 119: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0933 - capsnet_loss: 0.0898 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8651 - val_loss: 0.1205 - val_capsnet_loss: 0.1175 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0954 - capsnet_loss: 0.0919 - decoder_loss: 0.0090 - capsnet_accuracy: 0.8684\n",
            "Epoch 120: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0954 - capsnet_loss: 0.0919 - decoder_loss: 0.0090 - capsnet_accuracy: 0.8684 - val_loss: 0.1273 - val_capsnet_loss: 0.1243 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0908 - capsnet_loss: 0.0875 - decoder_loss: 0.0084 - capsnet_accuracy: 0.8969\n",
            "Epoch 121: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0908 - capsnet_loss: 0.0875 - decoder_loss: 0.0084 - capsnet_accuracy: 0.8969 - val_loss: 0.1269 - val_capsnet_loss: 0.1238 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0894 - capsnet_loss: 0.0860 - decoder_loss: 0.0087 - capsnet_accuracy: 0.8816\n",
            "Epoch 122: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0894 - capsnet_loss: 0.0860 - decoder_loss: 0.0087 - capsnet_accuracy: 0.8816 - val_loss: 0.1178 - val_capsnet_loss: 0.1148 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0952 - capsnet_loss: 0.0916 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8684\n",
            "Epoch 123: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0952 - capsnet_loss: 0.0916 - decoder_loss: 0.0091 - capsnet_accuracy: 0.8684 - val_loss: 0.1146 - val_capsnet_loss: 0.1115 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0791 - capsnet_loss: 0.0758 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9145\n",
            "Epoch 124: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0791 - capsnet_loss: 0.0758 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9145 - val_loss: 0.1193 - val_capsnet_loss: 0.1163 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0826 - capsnet_loss: 0.0792 - decoder_loss: 0.0086 - capsnet_accuracy: 0.8980\n",
            "Epoch 125: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0826 - capsnet_loss: 0.0792 - decoder_loss: 0.0086 - capsnet_accuracy: 0.8980 - val_loss: 0.1189 - val_capsnet_loss: 0.1159 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0792 - capsnet_loss: 0.0758 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9046\n",
            "Epoch 126: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0792 - capsnet_loss: 0.0758 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9046 - val_loss: 0.1296 - val_capsnet_loss: 0.1265 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0825 - capsnet_loss: 0.0790 - decoder_loss: 0.0087 - capsnet_accuracy: 0.8969\n",
            "Epoch 127: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0825 - capsnet_loss: 0.0790 - decoder_loss: 0.0087 - capsnet_accuracy: 0.8969 - val_loss: 0.1155 - val_capsnet_loss: 0.1125 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0820 - capsnet_loss: 0.0786 - decoder_loss: 0.0087 - capsnet_accuracy: 0.8849\n",
            "Epoch 128: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0820 - capsnet_loss: 0.0786 - decoder_loss: 0.0087 - capsnet_accuracy: 0.8849 - val_loss: 0.1075 - val_capsnet_loss: 0.1044 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0959 - capsnet_loss: 0.0925 - decoder_loss: 0.0087 - capsnet_accuracy: 0.8586\n",
            "Epoch 129: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0959 - capsnet_loss: 0.0925 - decoder_loss: 0.0087 - capsnet_accuracy: 0.8586 - val_loss: 0.1104 - val_capsnet_loss: 0.1073 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0767 - capsnet_loss: 0.0733 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9145\n",
            "Epoch 130: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0767 - capsnet_loss: 0.0733 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9145 - val_loss: 0.1347 - val_capsnet_loss: 0.1315 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.7935 - lr: 1.0000e-04\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0804 - capsnet_loss: 0.0771 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9145\n",
            "Epoch 131: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0804 - capsnet_loss: 0.0771 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9145 - val_loss: 0.1119 - val_capsnet_loss: 0.1088 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0796 - capsnet_loss: 0.0763 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9079\n",
            "Epoch 132: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0796 - capsnet_loss: 0.0763 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9079 - val_loss: 0.1161 - val_capsnet_loss: 0.1130 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0799 - capsnet_loss: 0.0765 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9031\n",
            "Epoch 133: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0799 - capsnet_loss: 0.0765 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9031 - val_loss: 0.1516 - val_capsnet_loss: 0.1484 - val_decoder_loss: 0.0081 - val_capsnet_accuracy: 0.7609 - lr: 1.0000e-04\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0915 - capsnet_loss: 0.0880 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9046\n",
            "Epoch 134: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0915 - capsnet_loss: 0.0880 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9046 - val_loss: 0.1209 - val_capsnet_loss: 0.1178 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0854 - capsnet_loss: 0.0821 - decoder_loss: 0.0082 - capsnet_accuracy: 0.8947\n",
            "Epoch 135: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0854 - capsnet_loss: 0.0821 - decoder_loss: 0.0082 - capsnet_accuracy: 0.8947 - val_loss: 0.1214 - val_capsnet_loss: 0.1183 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0888 - capsnet_loss: 0.0852 - decoder_loss: 0.0090 - capsnet_accuracy: 0.8914\n",
            "Epoch 136: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0888 - capsnet_loss: 0.0852 - decoder_loss: 0.0090 - capsnet_accuracy: 0.8914 - val_loss: 0.1194 - val_capsnet_loss: 0.1164 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0723 - capsnet_loss: 0.0690 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9178\n",
            "Epoch 137: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0723 - capsnet_loss: 0.0690 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9178 - val_loss: 0.1091 - val_capsnet_loss: 0.1060 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0801 - capsnet_loss: 0.0767 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9013\n",
            "Epoch 138: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0801 - capsnet_loss: 0.0767 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9013 - val_loss: 0.1144 - val_capsnet_loss: 0.1113 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0796 - capsnet_loss: 0.0763 - decoder_loss: 0.0084 - capsnet_accuracy: 0.8906\n",
            "Epoch 139: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0796 - capsnet_loss: 0.0763 - decoder_loss: 0.0084 - capsnet_accuracy: 0.8906 - val_loss: 0.1244 - val_capsnet_loss: 0.1213 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8043 - lr: 1.0000e-04\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0782 - capsnet_loss: 0.0748 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9079\n",
            "Epoch 140: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0782 - capsnet_loss: 0.0748 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9079 - val_loss: 0.1109 - val_capsnet_loss: 0.1078 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0694 - capsnet_loss: 0.0661 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9243\n",
            "Epoch 141: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0694 - capsnet_loss: 0.0661 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9243 - val_loss: 0.1156 - val_capsnet_loss: 0.1125 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0766 - capsnet_loss: 0.0732 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9079\n",
            "Epoch 142: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0766 - capsnet_loss: 0.0732 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9079 - val_loss: 0.1144 - val_capsnet_loss: 0.1113 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0689 - capsnet_loss: 0.0655 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9178\n",
            "Epoch 143: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0689 - capsnet_loss: 0.0655 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9178 - val_loss: 0.1103 - val_capsnet_loss: 0.1072 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0841 - capsnet_loss: 0.0807 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9046\n",
            "Epoch 144: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0841 - capsnet_loss: 0.0807 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9046 - val_loss: 0.1144 - val_capsnet_loss: 0.1113 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0830 - capsnet_loss: 0.0798 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9031\n",
            "Epoch 145: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0830 - capsnet_loss: 0.0798 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9031 - val_loss: 0.1577 - val_capsnet_loss: 0.1546 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.7717 - lr: 1.0000e-04\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0820 - capsnet_loss: 0.0786 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8947\n",
            "Epoch 146: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0820 - capsnet_loss: 0.0786 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8947 - val_loss: 0.1093 - val_capsnet_loss: 0.1062 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0795 - capsnet_loss: 0.0761 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9112\n",
            "Epoch 147: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0795 - capsnet_loss: 0.0761 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9112 - val_loss: 0.1108 - val_capsnet_loss: 0.1078 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0788 - capsnet_loss: 0.0756 - decoder_loss: 0.0081 - capsnet_accuracy: 0.8980\n",
            "Epoch 148: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0788 - capsnet_loss: 0.0756 - decoder_loss: 0.0081 - capsnet_accuracy: 0.8980 - val_loss: 0.1217 - val_capsnet_loss: 0.1187 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0831 - capsnet_loss: 0.0796 - decoder_loss: 0.0089 - capsnet_accuracy: 0.8947\n",
            "Epoch 149: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0831 - capsnet_loss: 0.0796 - decoder_loss: 0.0089 - capsnet_accuracy: 0.8947 - val_loss: 0.1144 - val_capsnet_loss: 0.1113 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0803 - capsnet_loss: 0.0768 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9046\n",
            "Epoch 150: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0803 - capsnet_loss: 0.0768 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9046 - val_loss: 0.1277 - val_capsnet_loss: 0.1246 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0737 - capsnet_loss: 0.0703 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9062\n",
            "Epoch 151: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0737 - capsnet_loss: 0.0703 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9062 - val_loss: 0.1078 - val_capsnet_loss: 0.1047 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0749 - capsnet_loss: 0.0715 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9046\n",
            "Epoch 152: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0749 - capsnet_loss: 0.0715 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9046 - val_loss: 0.1113 - val_capsnet_loss: 0.1082 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0644 - capsnet_loss: 0.0612 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9375\n",
            "Epoch 153: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0644 - capsnet_loss: 0.0612 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9375 - val_loss: 0.1150 - val_capsnet_loss: 0.1120 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0698 - capsnet_loss: 0.0665 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9276\n",
            "Epoch 154: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0698 - capsnet_loss: 0.0665 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9276 - val_loss: 0.1118 - val_capsnet_loss: 0.1087 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0649 - capsnet_loss: 0.0615 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9408\n",
            "Epoch 155: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0649 - capsnet_loss: 0.0615 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9408 - val_loss: 0.1164 - val_capsnet_loss: 0.1134 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0665 - capsnet_loss: 0.0632 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9408\n",
            "Epoch 156: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0665 - capsnet_loss: 0.0632 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9408 - val_loss: 0.1112 - val_capsnet_loss: 0.1081 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0721 - capsnet_loss: 0.0687 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9281\n",
            "Epoch 157: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0721 - capsnet_loss: 0.0687 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9281 - val_loss: 0.1180 - val_capsnet_loss: 0.1149 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0774 - capsnet_loss: 0.0741 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9145\n",
            "Epoch 158: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.0774 - capsnet_loss: 0.0741 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9145 - val_loss: 0.1191 - val_capsnet_loss: 0.1160 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0660 - capsnet_loss: 0.0628 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9243\n",
            "Epoch 159: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0660 - capsnet_loss: 0.0628 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9243 - val_loss: 0.1228 - val_capsnet_loss: 0.1198 - val_decoder_loss: 0.0076 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0848 - capsnet_loss: 0.0814 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8980\n",
            "Epoch 160: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0848 - capsnet_loss: 0.0814 - decoder_loss: 0.0088 - capsnet_accuracy: 0.8980 - val_loss: 0.1219 - val_capsnet_loss: 0.1188 - val_decoder_loss: 0.0080 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0751 - capsnet_loss: 0.0719 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9013\n",
            "Epoch 161: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0751 - capsnet_loss: 0.0719 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9013 - val_loss: 0.1111 - val_capsnet_loss: 0.1081 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0689 - capsnet_loss: 0.0655 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9211\n",
            "Epoch 162: val_capsnet_accuracy did not improve from 0.85870\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0689 - capsnet_loss: 0.0655 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9211 - val_loss: 0.1151 - val_capsnet_loss: 0.1120 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0662 - capsnet_loss: 0.0628 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9125\n",
            "Epoch 163: val_capsnet_accuracy improved from 0.85870 to 0.86957, saving model to ./result/weights-163.h5\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.0662 - capsnet_loss: 0.0628 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9125 - val_loss: 0.1061 - val_capsnet_loss: 0.1030 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0688 - capsnet_loss: 0.0654 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9342\n",
            "Epoch 164: val_capsnet_accuracy did not improve from 0.86957\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0688 - capsnet_loss: 0.0654 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9342 - val_loss: 0.1077 - val_capsnet_loss: 0.1046 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0719 - capsnet_loss: 0.0685 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9112\n",
            "Epoch 165: val_capsnet_accuracy did not improve from 0.86957\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0719 - capsnet_loss: 0.0685 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9112 - val_loss: 0.1161 - val_capsnet_loss: 0.1131 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0721 - capsnet_loss: 0.0688 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9178\n",
            "Epoch 166: val_capsnet_accuracy did not improve from 0.86957\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0721 - capsnet_loss: 0.0688 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9178 - val_loss: 0.1125 - val_capsnet_loss: 0.1094 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0734 - capsnet_loss: 0.0700 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9145\n",
            "Epoch 167: val_capsnet_accuracy did not improve from 0.86957\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0734 - capsnet_loss: 0.0700 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9145 - val_loss: 0.1074 - val_capsnet_loss: 0.1044 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0590 - capsnet_loss: 0.0558 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9441\n",
            "Epoch 168: val_capsnet_accuracy did not improve from 0.86957\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0590 - capsnet_loss: 0.0558 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9441 - val_loss: 0.1123 - val_capsnet_loss: 0.1093 - val_decoder_loss: 0.0076 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0748 - capsnet_loss: 0.0714 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9062\n",
            "Epoch 169: val_capsnet_accuracy did not improve from 0.86957\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0748 - capsnet_loss: 0.0714 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9062 - val_loss: 0.1254 - val_capsnet_loss: 0.1223 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.7935 - lr: 1.0000e-04\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0713 - capsnet_loss: 0.0680 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9342\n",
            "Epoch 170: val_capsnet_accuracy improved from 0.86957 to 0.90217, saving model to ./result/weights-170.h5\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.0713 - capsnet_loss: 0.0680 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9342 - val_loss: 0.1064 - val_capsnet_loss: 0.1034 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.9022 - lr: 1.0000e-04\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0643 - capsnet_loss: 0.0609 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9375\n",
            "Epoch 171: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0643 - capsnet_loss: 0.0609 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9375 - val_loss: 0.1084 - val_capsnet_loss: 0.1054 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0670 - capsnet_loss: 0.0638 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9013\n",
            "Epoch 172: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0670 - capsnet_loss: 0.0638 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9013 - val_loss: 0.1077 - val_capsnet_loss: 0.1047 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8804 - lr: 1.0000e-04\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0611 - capsnet_loss: 0.0578 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9309\n",
            "Epoch 173: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0611 - capsnet_loss: 0.0578 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9309 - val_loss: 0.1075 - val_capsnet_loss: 0.1045 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0597 - capsnet_loss: 0.0564 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9276\n",
            "Epoch 174: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0597 - capsnet_loss: 0.0564 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9276 - val_loss: 0.1144 - val_capsnet_loss: 0.1114 - val_decoder_loss: 0.0076 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0667 - capsnet_loss: 0.0634 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9187\n",
            "Epoch 175: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0667 - capsnet_loss: 0.0634 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9187 - val_loss: 0.1141 - val_capsnet_loss: 0.1111 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0648 - capsnet_loss: 0.0615 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9243\n",
            "Epoch 176: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0648 - capsnet_loss: 0.0615 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9243 - val_loss: 0.1111 - val_capsnet_loss: 0.1080 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0630 - capsnet_loss: 0.0596 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9309\n",
            "Epoch 177: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0630 - capsnet_loss: 0.0596 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9309 - val_loss: 0.1061 - val_capsnet_loss: 0.1031 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0638 - capsnet_loss: 0.0604 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9342\n",
            "Epoch 178: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0638 - capsnet_loss: 0.0604 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9342 - val_loss: 0.1208 - val_capsnet_loss: 0.1178 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0653 - capsnet_loss: 0.0621 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9309\n",
            "Epoch 179: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0653 - capsnet_loss: 0.0621 - decoder_loss: 0.0083 - capsnet_accuracy: 0.9309 - val_loss: 0.1052 - val_capsnet_loss: 0.1022 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0671 - capsnet_loss: 0.0638 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9211\n",
            "Epoch 180: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0671 - capsnet_loss: 0.0638 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9211 - val_loss: 0.1074 - val_capsnet_loss: 0.1044 - val_decoder_loss: 0.0076 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0728 - capsnet_loss: 0.0695 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9187\n",
            "Epoch 181: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0728 - capsnet_loss: 0.0695 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9187 - val_loss: 0.1088 - val_capsnet_loss: 0.1058 - val_decoder_loss: 0.0076 - val_capsnet_accuracy: 0.8804 - lr: 1.0000e-04\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0575 - capsnet_loss: 0.0541 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9408\n",
            "Epoch 182: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0575 - capsnet_loss: 0.0541 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9408 - val_loss: 0.1016 - val_capsnet_loss: 0.0985 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8804 - lr: 1.0000e-04\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0656 - capsnet_loss: 0.0621 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9112\n",
            "Epoch 183: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0656 - capsnet_loss: 0.0621 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9112 - val_loss: 0.1146 - val_capsnet_loss: 0.1116 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0795 - capsnet_loss: 0.0761 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9046\n",
            "Epoch 184: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0795 - capsnet_loss: 0.0761 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9046 - val_loss: 0.1080 - val_capsnet_loss: 0.1049 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0650 - capsnet_loss: 0.0616 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9243\n",
            "Epoch 185: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0650 - capsnet_loss: 0.0616 - decoder_loss: 0.0085 - capsnet_accuracy: 0.9243 - val_loss: 0.1136 - val_capsnet_loss: 0.1106 - val_decoder_loss: 0.0075 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0670 - capsnet_loss: 0.0637 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9243\n",
            "Epoch 186: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0670 - capsnet_loss: 0.0637 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9243 - val_loss: 0.1113 - val_capsnet_loss: 0.1083 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8152 - lr: 1.0000e-04\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0689 - capsnet_loss: 0.0657 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9250\n",
            "Epoch 187: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.0689 - capsnet_loss: 0.0657 - decoder_loss: 0.0082 - capsnet_accuracy: 0.9250 - val_loss: 0.1164 - val_capsnet_loss: 0.1134 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8261 - lr: 1.0000e-04\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0590 - capsnet_loss: 0.0556 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9375\n",
            "Epoch 188: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0590 - capsnet_loss: 0.0556 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9375 - val_loss: 0.1064 - val_capsnet_loss: 0.1034 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8804 - lr: 1.0000e-04\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0616 - capsnet_loss: 0.0581 - decoder_loss: 0.0089 - capsnet_accuracy: 0.9474\n",
            "Epoch 189: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0616 - capsnet_loss: 0.0581 - decoder_loss: 0.0089 - capsnet_accuracy: 0.9474 - val_loss: 0.1156 - val_capsnet_loss: 0.1125 - val_decoder_loss: 0.0079 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0714 - capsnet_loss: 0.0682 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9145\n",
            "Epoch 190: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0714 - capsnet_loss: 0.0682 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9145 - val_loss: 0.1093 - val_capsnet_loss: 0.1063 - val_decoder_loss: 0.0076 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0635 - capsnet_loss: 0.0602 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9441\n",
            "Epoch 191: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0635 - capsnet_loss: 0.0602 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9441 - val_loss: 0.1096 - val_capsnet_loss: 0.1066 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0714 - capsnet_loss: 0.0680 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9178\n",
            "Epoch 192: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0714 - capsnet_loss: 0.0680 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9178 - val_loss: 0.1068 - val_capsnet_loss: 0.1037 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0610 - capsnet_loss: 0.0575 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9219\n",
            "Epoch 193: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.0610 - capsnet_loss: 0.0575 - decoder_loss: 0.0088 - capsnet_accuracy: 0.9219 - val_loss: 0.1040 - val_capsnet_loss: 0.1010 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8804 - lr: 1.0000e-04\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0564 - capsnet_loss: 0.0532 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9408\n",
            "Epoch 194: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.0564 - capsnet_loss: 0.0532 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9408 - val_loss: 0.1047 - val_capsnet_loss: 0.1017 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0616 - capsnet_loss: 0.0584 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9408\n",
            "Epoch 195: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0616 - capsnet_loss: 0.0584 - decoder_loss: 0.0080 - capsnet_accuracy: 0.9408 - val_loss: 0.1103 - val_capsnet_loss: 0.1073 - val_decoder_loss: 0.0076 - val_capsnet_accuracy: 0.8696 - lr: 1.0000e-04\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0559 - capsnet_loss: 0.0523 - decoder_loss: 0.0090 - capsnet_accuracy: 0.9507\n",
            "Epoch 196: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0559 - capsnet_loss: 0.0523 - decoder_loss: 0.0090 - capsnet_accuracy: 0.9507 - val_loss: 0.1061 - val_capsnet_loss: 0.1030 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8587 - lr: 1.0000e-04\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0634 - capsnet_loss: 0.0601 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9079\n",
            "Epoch 197: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0634 - capsnet_loss: 0.0601 - decoder_loss: 0.0084 - capsnet_accuracy: 0.9079 - val_loss: 0.1171 - val_capsnet_loss: 0.1140 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8370 - lr: 1.0000e-04\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0650 - capsnet_loss: 0.0616 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9243\n",
            "Epoch 198: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0650 - capsnet_loss: 0.0616 - decoder_loss: 0.0087 - capsnet_accuracy: 0.9243 - val_loss: 0.1066 - val_capsnet_loss: 0.1036 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8804 - lr: 1.0000e-04\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0623 - capsnet_loss: 0.0590 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9438\n",
            "Epoch 199: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.0623 - capsnet_loss: 0.0590 - decoder_loss: 0.0086 - capsnet_accuracy: 0.9438 - val_loss: 0.1084 - val_capsnet_loss: 0.1054 - val_decoder_loss: 0.0078 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.0579 - capsnet_loss: 0.0547 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9507\n",
            "Epoch 200: val_capsnet_accuracy did not improve from 0.90217\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.0579 - capsnet_loss: 0.0547 - decoder_loss: 0.0081 - capsnet_accuracy: 0.9507 - val_loss: 0.1220 - val_capsnet_loss: 0.1190 - val_decoder_loss: 0.0077 - val_capsnet_accuracy: 0.8478 - lr: 1.0000e-04\n",
            "Trained model saved to './result/trained_model.h5'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7f092cbd3ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2706080d-2d50-4876-bd4d-c0f3c4ce87b5",
        "_uuid": "9afcde53f3cf3ba3eeeed1f083241874b4cd84e2",
        "id": "lMRMqKA9o8yS"
      },
      "source": [
        "# Show the results on the hold-out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0OqXV_qjimb",
        "outputId": "be602ec7-9802-4c4b-9b56-63d217dc4dd6"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(92, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "56a6fe58-fe97-45c8-95da-223297842f79",
        "_uuid": "25ac7feb2d111b82e755169288ffd47ebc4d196a",
        "id": "PL8it8clo8yT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2e22280-d52b-44d0-e547-0787c57bc3b0"
      },
      "source": [
        "\n",
        "\n",
        "test(model=eval_model, data=(x_test, y_test), args=args)\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-eb232b85b867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-108-69f5d40baf9c>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, data, args)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, batch_size=args.batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m30\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Begin: test'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test acc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_34/digitcaps/map/TensorArrayUnstack/TensorListFromTensor' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-100-aa220b8ce642>\", line 3, in <module>\n      test(model=eval_model, data=(x_test, y_test), args=args)\n    File \"<ipython-input-35-f02408383758>\", line 52, in test\n      y_pred, x_recon = model.predict(x_test, batch_size=100)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1982, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"<ipython-input-32-dcffcc493d88>\", line 124, in call\n      inputs_hat = tf.squeeze(tf.map_fn(lambda x: tf.matmul(self.W, x), elems=inputs_tiled))\nNode: 'model_34/digitcaps/map/TensorArrayUnstack/TensorListFromTensor'\nSpecified a list with shape [2,18432,8,1] from a tensor with shape [2,9216,8,1]\n\t [[{{node model_34/digitcaps/map/TensorArrayUnstack/TensorListFromTensor}}]] [Op:__inference_predict_function_4105446]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiBpPdkmY500"
      },
      "source": [
        "# pick some collabs stuff "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}